<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="http://img.catpaws.top/blog-source/imgs/webicon.png"><link rel="icon" href="http://img.catpaws.top/blog-source/imgs/webicon.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="猫爪在上"><meta name="keywords" content=""><meta name="description" content="一、数据结构 1.1、动态字符串 SDS Redis 中保存的 Key 是字符串，value 往往是字符串或者字符串的集合。可见字符串是 Redis 中最常用的一种数据结构。 不过 Redis 没有直接使用 C 语言中的字符串，因为 C 语言字符串存在很多问题：   没有内置的字符串类 C 语言没有像其他高级语言那样提供内置的字符串类型。字符串在 C 语言中是以空字符\0"><meta property="og:type" content="article"><meta property="og:title" content="Redis - 原理篇"><meta property="og:url" content="https://catpaws.top/284457ed/index.html"><meta property="og:site_name" content="猫爪在上de书桌"><meta property="og:description" content="一、数据结构 1.1、动态字符串 SDS Redis 中保存的 Key 是字符串，value 往往是字符串或者字符串的集合。可见字符串是 Redis 中最常用的一种数据结构。 不过 Redis 没有直接使用 C 语言中的字符串，因为 C 语言字符串存在很多问题：   没有内置的字符串类 C 语言没有像其他高级语言那样提供内置的字符串类型。字符串在 C 语言中是以空字符\0"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://img.catpaws.top/img/image-20241230172432582-2024-12-3017_25_02.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20241230173709674-2024-12-3017_37_11.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20241230213128501-2024-12-3021_31_30.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20241231115851490-2024-12-3111_58_54.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250101104658228-2025-1-110_47_00.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250101104919212-2025-1-110_49_20.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250101202110049-2025-1-120_21_37.png"><meta property="og:image" content="http://img.catpaws.top/img/1653992091967-2025-1-120_50_56.png"><meta property="og:image" content="http://img.catpaws.top/img/1653992172526-2025-1-120_59_11.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250101210256404-2025-1-121_02_57.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250101210931134-2025-1-121_09_32.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250101211648500-2025-1-121_16_49.png"><meta property="og:image" content="http://img.catpaws.top/img/%E6%97%A0%E6%A0%87%E9%A2%98-2025-1-122_10_10.png"><meta property="og:image" content="http://img.catpaws.top/img/1653896065386-2025-1-209_23_22.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250102195140543-2025-1-219_51_44.png"><meta property="og:image" content="http://img.catpaws.top/img/1653896687354-2025-1-219_54_18.png"><meta property="og:image" content="http://img.catpaws.top/img/select-2025-1-221_10_44.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250102212349537-2025-1-221_23_50.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250102213454924-2025-1-221_34_57.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250102214720250-2025-1-221_47_22.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250102221030671-2025-1-222_10_31.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250102221248791-2025-1-413_40_19.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250102221353073-2025-1-222_13_55.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250102222040358-2025-1-413_40_46.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250102222307077-2025-1-222_23_09.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250102222811692-2025-1-222_28_12.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250103091322550-2025-1-309_13_33.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250103092223705-2025-1-309_22_24.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250103144051474-2025-1-314_40_52.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250103214944506-2025-1-321_50_18.png"><meta property="og:image" content="http://img.catpaws.top/img/redisDb-2025-1-322_35_25.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250103230109701-2025-1-323_01_10.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250103230330831-2025-1-323_03_31.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250103230423489-2025-1-323_04_24.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250103235731736-2025-1-323_57_42.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20250104004036495-2025-1-400_40_37.png"><meta property="article:published_time" content="2024-12-30T07:18:46.000Z"><meta property="article:modified_time" content="2025-01-26T07:06:10.737Z"><meta property="article:author" content="猫爪在上"><meta property="article:tag" content="动态字符串SDS"><meta property="article:tag" content="IntSet"><meta property="article:tag" content="Dict"><meta property="article:tag" content="ZipList"><meta property="article:tag" content="QuickList"><meta property="article:tag" content="SkipList"><meta property="article:tag" content="RedisObject"><meta property="article:tag" content="Linux IO模型"><meta property="article:tag" content="Redis网络模型"><meta property="article:tag" content="内存策略"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="http://img.catpaws.top/img/image-20241230172432582-2024-12-3017_25_02.png"><title>Redis - 原理篇 - 猫爪在上de书桌</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css"><link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/bynotes/texiao/source/css/shubiao.css"><link rel="stylesheet" href="//img.catpaws.top/blog-source/css/font.css"><link rel="stylesheet" href="//img.catpaws.top/blog-source/css/poem.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"catpaws.top",root:"/",version:"1.9.8",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,follow_dnt:!0,baidu:null,google:{measurement_id:null},tencent:{sid:null,cid:null},leancloud:{app_id:"TNTPv22capMq3aFV9S0sLqSm-gzGzoHsz",app_key:"G2BBAxXmiixopVg5mIJ2sxXR",server_url:"https://tntpv22c.lc-cn-n1-shared.com",path:"window.location.pathname",ignore_local:!1},umami:{src:null,website_id:null,domains:null,start_time:"2024-01-01T00:00:00.000Z",token:null,api_server:null}},search_path:"/local-search.xml",include_content_in_search:!0};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 7.3.0"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>猫爪在上de书桌</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/about/" target="_self"><i class="iconfont icon-addrcard"></i> <span>主页</span></a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><i class="iconfont icon-books"></i> <span>博客</span></a><div class="dropdown-menu" aria-labelledby="navbarDropdown"><a class="dropdown-item" href="/" target="_self"><i class="iconfont icon-pen"></i> <span>文章</span> </a><a class="dropdown-item" href="/archives/" target="_self"><i class="iconfont icon-archive-fill"></i> <span>归档</span> </a><a class="dropdown-item" href="/categories/" target="_self"><i class="iconfont icon-category-fill"></i> <span>分类</span> </a><a class="dropdown-item" href="/tags/" target="_self"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></div></li><li class="nav-item"><a class="nav-link" href="/messages/" target="_self"><i class="iconfont icon-comment"></i> <span>留言板</span></a></li><li class="nav-item"><a class="nav-link" href="/timeline/" target="_self"><i class="iconfont icon-images"></i> <span>时光轴</span></a></li><li class="nav-item"><a class="nav-link" href="/links/" target="_self"><i class="iconfont icon-link-fill"></i> <span>友链</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(http://img.catpaws.top/blog-source/imgs/article-bg.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="Redis - 原理篇"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2024-12-30 15:18" pubdate>2024年12月30日 下午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 18k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 152 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 id="seo-header">Redis - 原理篇</h1><p id="updated-time" class="note note-info">本文最后更新于 2025年1月26日 下午</p><div class="markdown-body"><meta name="referrer" , content="no-referrer"><h2 id="一数据结构">一、数据结构</h2><h3 id="动态字符串-sds">1.1、动态字符串 SDS</h3><p>Redis 中保存的 Key 是字符串，value 往往是字符串或者字符串的集合。可见字符串是 Redis 中最常用的一种数据结构。</p><p>不过 Redis 没有直接使用 C 语言中的字符串，因为 C 语言字符串存在很多问题：</p><p><img src="http://img.catpaws.top/img/image-20241230172432582-2024-12-3017_25_02.png" srcset="/img/loading.gif" lazyload alt="image-20241230172432582" style="zoom:80%"></p><ul><li><p>没有内置的字符串类</p><p>C 语言没有像其他高级语言那样提供内置的字符串类型。字符串在 C 语言中是以空字符<code>\0</code>'结尾的字符数组。</p></li><li><p>获取字符串长度的需要通过运算</p><p>由于 C 语言字符串没有内置的长度字段，获取字符串长度需要遍历整个字符数组，时间复杂度为 O(N)。</p></li><li><p>非二进制安全</p><p>C 语言字符串以空字符结尾，因此不能包含空字符作为数据的一部分。这限制了字符串在保存二进制数据（如图片、音频、视频文件等）方面的能力。</p></li></ul><p>Redis 构建了一种新的字符串结构，称为<strong>简单动态字符串</strong>（Simple Dynamic String），简称<strong>SDS</strong></p><p>例如，执行<code>set name jack</code>，Redis 会创建两个 SDS，其中一个是包含'name'的 SDS，另一个是包含'jack'的 SDS。</p><p>Redis 是 C 语言实现的，其中 SDS 是一个结构体，源码如下：</p><figure><img src="http://img.catpaws.top/img/image-20241230173117353-2024-12-3017_31_36.png" srcset="/img/loading.gif" lazyload alt="image-20241230173117353"><figcaption aria-hidden="true">image-20241230173117353</figcaption></figure><p>其中包含头信息和字符数组</p><ul><li><p><code>len</code>：buf 已保存的字符串字节数，不包含结束标示。</p></li><li><p><code>alloc</code>：buf 申请的总的字节数，不包含结束标示。</p><blockquote><p>初始时<code>alloc</code>和<code>len</code>相同，但随着动态扩容，两者会有差异。</p></blockquote></li><li><p><code>flags</code>：不同 SDS 的头类型，用来控制 SDS 的头大小。</p><p>为了适应不同长度的字符串，Redis 设计了五种 SDS 头部结构，这些结构的主要区别在于它们能够表示的字符串长度的范围不同。</p><figure><img src="http://img.catpaws.top/img/image-20241230172940680-2024-12-3017_29_42.png" srcset="/img/loading.gif" lazyload alt="image-20241230172940680"><figcaption aria-hidden="true">image-20241230172940680</figcaption></figure></li><li><p>字符数组<code>buf[]</code>，保存字符串。为了兼容 C 语言，SDS 存储字符串时也会在字符数组末尾添加一个结束标识<code>/0</code>。</p></li></ul><p>例如：保存一个字符串'name'的 SDS 结构如下：</p><p><img src="http://img.catpaws.top/img/image-20241230173709674-2024-12-3017_37_11.png" srcset="/img/loading.gif" lazyload alt="image-20241230173709674" style="zoom:80%"></p><p>SDS 之所以叫做动态字符串，是因为它具备动态扩容的能力，例如一个内容为“hi”的 SDS：</p><figure><img src="http://img.catpaws.top/img/1653984787383-2024-12-3017_51_27.png" srcset="/img/loading.gif" lazyload alt="1653984787383"><figcaption aria-hidden="true">1653984787383</figcaption></figure><p>假如我们要给 SDS 追加一段字符串“,Amy”，这里首先会申请新内存空间：</p><p>如果新字符串小于 1M，则新空间为扩展后字符串长度的两倍+1（'1'是存储结束标识<code>\0</code>花费的空间）；</p><p>如果新字符串大于 1M，则新空间为扩展后字符串长度+1M+1。称为内存预分配。</p><figure><img src="http://img.catpaws.top/img/image-20241230175235061-2024-12-3017_52_36.png" srcset="/img/loading.gif" lazyload alt="image-20241230175235061"><figcaption aria-hidden="true">image-20241230175235061</figcaption></figure><p>优点：</p><ol type="1"><li>获取字符串长度的时间复杂度为<span class="math inline">\(O(1)\)</span></li><li>支持动态扩容</li><li>减少内存分配次数</li><li>二进制安全</li></ol><blockquote><p>当 Redis 需要存储一个字符串时，它会根据字符串的实际长度来选择合适的 SDS 头部结构。</p><p>‌<strong>当 Redis 中存储的字符串长度发生变化超出当前 SDS（简单动态字符串）结构存储上限时，SDS 会进行动态扩容，而不是切换到其他 SDS 结构存储</strong>‌。</p><p>SDS 还采用了<strong>内存预分配</strong>和<strong>惰性空间释放</strong>策略来优化内存使用。</p><ul><li>当字符串需要扩容时，SDS 会根据一定的规则（如小于 1MB 时按原长度两倍扩容，大于 1MB 时最多分配 1MB 空间）来分配新的内存空间 ‌。</li><li>当字符串缩短时，SDS 并不会立即回收多余的内存空间，而是将其记录下来，以便将来使用。这种惰性空间释放策略减少了内存分配和释放的次数，提高了性能 ‌。</li></ul></blockquote><h3 id="intset">1.2、Intset</h3><h4 id="intset-的结构">IntSet 的结构</h4><p>IntSet 是 Redis 中 set 集合的一种实现方式，基于整数数组来实现，并且具备长度可变、有序等特征。 结构如下：</p><figure><img src="http://img.catpaws.top/img/1653984923322-2024-12-3018_33_13.png" srcset="/img/loading.gif" lazyload alt="1653984923322"><figcaption aria-hidden="true">1653984923322</figcaption></figure><p>其中的 encoding 包含三种模式，表示存储的整数大小不同：</p><figure><img src="http://img.catpaws.top/img/1653984942385-2024-12-3018_33_14.png" srcset="/img/loading.gif" lazyload alt="1653984942385"><figcaption aria-hidden="true">1653984942385</figcaption></figure><p>为了方便查找，Redis 会将 intset 中所有的整数按照<strong>升序</strong>依次保存在 contents 数组中。</p><p>假设有一个 intset，元素为{5，10，20}，采用的编码是<code>INTSET_ENC_INT16</code>，则每个整数占 2 字节：结构如图：</p><figure><img src="http://img.catpaws.top/img/image-20241230183956901-2024-12-3018_39_59.png" srcset="/img/loading.gif" lazyload alt="image-20241230183956901"><figcaption aria-hidden="true">image-20241230183956901</figcaption></figure><p>现在，数组中每个数字都在 int16_t 的范围内，因此采用的编码方式是<code>INTSET_ENC_INT16</code>，每部分占用的字节大小为： encoding：4 字节 length：4 字节 contents：2 字节 * 3 = 6 字节</p><blockquote><p>由于数组中每个数字都采用相同的编码方式，即所占用的空间大小相同，可以结合数组起始地址和数组下标快速定位到每个元素的物理地址 <code>startPtr + (sizeof(int16) * index)</code></p><p>数组下标理解为 <strong>当前元素到数组起始地址间隔了多少个元素</strong></p></blockquote><h4 id="intset-升级">IntSet 升级</h4><p>当前的 IntSet 中，元素为（5，10，20），采用的编码是<code>INTSET_ENC_INT16</code>，则每个整数占 2 字节：</p><figure><img src="http://img.catpaws.top/img/image-20241230212623555-2024-12-3021_26_29.png" srcset="/img/loading.gif" lazyload alt="image-20241230212623555"><figcaption aria-hidden="true">image-20241230212623555</figcaption></figure><p>我们向该其中添加一个数字：50000，这个数字超出了<code>INTSET_ENC_INT16</code>的范围，intset 会自动<strong>升级</strong>编码方式到合适的大小。 以当前案例来说流程如下：</p><ul><li>升级编码为 INTSET_ENC_INT32, 每个整数占 4 字节，并按照新的编码方式及元素个数扩容数组</li><li><strong>倒序</strong>依次将数组中的元素拷贝到扩容后的正确位置（这样向后移动元素时不会覆盖还未处理的元素）</li><li>将待添加的元素放入数组末尾</li><li>最后，将 inset 的 encoding 属性改为 INTSET_ENC_INT32，将 length 属性改为 4</li></ul><p><img src="http://img.catpaws.top/img/image-20241230213128501-2024-12-3021_31_30.png" srcset="/img/loading.gif" lazyload alt="image-20241230213128501" style="zoom:80%"></p><p>源码分析：</p><figure><img src="http://img.catpaws.top/img/image-20241230215915090-2024-12-3021_59_16.png" srcset="/img/loading.gif" lazyload alt="intsetAdd"><figcaption aria-hidden="true">intsetAdd</figcaption></figure><figure><img src="http://img.catpaws.top/img/image-20241230215809558-2024-12-3021_58_20.png" srcset="/img/loading.gif" lazyload alt="intsetUpgradeAndAdd"><figcaption aria-hidden="true">intsetUpgradeAndAdd</figcaption></figure><h3 id="dict">1.3、Dict</h3><h4 id="dict-的结构">Dict 的结构</h4><p>Redis 是一个键值型（Key-Value Pair）的数据库，可以根据键实现快速的增删改查。而键与值的映射关系正是通过 Dict 来实现的。</p><p>Dict 由三部分组成，分别是：<strong>哈希表（DictHashTable）</strong>、<strong>哈希节点（DictEntry）</strong>、<strong>字典（Dict）</strong></p><p>1、哈希结点（DictEntry）</p><p>包含一对 key:value 和指向下一个 Entry 的指针。</p><figure><img src="http://img.catpaws.top/img/image-20241230223826657-2024-12-3022_38_28.png" srcset="/img/loading.gif" lazyload alt="DictEntry的数据结构"><figcaption aria-hidden="true">DictEntry的数据结构</figcaption></figure><p>​ <img src="http://img.catpaws.top/img/image-20241230224000025-2024-12-3022_40_02.png" srcset="/img/loading.gif" lazyload alt="DictEntry的图示"></p><p>2、哈希表（DictHashTable）</p><figure><img src="http://img.catpaws.top/img/image-20241230224110016-2024-12-3022_41_11.png" srcset="/img/loading.gif" lazyload alt="DictHashTable的数据结构"><figcaption aria-hidden="true">DictHashTable的数据结构</figcaption></figure><p>哈希表实际上就是一个数组，其中：</p><ul><li><code>dictEntry **table</code>是一个<code>DictEntry</code>类型的数组指针，而数组内保存的是指向一个个<code>DictEntry</code>对象的指针。</li><li><code>size</code>：哈希表数组的大小。总是 <span class="math inline">\(\color{red}2^n\)</span>，<strong>默认为 4</strong>。</li><li><code>siezmask</code>：哈希表大小的掩码，总等于<span class="math inline">\(\color{red}size -1\)</span></li><li><code>used</code>：哈希表数组中已存在的 entry 的个数</li></ul><p>当我们向 Dict 添加键值对时，Redis 首先根据 key 计算出 hash 值（h），然后利用<code>h &amp; sizemask</code>来计算元素应该存储到数组中的哪个索引位置。</p><blockquote><p><code>h &amp; sizemask</code>就相当于 <code>h % size</code>。由于 size 总是<span class="math inline">\(2^n\)</span>，则它的余数就是 1 之后的那些位组成的数字，而 sizemask = size -1，<code>h &amp; sizemask</code>就将余数部分保留下来了，相当于完成了取余操作。如：</p><figure><img src="http://img.catpaws.top/img/image-20241230225659603-2024-12-3022_57_01.png" srcset="/img/loading.gif" lazyload alt="image-20241230225659603"><figcaption aria-hidden="true">image-20241230225659603</figcaption></figure><p><strong>因此，size 必须始终为<span class="math inline">\(2^n\)</span>,sizemask 才能保证对应 size 余数部分的二进制都为 1，与 hash 值做与运算后才能得到余数，即新元素在哈希表中的索引位置。</strong></p></blockquote><p>例如：存储 k1=v1，假设 k1 的哈希值 h =1，则 1&amp;3 =1，因此 k1=v1 要存储到数组角标 1 位置。此时，再次插入的新的键值 k2=v2 经过 hash 运算，也要存储到数组下标 1 的位置，会产生<strong>哈希冲突</strong>。Redis 解决冲突的方式是<strong>拉链法</strong>，将同义词通过链表连接起来，每次将新的同义词插入链表<strong>头部</strong>即可（若加到队尾，需要进行遍历）。</p><figure><img src="http://img.catpaws.top/img/image-20241230230514385-2024-12-3023_05_16.png" srcset="/img/loading.gif" lazyload alt="image-20241230230514385"><figcaption aria-hidden="true">image-20241230230514385</figcaption></figure><p>3、字典（Dict）</p><figure><img src="http://img.catpaws.top/img/image-20241230230632158-2024-12-3023_06_34.png" srcset="/img/loading.gif" lazyload alt="image-20241230230632158"><figcaption aria-hidden="true">image-20241230230632158</figcaption></figure><p>其中：</p><ul><li><code>type</code>和<code>privdata</code>都是用来做哈希运算的</li><li><code>dictht ht[2]</code>: 一个 Dict 包含两个哈希表，其中<code>ht[0]</code>保存当前数据；<code>ht[1]</code>一般是空，<strong>rehash</strong>时使用</li><li><code>rehashidx</code>：rehash 的进度，-1 表示未进行。<strong>Dict 的 rehash 并不是一次性完成的，而是分多次、渐进式的完成。</strong>rehash 开始时设置为 0，在每次执行新增、查询、修改、删除操作时，执行一次 rehash，将<code>ht[0]</code> 中<code>rehashindex</code>对应下标的链表迁移到<code>ht[1]</code>，并且<code>rehashindex++</code>，直至<code>ht[0]</code>的所有数据都 rehash 到<code>ht[1]</code></li><li><code>pauserehash</code>：rehash 是否暂停，1 则暂停，0 则继续</li></ul><figure><img src="http://img.catpaws.top/img/image-20241230232051927-2024-12-3023_20_54.png" srcset="/img/loading.gif" lazyload alt="Dict的结构"><figcaption aria-hidden="true">Dict的结构</figcaption></figure><h4 id="dict-的扩容">Dict 的扩容</h4><p>Dict 中的 HashTable 就是数组结合单向链表的实现，当集合中元素较多时，必然导致哈希冲突增多，链表过长，则查询效率会大大降低。</p><p>Dict 在每次<strong>新增</strong>键值对时都会检查负载因子（<code>LoadFactor = used/size</code>） ，满足以下两种情况时会触发哈希表扩容：</p><ul><li>哈希表的 LoadFactor &gt;= 1，并且服务器没有执行 BGSAVE 或者 BGREWRITEAOF 等后台进程；</li><li>哈希表的 LoadFactor &gt; 5 ；</li></ul><figure><img src="http://img.catpaws.top/img/image-20241230233412969-2024-12-3023_34_15.png" srcset="/img/loading.gif" lazyload alt="HashTable扩容"><figcaption aria-hidden="true">HashTable扩容</figcaption></figure><h4 id="dict-的收缩">Dict 的收缩</h4><p>Dict 除了扩容以外，每次<strong>删除</strong>元素时，也会对负载因子做检查，当<code>LoadFactor</code> &lt; 0.1 时，会做哈希表收缩：</p><figure><img src="http://img.catpaws.top/img/image-20241231000236670-2024-12-3100_02_39.png" srcset="/img/loading.gif" lazyload alt="HashTable收缩逻辑"><figcaption aria-hidden="true">HashTable收缩逻辑</figcaption></figure><p>Dict 的扩容和收缩都会调用<code>dictExpand</code>方法，其源码如下：</p><figure><img src="http://img.catpaws.top/img/image-20241230235746690-2024-12-3023_57_49.png" srcset="/img/loading.gif" lazyload alt="image-20241230235746690"><figcaption aria-hidden="true">image-20241230235746690</figcaption></figure><h4 id="dict-的-rehash">Dict 的 rehash</h4><p>不管是扩容还是收缩，必定会创建新的哈希表，导致哈希表的 size 和 sizemask 变化，而 key 的查询与 sizemask 有关。因此<strong>必须对哈希表中的每一个 key 重新计算索引，插入新的哈希表，这个过程称为 rehash</strong>。但是 rehash 是在执行增删操作时判断是否要执行 rehash，而这些操作是在 Redis 的主进程中进行的，若一次迁移太多的 entry 会导致主进程阻塞，直至完成 rehash 后才能处理新命令。</p><p>因此，Dict 的 rehash 并不是一次性完成的。<strong>Dict 的 rehash 是分多次、渐进式的完成</strong>，因此称为<strong>渐进式 rehash</strong>。流程如下：</p><ol type="1"><li><p>计算新 hash 表的 realeSize，值取决于当前要做的是扩容还是收缩：</p><ul><li>如果是扩容，则新 size 为第一个大于等于 dict.ht[0].used + 1 的 <span class="math inline">\(2^n\)</span></li><li>如果是收缩，则新 size 为第一个大于等于 dict.ht[0].used 的 <span class="math inline">\(2^n\)</span>（不得小于 4）</li></ul></li><li><p>按照新的 realeSize 申请内存空间，创建 dictht，并赋值给 dict.ht[1]</p></li><li><p>设置 dict.rehashidx = 0，标示开始 rehash</p></li><li><p>每次执行新增、查询、修改、删除操作时，都检查一下 dict.rehashidx 是否大于-1，如果是则将 dict.ht[0].table[rehashidx]的 entryl 链表 rehash 到 dict.ht[1]，并且将 rehashidx++。直至 dict.ht[0]的所有数据都 rehash 到 dict.ht[1]</p><blockquote><p>即每次执行新增、查询、修改、删除操作时，都将 ht[0]中<code>rehashindex</code>所指下标的链表迁移到 ht[1]，每次只迁移一条链表的数据，并且<code>rehashindex++</code>，直至将 ht[0]中的数据都迁移到 ht[1]</p></blockquote></li><li><p>将 dict.ht[1]赋值给 dict.ht[0]，给 dict.ht[1]初始化为空哈希表，释放原来的 dict.ht[0]的内存</p></li><li><p>将 rehashidx 赋值为-1，代表 rehash 结束</p></li><li><p>在 rehash 过程中，<strong>新增操作，则直接写入 ht[1]</strong>，<strong>查询、修改和删除则会在 dict.ht[0]和 dict.ht[1]依次查找并执行</strong>。这样可以确保 ht[0]的数据只减不增，随着 rehash 最终为空。</p></li></ol><h3 id="ziplist">1.4、ZipList</h3><p>Dict 是由数组+单链表实现的，其数据存储在不连续的存储单元中，使用指针相互关联，这种方式存在的主要问题是内存的浪费，容易产生内存碎片，并且每个指针本身还要占据一定的字节空间。</p><p>ziplist 是一种压缩存储结构，用于存储字符串或整数。它通过一系列特殊编码的<strong>连续内存块</strong>来存储数据，以减少内存使用。由于其设计结构，ZipList 可以看作特殊“双端链表” ，它没有使用指针记录前后结点的地址，而是通过<strong>记录结点长度</strong>来推算出前后结点的位置，它可以在任意一端进行压入/弹出操作, 并且该操作的时间复杂度为 O(1)。</p><h4 id="ziplist-的结构">ZipList 的结构</h4><figure><img src="http://img.catpaws.top/img/image-20241231115108381-2024-12-3111_51_09.png" srcset="/img/loading.gif" lazyload alt="ZipList结构"><figcaption aria-hidden="true">ZipList结构</figcaption></figure><p>ZipList 主要包含四部分数据，分别是</p><ul><li><code>zlbytes</code> ：类型<code>uint32_t</code>，长度 4 字节，<strong>记录整个压缩列表占用的内存字节数</strong></li><li><code>zltail</code>：类型<code>uint32_t</code>，长度 4 字节<strong>，记录压缩列表表尾节点距离压缩列表的起始地址有多少字节</strong>，通过这个偏移量，可以确定表尾节点的地址。</li><li><code>zllen</code>：类型<code>uint16_t</code>，长度 2 字节，<strong>记录了压缩列表包含的节点数量</strong>。最大值为 UINT16-MAX（65534），如果超过这个值，此处会记录为 65535，但节点的真实数量需要遍历整个压缩列表才能计算得出。</li><li><code>entry</code>：压缩列表包含的各个节点，节点的长度由节点保存的内容决定，长度不定</li><li><code>zlend</code>：类型<code>uint8_t</code>，长度 1 字节，特殊值 OxFF（十进制 255），<strong>用于标记压缩列表的末端。</strong></li></ul><h4 id="entry-的结构">Entry 的结构</h4><p>ZipList 中的 Entry 并不像普通链表那样记录前后节点的指针，因为记录两个指针要占用 16 个字节，浪费内存。而是采用了下面的结构：</p><p><img src="http://img.catpaws.top/img/image-20241231115851490-2024-12-3111_58_54.png" srcset="/img/loading.gif" lazyload alt="ZipList entry的结构" style="zoom:80%"></p><ul><li><code>previous_entry_length</code>：前一节点的长度，占 1 个或 5 个字节。<ul><li>如果前一节点的长度小于 254 字节，则采用 1 个字节来保存这个长度值</li><li>如果前一节点的长度大于 254 字节，则采用 5 个字节来保存这个长度值，第一个字节为 0xfe，后四个字节才是真实长度数据</li></ul></li><li><code>encoding</code>：编码属性，记录<strong>content 的数据类型</strong>（字符串还是整数）以及<strong>长度</strong>，占用 1 个、2 个或 5 个字节</li><li><code>contents</code>：负责保存节点的数据，可以是字符串或整数</li></ul><blockquote><p>要获得下一节点的地址。只需用当前节点的地址 + entry 的长度即可</p><p>要获得前一结点的地址，只需用当前节点的地址 - <code>previous_entry_length</code>即可</p><p>ZipList 中所有存储长度的数值均采用<strong>小端存储</strong>，即先存储低字节，低地址存低字节，高地址存高字节。例如：数值 0x1234，采用小端字节序后实际存储值为：0x3412</p><p><strong>如果列表数据过多，导致链表过长，查询中间的某个数据时要经过多次计算寻址，可能影响查询性能</strong></p></blockquote><h4 id="entry-的-encoding-编码">Entry 的 Encoding 编码</h4><p>ZipListEntry 中的 encoding 编码分为字符串和整数两种：</p><p><strong>字符串</strong>：如果 encoding 是以“00”、“01”或者“10”开头，则证明 content 是字符串</p><figure><img src="http://img.catpaws.top/img/image-20241231195137157-2024-12-3119_52_06.png" srcset="/img/loading.gif" lazyload alt="image-20241231195137157"><figcaption aria-hidden="true">image-20241231195137157</figcaption></figure><p>例如，我们要保存字符串：“ab”和 “bc”。ZipList 中第一个 Entry 保存的是"ab"，其中<code>previous_entry_length</code> = 0，"ab"的占两个字节，<code>encoding</code> = 00000010，a 和 b 的 ASCII 码分别为 61 和 62，故存储"ab"的 Entry 内容如下，左侧为十六进制存储。存储“bc”的 Entry 内容同理可得。</p><figure><img src="http://img.catpaws.top/img/image-20241231195950607-2024-12-3120_00_06.png" srcset="/img/loading.gif" lazyload alt="ab的Entry内容"><figcaption aria-hidden="true">ab的Entry内容</figcaption></figure><p>整个 ZIPList 的内容如下：</p><figure><img src="http://img.catpaws.top/img/image-20241231200702856-2024-12-3120_07_06.png" srcset="/img/loading.gif" lazyload alt="image-20241231200702856"><figcaption aria-hidden="true">image-20241231200702856</figcaption></figure><p><strong>整数</strong>：如果 encoding 是以“11”开始，则证明 content 是整数，且 encoding 固定只占用 1 个字节</p><figure><img src="http://img.catpaws.top/img/image-20241231201103448-2024-12-3120_11_06.png" srcset="/img/loading.gif" lazyload alt="image-20241231201103448"><figcaption aria-hidden="true">image-20241231201103448</figcaption></figure><p>整数的编码通常只有<code>byte</code>、<code>short</code>、<code>int</code>、<code>long</code>，对应的数据分别为 1、2、4、8 个字节，用两位编码即可区分，故除了最高位的 11 用来表示整数，之后的两位用来表示是哪种编码。Redis 中多了一种 3 字节的整数，所以多用了一种编码表示该类型。</p><p>对于一些比较小的数字，如 1,3,8 等，用一个字节表示还是有点浪费，Redis 直接把这些小数字的值保存在类型编码里，范围是 0001 - 1101（低四位的 0000 和 1110 都被使用了，为了不和编码产生冲突，只能存储这个范围内的数字），减一后结果为实际值，即 0001 表示 0,0010 表示 1。</p><p>例如，一个 ZipList 中包含两个整数值："2"和"5"，其 Entry 结构和整个 ZipList 结构如下：</p><figure><img src="http://img.catpaws.top/img/image-20241231202638438-2024-12-3120_26_56.png" srcset="/img/loading.gif" lazyload alt="整数2和5的Entry结构"><figcaption aria-hidden="true">整数2和5的Entry结构</figcaption></figure><figure><img src="http://img.catpaws.top/img/image-20241231202829878-2024-12-3120_28_30.png" srcset="/img/loading.gif" lazyload alt="整个ZipList的结构"><figcaption aria-hidden="true">整个ZipList的结构</figcaption></figure><h4 id="ziplist-的连锁更新问题">ZipList 的连锁更新问题</h4><p>ZipList 的每个 Entry 都包含<code>previous_entry_length</code>字段来记录上一个节点的大小。这个字段的长度是 1 个或 5 个字节：</p><ul><li>如果前一节点的长度小于 254 字节，则采用 1 个字节来保存这个长度值。</li><li>如果前一节点的长度大于等于 254 字节，则采用 5 个字节来保存这个长度值，其中第一个字节为 0xfe，后四个字节才是真实长度数据。</li></ul><p>当在 ZipList 中插入、删除或修改数据时，如果新元素的长度改变了相邻元素的<code>previous_entry_length</code>字段的值（例如，从 1 个字节变为 5 个字节），那么就需要更新这个字段。更糟糕的是，这个更新可能会触发后续元素的连续更新，因为后续元素的<code>previous_entry_length</code>字段也可能需要调整以反映新的前一个元素的大小。这种连续多次的空间扩展操作就被称为<strong>连锁更新。</strong></p><p>例如：有 N 个连续的、长度为 250-253 字节之间的 entry，因此 entry 的 previous_entry_length 属性用 1 个字节即可表示，如图所示：</p><figure><img src="http://img.catpaws.top/img/image-20241231204258567-2024-12-3120_42_59.png" srcset="/img/loading.gif" lazyload alt="image-20241231204258567"><figcaption aria-hidden="true">image-20241231204258567</figcaption></figure><p>若此时，在表头插入一个长度为 254 字节的 entry，原来表头 entry 的<code>previous_entry_length</code>就要从 1 个字节变为 5 个字节，那么这个 entry 的长度就变成 254 字节。原来第二个 entry 为了记录前面 entry 的长度，它的<code>previous_entry_length</code>也要从 1 个字节变为 5 个字节，它的长度也变成 254 字节，又会引起后面一个 entry 的<code>previous_entry_length</code>变大......</p><figure><img src="http://img.catpaws.top/img/image-20241231204815306-2024-12-3120_48_16.png" srcset="/img/loading.gif" lazyload alt="image-20241231204815306"><figcaption aria-hidden="true">image-20241231204815306</figcaption></figure><blockquote><p>由于 ZipList 的 entry 是连续存储，<code>previous_entry_length</code>要从 1 个字节变为 5 个字节，需要将之后的数据整体向后迁移，若空间不足还要申请新的空间，对性能影响较大。但这种情况<strong>发生概率是极低</strong>的，连锁更新通常发生在特定的条件下。</p></blockquote><p>为了缓解 ZipList 的连锁更新问题，可以采取以下几种解决方案：</p><ol type="1"><li><p>‌<strong>限制 ZipList 的长度和 Entry 大小</strong>‌：</p><p>通过配置 Redis 的相关参数（如<code>hash-max-ziplist-entries</code>、<code>hash-max-ziplist-value</code>、<code>zset-max-ziplist-entries</code>、<code>zset-max-ziplist-value</code>等），限制 ZipList 的长度和 Entry 的大小。当数据超过这些限制时，Redis 会自动将 ZipList 转换为其他数据结构（如 Hash、SkipList+Dict）来存储。</p></li><li><p>‌<strong>使用多个 ZipList 分片存储数据</strong>‌：</p><p>如果需要存储大量数据，可以考虑将数据分片存储到多个 ZipList 中。这样，每个 ZipList 的大小都会受到限制，从而减少了连锁更新发生的可能性。</p></li><li><p>‌<strong>升级 Redis 版本</strong>‌：</p><p>在 Redis 5 版本中，引入了 ZipList 的替代版本 ListPack。ListPack 移除了<code>prevlen</code>字段，采用了不同的结构来存储数据，从而避免了连锁更新的问题。如果可能的话，可以考虑升级到支持 ListPack 的 Redis 版本。</p><blockquote><p>为了解决 ziplist 的连锁更新问题，Redis 引入了 listpack 结构。Listpack 同样采用了紧凑的内存布局，但<strong>它摒弃了 ziplist 中的 prevlen 字段，改为让每个元素只记录自己的长度信息。这样，当修改某个元素时，就不会影响到其他元素，从而避免了连锁更新的发生。</strong></p></blockquote><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_51504545/article/details/126078789">ListPack 参考文章</a></p></li></ol><h3 id="quicklist">1.5、QuickList</h3><p>ZipList 虽然节省内存，但申请内存必须是连续空间，如果内存占用较多，申请内存效率很低。怎么办？</p><p>为了缓解这个问题，我们必须限制 ZipList 的长度和 entry 大小。</p><p>但是我们要存储大量数据，超出了 ZipList 最佳的上限该怎么办？</p><p>我们可以创建多个 ZipList 来分片存储数据。</p><p>数据拆分后比较分散，不方便管理和查找，这多个 ZipList 如何建立联系？</p><p>Redis 在 3.2 版本引入了新的数据结构<strong>Quicklist</strong>，<strong>它是一个双端链表，只不过链表中的每个节点都是一个 ZipList</strong>。它结合了 ziplist 和双向链表的优点，旨在提供高效的内存利用率和快速的插入、删除操作。其结构如下：</p><figure><img src="http://img.catpaws.top/img/image-20250101104308576-2025-1-110_43_25.png" srcset="/img/loading.gif" lazyload alt="QuickList结构"><figcaption aria-hidden="true">QuickList结构</figcaption></figure><p>为了避免 QuickList 中的每个 ZipList 中 entry 过多，Redis 提供了一个配置项：<code>list-max-ziplist-size</code>来限制。</p><p>如果值为正，则代表 ZipList 的允许的<strong>entry 个数的最大值</strong></p><p>如果值为负，则代表<strong>ZipList 的最大内存大小</strong>，分 5 种情况：</p><ul><li>-1：每个 ZipList 的内存占用不能超过 4kb</li><li>-2：每个 ZipList 的内存占用不能超过 8kb</li><li>-3：每个 ZipList 的内存占用不能超过 16kb4</li><li>-4：每个 ZipList 的内存占用不能超过 32kb</li><li>-5：每个 ZipList 的内存占用不能超过 64kb</li></ul><p>其默认值为：-2</p><p><img src="http://img.catpaws.top/img/image-20250101104658228-2025-1-110_47_00.png" srcset="/img/loading.gif" lazyload alt="list-max-ziplist-size的默认值" style="zoom:80%"></p><p>除了控制 ZipList 的大小，QuickList 还可以对节点的 ZipList 做压缩。通过配置项<code>list-compress-depth</code>来控制。因为链表一般都是从首尾访问较多，所以首尾是不压缩的。这个参数是控制<strong>首尾不压缩的节点个数</strong>：</p><ul><li>0：特殊值，代表不压缩</li><li>1：标示 QuickList 的首尾各有 1 个节点不压缩，中间节点压缩</li><li>2：标示 QuickList 的首尾各有 2 个节点不压缩，中间节点压缩</li><li>以此类推</li></ul><p>默认值为 0，默认不进行压缩</p><p><img src="http://img.catpaws.top/img/image-20250101104919212-2025-1-110_49_20.png" srcset="/img/loading.gif" lazyload alt="list-compress-depth的默认值" style="zoom:80%"></p><p>源码分析：</p><p>以下是 QuickList 的和 QuickListNode 的结构源码，及内存结构图</p><figure><img src="http://img.catpaws.top/img/image-20250101105404993-2025-1-110_54_06.png" srcset="/img/loading.gif" lazyload alt="image-20250101105404993"><figcaption aria-hidden="true">image-20250101105404993</figcaption></figure><figure><img src="http://img.catpaws.top/img/image-20250101105543536-2025-1-110_55_45.png" srcset="/img/loading.gif" lazyload alt="image-20250101105543536"><figcaption aria-hidden="true">image-20250101105543536</figcaption></figure><p>QuickList 的优势主要体现在以下几个方面：</p><ul><li>‌<strong>内存占用低</strong>‌：通过结合 ziplist 和双向链表的优点，QuickList 进一步压缩了内存的使用量。</li><li>‌<strong>操作速度快</strong>‌：QuickList 提供了高效的遍历算法和快速的插入、删除操作。</li><li>‌<strong>灵活性高</strong>‌：QuickList 可以根据实际情况动态调整节点的大小和数量，以适应不同的应用场景。</li></ul><blockquote><p>当向 QuickList 中插入一个元素时，Redis 会根据一定的策略选择一个合适的 quicklistNode，并将元素插入到该节点中。如果插入操作导致 quicklistNode 中的元素数量超过了一定的阈值（由 list-max-ziplist-size 参数决定），Redis 会将该节点拆分成两个节点。同样，如果删除操作导致 quicklistNode 中的元素数量过少，Redis 会将相邻的两个节点合并成一个节点。</p></blockquote><p>从 Redis 3.2 版本开始，list 数据结构就使用了 QuickList 来代替之前的压缩列表（ziplist）和链表（linkedlist）。因此，当使用 Redis 的 list 命令（如 lpush、rpush、lpop、rpop 等）时，实际上就是在操作 QuickList。</p><p>总结：QuickList 是一个节点为 ZipList 的双端链表，节点采用 ZipList，解决了传统链表的内存占用问题；控制了 ZipList 大小，解决连续内存空间申请效率问题；中间节点可以压缩，进一步节省了内存。</p><h3 id="skiplist">1.6、SkipList</h3><p>SkipList 是为了解决有序集合的高效查找、插入和删除操作而设计的。它结合了平衡树和链表的优点，既保持了数据的有序性，又提供了快速的访问速度。主要用于实现 Redis 中的有序集合（Sorted Set）</p><p><strong>SkipList（跳表）</strong>首先是链表，但与传统链表相比有几点差异：</p><ul><li><p>元素按照升序排列存储</p></li><li><p>节点可能<strong>包含多个指针，指针跨度不同</strong>。</p><figure><img src="http://img.catpaws.top/img/image-20250101112809753-2025-1-111_28_10.png" srcset="/img/loading.gif" lazyload alt="image-20250101112809753"><figcaption aria-hidden="true">image-20250101112809753</figcaption></figure></li></ul><p>其结构定义如下：</p><figure><img src="http://img.catpaws.top/img/image-20250101112015649-2025-1-111_20_34.png" srcset="/img/loading.gif" lazyload alt="SkipList的结构定义"><figcaption aria-hidden="true">SkipList的结构定义</figcaption></figure><p>SkipList 本身的定义中包含头尾节点指针，链表中结点的数量和最大的索引层级，默认是 1。</p><p>SkipList 结点的定义中包括：</p><ul><li>结点的值，类型是动态字符串；</li><li>结点的分数，<strong>按分数对结点升序排列存储</strong>，用于排序和查找；</li><li>前一个结点的指针</li><li>多级索引数组，每个结点中包含的指针数量不确定，首节点的最多，中间节点的较少，故用数组保存。这些指针分布在不同的层级上，用于实现多级索引。每个索引包括指向下一节点的指针和该指针的跨度</li></ul><figure><img src="http://img.catpaws.top/img/image-20250101113225469-2025-1-111_32_26.png" srcset="/img/loading.gif" lazyload alt="SkipList内存结构"><figcaption aria-hidden="true">SkipList内存结构</figcaption></figure><p><strong>查找操作</strong>‌：</p><ul><li>从最高层开始，通过前进指针逐层向下查找。</li><li>如果当前节点的下一个节点的值小于要查找的值，则向右移动；如果大于要查找的值，则向下移动。</li><li>重复上述过程，直到找到目标节点或确定目标节点不存在。</li></ul><p>‌<strong>插入操作</strong>‌：</p><ul><li><p>首先进行查找操作，找到插入位置。</p></li><li><p>随机生成一个层数，根据这个层数在每一层插入新节点。</p><blockquote><p>SkipList 的一个关键特性是它允许节点在不同的层级上存在。为了确定新节点的层级，通常会使用一个概率模型来随机选择。例如，可以设置一个预设值 p（通常是一个小于 1 的常数），然后生成一个 0 到 1 之间的随机数。如果这个随机数小于 p，就将节点的层数加 1，直到达到一个预设的最大层数或者随机数不再小于 p 为止。这个过程确保了节点层级的随机性，从而有助于保持 SkipList 的平衡性。</p></blockquote></li><li><p>更新相关节点的前进指针和跨度。</p></li></ul><p><strong>删除操作</strong>‌：</p><ul><li>首先进行查找操作，找到要删除的节点。</li><li>然后在每一层删除这个节点，并调整相关节点的前进指针和跨度。</li></ul><h3 id="redisobject">1.7、RedisObject</h3><p>RedisObject 是 Redis 中表示数据对象的结构体，它是 Redis 数据库中的基本数据类型的抽象。在 Redis 中，<strong>所有的数据都被存储为 RedisObject 类型的对象</strong>。</p><p>RedisObject 结构体中包含了多个字段，用于表示对象的类型、编码方式、引用计数、最近访问时间以及指向实际存储数据的指针等信息。</p><div class="code-wrapper"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">redisObject</span> &#123;</span>
    <span class="hljs-type">unsigned</span> type:<span class="hljs-number">4</span>;       <span class="hljs-comment">// 数据类型，如字符串、列表、哈希等</span>
    <span class="hljs-type">unsigned</span> encoding:<span class="hljs-number">4</span>;   <span class="hljs-comment">// 编码方式，如int、raw、hashtable等</span>
    <span class="hljs-type">unsigned</span> lru:LRU_BITS; <span class="hljs-comment">// Least Recently Used，用于记录对象最近被访问的时间</span>
    <span class="hljs-type">int</span> refcount;          <span class="hljs-comment">// 引用计数，用于自动内存管理</span>
    <span class="hljs-type">void</span> *ptr;             <span class="hljs-comment">// 指向实际存储数据的指针</span>
&#125; robj;</code></pre></div><ul><li><p>‌<strong>type</strong>‌：表示数据对象的类型，用 4 位表示，对应着 Redis 的几种基本数据类型，分别是 string、hash、list、set 和 zset。</p><blockquote><p>#define OBJ_STRING 0 #define OBJ_LIST 1 #define OBJ_SET 2 #define OBJ_ZSET 3 #define OBJ_HASH 4</p></blockquote></li><li><p>‌<strong>encoding</strong>‌：底层编码方式，共有 11 种，占 4 个 bit 位，不同的编码方式对应不同的存储结构。</p></li><li><p>‌<strong>lru</strong>‌：记录对象最近被访问的时间，占用 24 个 bit 位，用于实现 LRU（Least Recently Used）策略，即最近最少使用策略，用于内存淘汰。</p></li><li><p>‌<strong>refcount</strong>‌：对象引用计数器，，用于自动内存管理。当引用计数为 0 时，表示对象可以被释放。Redis 通过引用计数来管理内存，避免内存泄漏。</p></li><li><p>‌<strong>ptr</strong>‌：指向实际存储数据的指针，根据不同的数据类型和编码方式，指向不同的数据结构。</p></li></ul><blockquote><p>一个 RedisObject 的头信息所占用的空间是 16 字节。若有 n 个字符串要存储，每个字符串都选用 String 类型存储，每个都需要一个 RedisObject 头，会造成大量空间浪费在头信息的存储。若使用 List 等集合类型存储这些字符串，只需一个 RedisObject 头就可以完成。</p><p>因此，当有大量数据存储时，尽量选择集合类型进行存储，避免内存浪费。</p></blockquote><p>Redis 中会根据存储的数据类型不同，选择不同的编码方式，共包含 11 种不同类型：</p><figure><img src="http://img.catpaws.top/img/image-20250101120941750-2025-1-112_09_43.png" srcset="/img/loading.gif" lazyload alt="11种编码类型"><figcaption aria-hidden="true">11种编码类型</figcaption></figure><p>每种数据类型的使用的编码方式如下：</p><figure><img src="http://img.catpaws.top/img/image-20250101121049469-2025-1-112_10_50.png" srcset="/img/loading.gif" lazyload alt="image-20250101121049469"><figcaption aria-hidden="true">image-20250101121049469</figcaption></figure><p>RedisObject 的作用：</p><ul><li>‌<strong>统一对象管理</strong>‌：RedisObject 为 Redis 中的各种数据类型提供了一个统一的接口，使得 Redis 能够以一致的方式处理不同类型的数据。</li><li>‌<strong>内存优化</strong>‌：通过引用计数和 LRU 机制，RedisObject 实现了自动内存管理和淘汰策略，有效地节省了内存空间，提高了内存利用率。</li><li>‌<strong>操作一致性</strong>‌：RedisObject 为不同类型的数据提供了统一的操作接口，如获取对象类型、编码方式、值等，保证了操作的一致性。</li></ul><p>Redis 底层数据结构包括 SDS（简单动态字符串）、IntSet（整数集合）、Dict（字典）、ZipList（压缩列表）、QuickList（快速列表）、SkipList（跳跃表）等。这些数据结构被广泛应用于 Redis 的各种功能模块中，如字符串、哈希、列表、集合、有序集合等。</p><p>RedisObject 与这些底层数据结构的关系是：RedisObject 是对这些底层数据结构的抽象和封装。RedisObject 的<code>ptr</code>字段指向实际存储数据的指针，这个数据结构由<code>type</code>和<code>encoding</code>属性决定。例如，如果一个 RedisObject 的<code>type</code>属性为<code>OBJ_LIST</code>，<code>encoding</code>属性为<code>OBJ_ENCODING_QUICKLIST</code>，那么这个对象就是一个 Redis 列表（List），它的值保存在一个 QuickList 的数据结构内，而<code>ptr</code>指针就指向 QuickList 的对象。</p><h3 id="五种不同的数据类型">1.8、五种不同的数据类型</h3><h4 id="string">String</h4><p>String 是 Redis 中最常见的数据存储类型，基于<strong>简单动态字符串（SDS）</strong>实现。String 类型的底层编码方式有三种，分别是<code>raw</code>、<code>embstr</code>和<code>int</code>。</p><ul><li><p>当存储的字符串长度超过 44 字节时，会采用<code>raw</code>编码方式。，存储上限为 512mb。</p><p>RedisObject 对象头和 SDS 对象在内存地址不是连续的，需要分配两次内存，性能较差。</p><figure><img src="http://img.catpaws.top/img/image-20250101155622345-2025-1-115_56_28.png" srcset="/img/loading.gif" lazyload alt="raw类型编码"><figcaption aria-hidden="true">raw类型编码</figcaption></figure></li><li><p>当存储的字符串长度小于等于<strong>44 字节</strong>时，Redis 使用<code>embstr</code>编码。在 embstr 编码中，RedisObject 对象头和 SDS（Simple Dynamic String）对象在内存中地址是连在一起的，申请内存时只需要调用一次内存分配函数，操作字符串时不用做额外的寻址操作，效率较高。</p><figure><img src="http://img.catpaws.top/img/image-20250101165235446-2025-1-116_52_36.png" srcset="/img/loading.gif" lazyload alt="embstr编码"><figcaption aria-hidden="true">embstr编码</figcaption></figure><blockquote><p>为什么是 44 字节？SDS 的头信息中<code>len</code>、<code>alloc</code>、<code>flags</code>各占一字节，字符结束符<code>\0</code>占一字节，字符串内容 44 字节，整个 SDS 共占 48 字节，RedisObject 头信息共占 16 字节，加起来是 64 字节。<strong>Redis 中，jemalloc 是默认的内存分配器</strong>，Jemalloc 会为不同大小的内存请求分配固定大小的块（这些块的大小通常是 2 的幂次），在分配内存时会尽量满足内存对齐的要求，以减少由于频繁的内存分配和释放操作导致的内存碎片。64 字节刚好是 Jemalloc 的一个内存分配单位，能把这些数据存储在一个连续的内存块中而不产生内存碎片。</p></blockquote></li><li><p>当存储的字符串是整数值，并且大小在 LONG_MAX 范围内，则会采用<code>INT</code>编码：<strong>直接将数据保存在 RedisObject 的 ptr 指针位置，不再需要 SDS 了</strong>。</p><figure><img src="http://img.catpaws.top/img/image-20250101172324620-2025-1-117_23_25.png" srcset="/img/loading.gif" lazyload alt="image-20250101172324620"><figcaption aria-hidden="true">image-20250101172324620</figcaption></figure><blockquote><p>一个指针占 8 字节，而不论 Java 还是 C 中的整数最多占 8 个字节，因此刚好可以用 ptr 指针的内存空间存储整数值</p></blockquote></li></ul><h4 id="list">List</h4><p>Redis 的 List 类型可以从首、尾操作列表中的元素。哪一个数据结构能满足上述特征？</p><ul><li>LinkedList：普通链表，可以从双端访问，内存占用较高，内存碎片较多</li><li>ZipList：压缩列表，可以从双端访问，内存占用低，存储上限低</li><li>QuickList：LinkedList + ZipList，可以从双端访问，内存占用较低，包含多个 ZipList，存储上限高</li></ul><p>在 3.2 版本之前，Redis 采用 ZipList 和 LinkedList 来实现 List，当元素数量小于 512 并且元素大小小于 64 字节时采用 ZipList 编码，超过则采用 LinkedList 编码。</p><p>在 3.2 版本之后，Redis 统一采用<strong>QuickList</strong>来实现 List</p><figure><img src="http://img.catpaws.top/img/image-20250101185826611-2025-1-118_58_34.png" srcset="/img/loading.gif" lazyload alt="List结构"><figcaption aria-hidden="true">List结构</figcaption></figure><h4 id="set">Set</h4><p>Set 是 Redis 中的单列集合，满足下列特点：</p><ul><li>不保证有序性</li><li>保证元素唯一（可以判断元素是否存在）</li><li>求交集、并集、差集</li></ul><p>由于 Set 要保证集合中元素唯一，在很多操作中都要判断一个元素是否已经存在，如插入时需判断元素是否存在，求交集时要找出两个集合都存在的元素等等。可以看出，<strong>Set 对查询元素的效率要求非常高</strong>。</p><p>为了查询效率和唯一性，set 采用<strong>HT 编码</strong>（<strong>Dict</strong>）。<strong><u>Dict 中的 key 用来存储元素，value 统一为 null。</u></strong></p><p>当存储的所有数据都是整数，并且元素数量不超过<code>set-max-intset-entries</code>时，Set 会采用<strong>IntSet 编码</strong>，以节省内存。</p><blockquote><p><code>set-max-intset-entries</code>可以在配置文件中设置，默认为 512</p></blockquote><p>当第一次向 set 中添加元素时会创建新的 set，会根据元素的值来决定采用什么编码，创建什么结构来存储。如果该字符是数值类型，会采用 Intset 编码，并创建 IntSet 存储元素；如果该字符不是数值类型，则会采用 HT 编码，创建 Dict 存储元素。</p><p><img src="http://img.catpaws.top/img/image-20250101201119665-2025-1-120_11_37.png" srcset="/img/loading.gif" lazyload alt="image-20250101201119665">在向 set 插入元素过程中</p><ul><li><p>若原来的编码类型是 HT，则直接插入。</p></li><li><p>若当前的编码是 IntSet，需要进行判断。当<u>目前插入的元素不是数值类型</u>或者<u>该元素是数值类型，但成功插入后 Set 中的元素个数超过了设定值</u>时，该 Set 的编码会从 IntSet 切换为 HT，并使用 Dict 存储当前 IntSet 中的值。若这两个条件都满足，则继续在原来的 IntSet 中存储新元素。</p><figure><img src="http://img.catpaws.top/img/image-20250101202638679-2025-1-413_44_38.png" srcset="/img/loading.gif" lazyload alt="image-20250101202638679"><figcaption aria-hidden="true">image-20250101202638679</figcaption></figure></li></ul><p>插入过程的源码分析如下：</p><p><img src="http://img.catpaws.top/img/image-20250101202110049-2025-1-120_21_37.png" srcset="/img/loading.gif" lazyload style="zoom:80%"></p><h4 id="zset">ZSet</h4><p>ZSet 也就是 SortedSet，其中每一个元素都需要指定一个 score 值和 member 值。</p><p><img src="http://img.catpaws.top/img/1653992091967-2025-1-120_50_56.png" srcset="/img/loading.gif" lazyload alt="1653992091967" style="zoom:80%"></p><p>具备以下功能：</p><ul><li>可以根据 score 值排序</li><li>member 必须唯一</li><li>可以根据 member 查询分数</li></ul><p>因此，zset 底层数据结构必须满足<strong>键值存储</strong>、<strong>键必须唯一</strong>、<strong>可排序</strong>这几个需求。哪种编码结构可以满足？</p><ul><li>SkipList：可以排序，并且可以同时存储 score 和 ele 值（member），但无法保证键的唯一性。</li><li>HT（Dict）：可以键值存储，并且可以根据 key 找 value，但无法排序。</li></ul><p>Zset 底层同时使用了这两种编码结构，结合它们的功能满足 Zset 的需要，ZSet 的结构定义如下，在创建 ZsetObject 对象时，先创建了 Zset 对象，再为 Zset 对象创建了 Dict 和 SkipList，并将编码方式设置为<code>OBJ_ENCODING_SKIPLIST</code></p><figure><img src="http://img.catpaws.top/img/image-20250101205736858-2025-1-120_57_37.png" srcset="/img/loading.gif" lazyload alt="Zset结构"><figcaption aria-hidden="true">Zset结构</figcaption></figure><figure><img src="http://img.catpaws.top/img/1653992172526-2025-1-120_59_11.png" srcset="/img/loading.gif" lazyload alt="Zset内存结构"><figcaption aria-hidden="true">Zset内存结构</figcaption></figure><p>当元素数量不多时，HT 和 SkipList 的优势不明显，而且更耗内存，同一份数据存储了两份。因此 zset 还会采用<strong>ZipList</strong>结构来节省内存，不过需要同时满足两个条件：</p><ul><li>元素数量小于 zset_max_ziplist_entries，默认值 128</li><li>每个元素都小于 zset_max_ziplist_value 字节，默认值 64</li></ul><p><img src="http://img.catpaws.top/img/image-20250101210256404-2025-1-121_02_57.png" srcset="/img/loading.gif" lazyload alt="image-20250101210256404" style="zoom:80%"></p><p>但是 ziplist 本身没有排序功能，而且没有键值对的概念，因此需要通过逻辑编码实现：</p><ul><li>ZipList 是连续内存，因此 score 和 element 是紧挨在一起的两个 entry， element 在前，score 在后</li><li>score 越小越接近队首，score 越大越接近队尾，按照 score 值升序排列</li></ul><figure><img src="http://img.catpaws.top/img/image-20250101210507745-2025-1-121_05_08.png" srcset="/img/loading.gif" lazyload alt="Zset使用ZipList时的内存结构"><figcaption aria-hidden="true">Zset使用ZipList时的内存结构</figcaption></figure><p>源码分析：</p><p>创建 Zset：在 zadd 添加元素时，先根据 key 找到 zset，不存在则创建新的 zset。创建时判断配置文件中<code>zset_max_ziplist_entries</code>值是否为 0，设置为 0 就是禁用了 zipList；或者 value 大小超过了<code>zset_max_ziplist_value</code>，此时采用 HT 和 SKipList 的方案，否则采用 ZipList。</p><p><img src="http://img.catpaws.top/img/image-20250101210931134-2025-1-121_09_32.png" srcset="/img/loading.gif" lazyload alt="image-20250101210931134" style="zoom:80%"></p><p>由于 Zset 存在两种编码方式，在添加元素可能发生编码转换。向 Zset 中添加元素时，首先判断编码方式，若本身是 SKIPLIST 编码，无序转换。否则，可能存在编码转换的可能，具体逻辑如代码所示。</p><p><img src="http://img.catpaws.top/img/image-20250101211648500-2025-1-121_16_49.png" srcset="/img/loading.gif" lazyload alt="image-20250101211648500" style="zoom:80%"></p><h4 id="hash">Hash</h4><p>Hash 结构与 Redis 中的 Zset 非常类似：</p><ul><li>都是键值存储</li><li>都需求根据键获取值</li><li>键必须唯一</li></ul><p>不同的是，zset 要根据 score 排序；hash 则无需排序。因此，Hash 底层采用的编码与 Zset 也基本一致，只需要把排序有关的 SkipList 去掉即可。</p><p>Hash 结构<strong>默认采用 ZipList 编码</strong>，用以节省内存。ZipList 中相邻的两个 entry 分别保存 field 和 value。</p><figure><img src="http://img.catpaws.top/img/image-20250101220515346-2025-1-122_05_16.png" srcset="/img/loading.gif" lazyload alt="ZipList编码方式"><figcaption aria-hidden="true">ZipList编码方式</figcaption></figure><p>当数据量较大时，Hash 结构会转为 HT 编码，也就是 Dict，触发条件有两个：</p><ul><li>ZipList 中的元素数量超过了 hash-max-ziplist-entries（默认 512）</li><li>ZipList 中的任意 entry 大小超过了 hash-max-ziplist-value（默认 64 字节）</li></ul><figure><img src="http://img.catpaws.top/img/image-20250101220835623-2025-1-122_08_36.png" srcset="/img/loading.gif" lazyload alt="HT编码格式"><figcaption aria-hidden="true">HT编码格式</figcaption></figure><p>源码分析：</p><p>Hash 结构在创建默认采用 ZipList 编码，由于存在两种编码格式，在添加元素时也会发生格式转换，代码分析如图：</p><p><img src="http://img.catpaws.top/img/无标题-2025-1-122_10_10.png" srcset="/img/loading.gif" lazyload alt="Hash创建及添加数据代码分析" style="zoom:50%"></p><h2 id="二网络模型">二、网络模型</h2><h3 id="用户空间和内核空间">2.1、用户空间和内核空间</h3><p>ubuntu 和 Centos 都是 Linux 的发行版，发行版可以看成对 linux 包了一层壳，任何 Linux 发行版，其系统内核都是 Linux。</p><p>用户的应用，比如 redis，mysql 等其实是没有办法去执行访问系统的硬件的，所以可以通过发行版的这个壳子去访问内核，再通过内核去访问计算机硬件。</p><p>计算机硬件包括，如 cpu，内存，网卡等等，内核（通过寻址空间）可以操作硬件，但是内核需要不同设备的驱动，有了这些驱动之后，内核就可以去对计算机硬件去进行 内存管理，文件系统的管理，进程的管理等等。</p><figure><img src="http://img.catpaws.top/img/1653896065386-2025-1-209_23_22.png" srcset="/img/loading.gif" lazyload alt="1653896065386"><figcaption aria-hidden="true">1653896065386</figcaption></figure><p>我们想要用户的应用来访问，计算机就必须要通过对外暴露的一些接口，才能访问到，从而间接的实现对内核的操控，但是内核本身上来说也是一个应用，所以他本身也需要一些内存，cpu 等设备资源，用户应用本身也在消耗这些资源。为了避免了用户程序随意的去操作系统资源，错误地或恶意地执行危险指令，如清空内存、修改时钟等，需要把用户和<strong>内核隔离开</strong>。</p><p>进程的寻址空间划分成两部分：<strong>内核空间、用户空间</strong></p><p>应用程序也好，还是内核空间也好，都是没有办法直接去物理内存的，而是通过分配虚拟内存映射到物理内存中。通过虚拟内存可以将内核空间与用户空间隔离开来，避免用户程序错误地或恶意地访问内核空间。在 32 位 Linux 操作系统中，虚拟内存空间大小为 4GB，其被划分为两部分：高位的 1G 空间作为内核空间，低位的 3G 空间作为用户空间。</p><p><img src="http://img.catpaws.top/img/image-20250102195140543-2025-1-219_51_44.png" srcset="/img/loading.gif" lazyload alt="虚拟内存划分" style="zoom:80%"></p><p>在 linux 中，他们权限分成两个等级，0 和 3，用户空间只能执行受限的命令（Ring3），而且不能直接调用系统资源，必须通过内核提供的接口来访问。内核空间可以执行特权命令（Ring0），调用一切系统资源，所以一般情况下，用户的操作是运行在用户空间，而内核运行的数据是在内核空间的，而有的情况下，一个应用程序需要去调用一些特权资源，去调用一些内核空间的操作，所以此时他俩需要<strong>在用户态和内核态之间进行切换</strong>。</p><h3 id="linux-io-模型">2.2、Linux IO 模型</h3><p>Linux 系统为了提高 IO 效率，会在用户空间和内核空间都加入缓冲区：</p><ul><li><p>写数据时，要把用户缓冲数据拷贝到内核缓冲区，然后写入设备</p></li><li><p>读数据时，要从设备读取数据到内核缓冲区，然后拷贝到用户缓冲区</p></li></ul><p>针对这个操作：用户在读数据时，会去向内核态申请，想要读取内核的数据，而内核数据要去等待驱动程序从硬件上读取数据，当从磁盘上加载到数据之后，内核会将数据写入到内核的缓冲区中，然后再将数据拷贝到用户态的 buffer 中，然后再返回给应用程序。</p><p><img src="http://img.catpaws.top/img/1653896687354-2025-1-219_54_18.png" srcset="/img/loading.gif" lazyload alt="1653896687354" style="zoom:80%"></p><p>该过程中主要的时间花费就是用在了用户等待数据就绪以及用户态和内核态数据缓冲区之间的数据拷贝。为了提高 IO 效率，Linux 的五种不同的 IO 模型就是在<strong>等待数据就绪</strong>和<strong>读取数据</strong>这两个阶段做了不同的处理。</p><figure><img src="http://img.catpaws.top/img/image-20250102200444084-2025-1-220_04_45.png" srcset="/img/loading.gif" lazyload alt="image-20250102200444084"><figcaption aria-hidden="true">image-20250102200444084</figcaption></figure><p>在《UNIX 网络编程》一书中，总结归纳了 5 种 IO 模型：</p><ul><li>阻塞 IO（Blocking IO）</li><li>非阻塞 IO（Nonblocking IO）</li><li>IO 多路复用（IO Multiplexing）</li><li>信号驱动 IO（Signal Driven IO）</li><li>异步 IO（Asynchronous IO）</li></ul><h4 id="阻塞-io">阻塞 IO</h4><p>顾名思义，阻塞 IO 就是两个阶段都必须阻塞等待：</p><figure><img src="http://img.catpaws.top/img/image-20250102201324645-2025-1-220_13_26.png" srcset="/img/loading.gif" lazyload alt="image-20250102201324645"><figcaption aria-hidden="true">image-20250102201324645</figcaption></figure><p>当应用程序调用 IO 函数（如 read 或 write）时，如果数据没有准备好，用户进程会被阻塞，直到数据准备好并被复制到应用程序的缓冲区中。</p><p>在阻塞期间，进程无法执行其他任务，CPU 资源被浪费在等待上。</p><h4 id="非阻塞-io">非阻塞 IO</h4><p>非阻塞 IO 的 recvfrom 操作会立即返回结果而不是阻塞用户进程。如果数据没有准备好，函数会立即返回，并返回一个错误码（如 EWOULDBLOCK），表示当前没有数据可读或可写。用户程序需要<strong>不断轮询内核</strong>，检查数据是否准备好，这会导致 CPU 资源的浪费。</p><figure><img src="http://img.catpaws.top/img/image-20250102201821482-2025-1-220_18_23.png" srcset="/img/loading.gif" lazyload alt="image-20250102201821482"><figcaption aria-hidden="true">image-20250102201821482</figcaption></figure><p>可以看到，非阻塞 IO 模型中，用户进程在第一个阶段是非阻塞，第二个阶段是阻塞状态。虽然是非阻塞，但性能并没有得到提高。而且忙等机制会导致 CPU 空转，CPU 使用率暴增。</p><h4 id="io-多路复用">IO 多路复用</h4><p>无论是阻塞 IO 还是非阻塞 IO，用户应用在一阶段都需要调用 recvfrom 来获取数据，差别在于无数据时的处理方案：</p><ul><li>如果调用 recvfrom 时，恰好<strong>没有</strong>数据，阻塞 IO 会使 CPU 阻塞，非阻塞 IO 使 CPU 空转，都不能充分发挥 CPU 的作用。</li><li>如果调用 recvfrom 时，恰好<strong>有</strong>数据，则用户进程可以直接进入第二阶段，读取并处理数据</li></ul><p>比如服务端处理客户端 Socket 请求时，在单线程情况下，只能依次处理每一个 socket，如果正在处理的 socket 恰好未就绪（数据不可读或不可写），线程就会被阻塞，所有其它客户端 socket 都必须等待，性能自然会很差。</p><p>就比如服务员给顾客点餐，<strong>分两步</strong>：</p><ul><li>顾客思考要吃什么（等待数据就绪）</li><li>顾客想好了，开始点餐（读取数据）</li></ul><figure><img src="http://img.catpaws.top/img/image-20250102202456528-2025-1-220_24_58.png" srcset="/img/loading.gif" lazyload alt="image-20250102202456528"><figcaption aria-hidden="true">image-20250102202456528</figcaption></figure><p>要提高效率有几种办法？</p><p>方案一：增加更多服务员（多线程） 方案二：不排队，谁想好了吃什么（数据就绪了），服务员就给谁点餐（用户应用就去读取数据）</p><p>那么问题来了：用户进程如何知道内核中数据是否就绪呢？</p><p><strong>文件描述符</strong>（File Descriptor）：简称<strong>FD</strong>，<strong>是一个从 0 开始递增的无符号整数，用来关联 Linux 中的一个文件。在 Linux 中，一切皆文件，例如常规文件、视频、硬件设备等，当然也包括网络套接字（Socket）</strong>。<a target="_blank" rel="noopener" href="https://blog.csdn.net/ye_yumo/article/details/143252968">参考文章</a></p><p><strong>IO 多路复用：是利用单个线程来同时监听多个 FD，并在某个 FD 可读、可写时得到通知，从而避免无效的等待，充分利用 CPU 资源。</strong></p><figure><img src="http://img.catpaws.top/img/image-20250102203443599-2025-1-220_34_45.png" srcset="/img/loading.gif" lazyload alt="image-20250102203443599"><figcaption aria-hidden="true">image-20250102203443599</figcaption></figure><p>不过在 Linux 系统中监听 FD 的方式、通知的方式又有多种实现，常见的有：<code>select</code>、<code>poll</code>和<code>epoll</code>。它们是 Linux 提供的用于监听多个文件描述符状态的系统调用。这些系统调用允许程序将一组文件描述符注册到监听队列中，当其中任何一个文件描述符的状态发生变化时（如可读、可写或发生错误），系统调用会返回并通知应用程序。</p><p>区别：</p><ul><li><code>select</code>和<code>poll</code>适用于监听文件描述符数量较少的情况，而<code>epoll</code>在大量文件描述符的监听场景中性能更优。</li><li>在通知方式上，<code>select</code>和<code>poll</code>只会通知用户进程有 FD 就绪，但不确定具体是哪个 FD，需要用户进程逐个遍历 FD 来确认；<code>epoll</code>则会在通知用户进程 FD 就绪的同时，把已就绪的 FD 写入用户空间。</li></ul><h5 id="io-多路复用之-select">IO 多路复用之 select</h5><p>select 是 Linux 中最早的 I/O 多路复用实现方案，select 函数相关源码如下：</p><figure><img src="http://img.catpaws.top/img/select-2025-1-221_10_44.png" srcset="/img/loading.gif" lazyload alt="select"><figcaption aria-hidden="true">select</figcaption></figure><p>通过 select 方式进行 IO 多路复用的流程如下：</p><ol type="1"><li>假设现在的 IO 都是读操作，创建<code>fd_set rfds</code>，初始时将所有比特位都置为零。</li><li>假如要监听 fd = 1，2，5，将<code>rfds</code>中对应的比特位置为 1</li><li>调用 select 函数将这些 fd 信息拷贝到内核空间，内核负责对这些 fd 进行监听。执行<code>select(5 + 1, rfds, null, null, 3)</code></li><li>内核遍历<code>rfds</code>，从最低位开始，到传入的最大值为止，判断这个范围内被标记的 fd 是否已经就绪</li><li>若当前没有就绪的 fd，休眠等待数据就绪被唤醒或超时</li></ol><p><img src="http://img.catpaws.top/img/image-20250102212349537-2025-1-221_23_50.png" srcset="/img/loading.gif" lazyload alt="image-20250102212349537" style="zoom:80%"></p><ol start="6" type="1"><li>当有 fd 就绪时，内核会将结果写回到内核的<code>rfds</code>中。具体做法是，遍历内核中的<code>rfds</code>，遍历过程中找到被监听的 fd，将其与已就绪的 fd 比较，相同则保留，其余的 fd 对应比特位置为 0。之后将内核中的<code>rfds</code>拷贝回用户空间的<code>rfds</code>中，此时<code>rfds</code>中保存的就是已就绪的 fd，并且 select 函数会返回已就绪 fd 的数量。</li></ol><p><img src="http://img.catpaws.top/img/image-20250102213454924-2025-1-221_34_57.png" srcset="/img/loading.gif" lazyload alt="image-20250102213454924" style="zoom:80%"></p><ol start="7" type="1"><li>用户进程<strong>遍历</strong>fd_set，找到就绪的 fd，读取其中的数据</li></ol><p>以上是执行一次 select 函数的过程，之后要读取还未就绪的 fd 或者其他数据时，按照上面的流程将要读取的 fd 添加到<code>rfds</code>中（<strong>可能将一个 fd 循环拷贝多次</strong>），传到内核中进行监听，数据准备就绪时再去读取。循环往复处理各种读写数据的请求。</p><p>select 模式存在的问题：</p><ul><li>需要将整个 fd_set 从用户空间拷贝到内核空间，select 结束还要再次拷贝回用户空间</li><li>select 无法得知具体是哪个 fd 就绪，需要遍历整个 fd_set fd_set</li><li>监听的 fd 数量不能超过 1024</li></ul><h5 id="io-多路复用之-poll">IO 多路复用之 poll</h5><p>poll 模式对 select 模式做了简单改进，但性能提升不明显，部分关键代码如下：</p><p><img src="http://img.catpaws.top/img/image-20250102214720250-2025-1-221_47_22.png" srcset="/img/loading.gif" lazyload alt="poll模式" style="zoom:80%"></p><p>IO 流程：</p><ol type="1"><li><p>‌<strong>用户进程调用 poll()函数</strong>‌：</p><p>用户进程通过调用<code>poll()</code>函数，将需要监听的 fd 及其关注的事件类型（如读就绪、写就绪等）传递给内核。</p><p>传递给<code>poll()</code>函数的是一个<code>pollfd</code>结构体数组，每个结构体中包含了一个文件描述符和该文件描述符所关注的事件类型。</p></li><li><p>‌<strong>内核处理 poll()请求</strong>‌：</p><p>内核接收到<code>poll()</code>调用后，会将这些文件描述符和事件类型注册到内核内部的监听列表中（<strong>转链表存储，无上限</strong>）。</p><p>内核会监视这些文件描述符的状态，当其中一个或多个文件描述符的事件就绪时，内核会进行相应的处理。</p></li><li><p>‌<strong>内核通知用户进程</strong>‌：</p><p>当内核检测到某个 fd 的事件已经就绪时，它会修改该 fd 的<code>pollfd</code>结构体中的<code>revents</code>为已就绪，并将<code>pollfd</code>结构体数组从内核空间<strong>拷贝回用户空间</strong>，并返回就绪 fd 数量</p></li><li><p>‌<strong>用户进程处理就绪事件</strong>‌：</p><p>用户进程通过调用<code>poll()</code>函数，阻塞等待直到有文件描述符就绪或者超时。</p><p>当<code>poll()</code>函数返回时，用户进程通过<strong>遍历</strong><code>pollfd</code>结构体数组中的<code>revents</code>成员，可以得知哪些文件描述符的事件已经就绪，进而可以读取对应 fd 的数据。</p></li></ol><p><strong>与 select 对比：</strong></p><ul><li>select 模式中的 fd_set 大小固定为 1024，而 pollfd 在内核中采用链表，理论上无上限</li><li><code>poll()</code>函数在内核中是通过轮询的方式来检查文件描述符的状态的。监听 FD 越多，每次遍历消耗时间也越久，性能反而会下降</li></ul><h5 id="io-多路复用之-epoll">IO 多路复用之 epoll</h5><p><strong>epoll</strong>‌ 是对<code>select</code>和<code>poll</code>的改进，能够显著减少数据复制的开销并提高系统资源的利用率。</p><p>主要工作原理如下：</p><ul><li>‌<strong>事件驱动</strong>‌：<code>epoll</code>采用事件通知机制，只有当文件描述符有事件发生时才会被通知。与<code>select</code>和<code>poll</code>的轮询机制相比，<code>epoll</code>避免了无效轮询，提高了处理效率。</li><li>‌<strong>数据结构</strong>‌：<code>epoll</code>使用<strong>红黑树</strong>和<strong>就绪队列</strong>来管理文件描述符。红黑树用于快速查找和管理注册的文件描述符，就绪列表则用于存储已经准备好进行 IO 操作的文件描述符。</li><li>‌<strong>回调机制</strong>‌：<code>epoll</code>通过回调函数来通知用户进程文件描述符的事件状态。当事件发生时，内核会调用相应的回调函数，将事件信息添加到就绪列表中。</li></ul><p>具体源码分析，它提供了三个函数：</p><p>1、<code>epoll_create</code>：在内核创建 eventpoll 结构体，返回对应的句柄 epfd，即该 eventpoll 的唯一标识。</p><p><img src="http://img.catpaws.top/img/image-20250102221030671-2025-1-222_10_31.png" srcset="/img/loading.gif" lazyload alt="epoll_create" style="zoom:80%"></p><p><img src="http://img.catpaws.top/img/image-20250102221248791-2025-1-413_40_19.png" srcset="/img/loading.gif" lazyload alt="执行epoll_create" style="zoom:80%"></p><p>2、<code>epoll_ctl</code>：与 select 和 poll 相比，该函数只是将一个 fd 添加到 eventpoll 的红黑树中，对这个 fd 进行监听，但<strong>不会等待</strong>该 fd 对应的数据就绪。而是对该 fd 设置要监听的事件发生时的回调函数函数<code>ep_poll_callback</code>，当要监听的事件发生时，自动调用该回调函数，就把对应的 FD 加入到就绪列表中</p><p><img src="http://img.catpaws.top/img/image-20250102221353073-2025-1-222_13_55.png" srcset="/img/loading.gif" lazyload alt="epoll_ctl" style="zoom:80%"></p><p><img src="http://img.catpaws.top/img/image-20250102222040358-2025-1-413_40_46.png" srcset="/img/loading.gif" lazyload alt="执行epoll_ctl" style="zoom:80%"></p><p>3、<code>epoll_wait</code>：将 fd 添加到红黑树中后，调用 epoll_wait <strong>检查就绪列表</strong>是否为空，不为空则返回就绪的 FD 的数量，同时将就绪列表中的 fd 拷贝到用户空间中的<code>events</code>中。（与 select 和 poll 不同，它们是将所有的 fd 列表拷贝过去，而 epoll 拷贝过去的只是就绪的 fd）</p><p><img src="http://img.catpaws.top/img/image-20250102222307077-2025-1-222_23_09.png" srcset="/img/loading.gif" lazyload alt="epoll_wait" style="zoom:80%"></p><p><img src="http://img.catpaws.top/img/image-20250102222811692-2025-1-222_28_12.png" srcset="/img/loading.gif" lazyload alt="执行epoll_wait" style="zoom:67%"></p><p>小结：</p><p>select 模式存在的三个问题：</p><ul><li>能监听的 FD 最大不超过 1024</li><li>每次 select 都需要把所有要监听的 FD 都拷贝到内核空间</li><li>每次都要遍历所有 FD 来判断就绪状态</li></ul><p>poll 模式的问题：</p><ul><li>poll 利用链表解决了 select 中监听 FD 上限的问题，但依然要遍历所有 FD，如果监听较多，性能会下降</li></ul><p>epoll 模式中如何解决这些问题的？</p><ul><li>基基于 epoll 实例中的红黑树保存要监听的 FD，理论上无上限，而且增删改查效率都非常高，性能不会随监听的 FD 数量增多而下降</li><li><strong>每个 FD 只需要执行一次 epoll_ctl 添加到红黑树</strong>，以后每次 epol_wait 无需传递任何参数，无需重复拷贝 FD 到内核空间</li><li>内核会将就绪的 FD 直接拷贝到用户空间的指定位置，用户进程无需遍历所有 FD 就能知道就绪的 FD 是谁</li></ul><h5 id="基于-epoll-模式的-web-服务的基本流程">基于 epoll 模式的 web 服务的基本流程</h5><figure><img src="http://img.catpaws.top/img/image-20250103101024427-2025-1-310_10_25.png" srcset="/img/loading.gif" lazyload alt="image-20250103101024427"><figcaption aria-hidden="true">image-20250103101024427</figcaption></figure><ol type="1"><li>在服务端调用<code>epoll_create</code>创建 epoll 实例，在内核中创建红黑树和就绪列表</li><li>创建 serverSocket，得到一个服务端的套接字文件描述符，记为<code>ssfd</code>。</li><li>调用<code>epoll_ctl</code>将监听套接字添加到红黑树中，并指定监听的事件类型（如<code>EPOLLIN</code>表示读就绪事件），同时注册 fd 就绪时的回调函数。</li><li>进入事件循环，使用<code>epoll_wait</code>函数等待<code>ssfd</code>上有事件发生。</li><li>等待指定时间后若无事件发生，则再次调用<code>epoll_wait</code>。</li><li>当被监听的 fd 上有事件发生时，根据<code>epoll_wait</code>返回的事件类型，进行相应的处理。</li><li>如果<code>ssfd</code>发生读就绪事件，则说明有客户端进行连接，调用<code>accpt()</code>函数接收客户端 socket，得到对应的 fd，并调用<code>epoll_ctl</code>为客户端 socket 添加监听。</li><li>如果发生的是客户端 socket 的读就绪事件，则使用<code>read()</code>或<code>recv()</code>函数读取客户端发送的数据，进行处理后返回响应。</li><li>如果客户端连接关闭或发生错误，则使用<code>close()</code>函数关闭客户端套接字，并从 epoll 树中删除。</li><li>循环处理事件，重复步骤 4-9‌，继续等待并处理下一个事件，直到服务器进程被终止。</li></ol><h5 id="事件通知机制">事件通知机制</h5><p>在 IO 多路复用中，事件通知机制有两种主要的触发模式<code>LT</code>和<code>ET</code>，它们定义了当文件描述符上的事件就绪时，内核如何通知用户进程，并且用户进程应该如何处理这些事件。</p><p>水平触发（Level Triggered, <strong>LT</strong>）</p><ul><li><p>工作原理：当 FD 有数据可读时，每次调用<code>epoll_wait</code>时，都会返回该事件（<strong>会重复通知多次</strong>），直至数据处理完成。是 Epoll 的默认模式。</p></li><li><p>特点：LT 模式相对简单直观，用户进程可以在每次调用<code>epoll_wait</code>时处理一部分数据，而不必担心遗漏事件。然而，如果事件处理不及时，可能会导致事件堆积，增加处理复杂度。</p></li></ul><p>边缘触发（Edge Triggered, <strong>ET</strong>）</p><ul><li>工作原理：当 FD 有数据可读时，<strong>只会被通知一次</strong>，不管数据是否处理完成。用户进程必须确保在接收到通知后，<strong>能够一次性处理完所有就绪的事件</strong>，否则可能会遗漏后续的事件。</li><li>特点：ET 模式要求用户进程对事件进行高效处理，以避免遗漏。它通常与非阻塞 IO 结合使用，可以提高系统的吞吐量和响应速度。然而，实现起来相对复杂，需要用户进程仔细管理事件的处理逻辑。</li></ul><p>在 epoll 模式中，当 fd 的监听事件发生时，会调用该函数的回调函数，将该 fd 添加到就绪列表中。当调用<code>epoll_wait</code>时，会将就绪队列中的 fd 拷贝到用户空间去，但再次之前会将就绪的 fd 从就绪列表中断开，再完成拷贝动作。可能这次拷贝并没有将所有 fd 都拷贝过去，若当前采用的是<code>ET</code>模式，下次再来拷贝剩余的数据时会失败，因为之前的就绪的 fd 已经从就绪列表中断开了。而当采用的是<code>LT</code>模式时，若还有数据没有拷贝完，会将这些 fd 数据重写添加回就绪列表中，以便下次继续拷贝剩余的数据。</p><p>在实际应用中，选择 LT 模式还是 ET 模式取决于具体的应用场景和需求。</p><ul><li>‌<strong>LT 模式</strong>‌ 适用于那些可以容忍一定延迟，但希望简化事件处理逻辑的应用场景。</li><li>‌<strong>ET 模式</strong>‌ 则更适用于那些需要高效处理大量并发事件，对延迟敏感的应用场景，如高性能网络服务器。</li></ul><h4 id="信号驱动-io">信号驱动 IO</h4><p>它允许用户进程通过注册一个信号处理函数来<strong>异步</strong>接收数据可用的通知。当设备数据可用时，内核会向用户进程发送一个 SIGIO 信号，触发用户进程预先注册的信号处理函数，进而执行相应的 IO 操作。期间用户应用可以执行其它业务，无需阻塞等待。</p><p><img src="http://img.catpaws.top/img/image-20250103091322550-2025-1-309_13_33.png" srcset="/img/loading.gif" lazyload alt="image-20250103091322550" style="zoom:80%"></p><p><strong>与其他 IO 模型的比较</strong>‌：</p><ul><li>与阻塞 IO 相比，信号驱动 IO 避免了用户进程在 IO 操作完成前的阻塞，提高了 IO 效率。</li><li>与非阻塞 IO 相比，信号驱动 IO 不需要用户进程通过轮询方式不断尝试读写文件描述符，减少了 CPU 资源的浪费。</li><li>与 IO 复用（如 select、poll、epoll）相比，信号驱动 IO 通过信号机制实现 IO 操作的异步通知，不需要进程主动调用轮询函数来检查 IO 状态。</li><li>与异步 IO 相比，信号驱动 IO 仍然需要用户进程在信号处理函数中执行 IO 操作，而异步 IO 则完全由内核处理 IO 操作，并在完成后通知用户进程。</li></ul><p>存在的问题：当有大量 IO 操作时，信号较多，SIGIO 处理函数不能及时处理可能导致信号队列溢出而且内核空间与用户空间的频繁信号交互性能也较低。</p><h4 id="异步-io">异步 IO</h4><p>异步 IO 的<strong>整个过程都是非阻塞的</strong>，用户进程调用完异步 API 后就可以去做其它事情，内核等待数据就绪并拷贝到用户空间后才会递交信号，通知用户进程。</p><figure><img src="http://img.catpaws.top/img/image-20250103091746704-2025-1-309_17_47.png" srcset="/img/loading.gif" lazyload alt="image-20250103091746704"><figcaption aria-hidden="true">image-20250103091746704</figcaption></figure><p><strong>优点</strong></p><ol type="1"><li>‌<strong>高性能</strong>‌：异步 IO 能够在 IO 操作进行的同时，让 CPU 去执行其他任务，从而提高系统的整体性能。</li><li>‌<strong>资源利用率高</strong>‌：异步 IO 可以让一个线程同时处理多个 IO 操作，避免了频繁的线程切换，从而提高了 CPU 和内存的利用率。</li><li>‌<strong>提高响应速度</strong>‌：由于异步 IO 不需要等待 IO 操作完成，可以立即返回执行其他任务，因此可以提高系统的响应速度。</li><li>‌<strong>高并发处理能力</strong>‌：异步 IO 可以处理大量的并发 IO 请求，使得系统能够更有效地处理多个 IO 操作。</li></ol><p><strong>缺点</strong></p><ol type="1"><li>‌<strong>编程复杂度增加</strong>‌：异步编程模型相对于同步编程模型更加复杂，因为它涉及到事件循环、回调函数等概念，可能会增加代码的编写和维护成本。</li><li>‌<strong>错误处理困难</strong>‌：异步编程中可能存在回调地狱(Callback Hell)等问题，导致代码难以理解和调试，容易出现逻辑错误和内存泄漏等问题。</li><li>‌<strong>调试困难</strong>‌：异步程序中的事件顺序可能比较随机，因此在调试时可能会很难追踪代码的执行流程，特别是当存在大量异步操作时更加困难。</li><li>‌<strong>资源竞争</strong>‌：如果异步操作涉及共享资源的读写，可能会导致资源竞争和数据一致性问题，需要额外的同步机制来解决。</li></ol><p>注意：在 IO 操作中，<strong>同步和异步</strong> 与 <strong>阻塞和非阻塞</strong>没有直接关系。</p><p>IO 操作是同步还是异步，<strong>关键看数据在内核空间与用户空间的拷贝过程</strong>（数据读写的 10 操作），也就是阶段二是同步还是异步：</p><p><img src="http://img.catpaws.top/img/image-20250103092223705-2025-1-309_22_24.png" srcset="/img/loading.gif" lazyload alt="image-20250103092223705" style="zoom:80%"></p><h3 id="redis-网络模型">2.3、Redis 网络模型</h3><p>Redis 是单线程还是多线程？</p><p>如果仅仅聊 Redis 的核心业务部分（命令处理），答案是单线程</p><p>如果是聊整个 Redis，那么答案就是多线程</p><p>在 Redis 版本迭代过程中，在两个重要的时间节点上引入了多线程的支持：</p><ul><li>Redis v4.0：引入多线程异步处理一些耗时较长的任务，例如异步删除命令 unlink</li><li>Redis v6.0：在核心网络模型中引入多线程，进一步提高对于多核 CPU 的利用率</li></ul><p>为什么 Redis 要选择单线程？</p><ul><li><p>抛开持久化不谈，Redis 是纯内存操作，执行速度非常快，它的性能瓶颈是网络延迟而不是执行速度，因此多线程并不会带来巨大的性能提升。</p></li><li><p>多线程会导致过多的上下文切换，带来不必要的开销</p></li><li><p>引入多线程会面临线程安全问题，必然要引入线程锁这样的安全手段，实现复杂度增高，而且性能也会大打折扣</p></li></ul><p>Redis 通过 IO 多路复用来提高网络性能，并且支持各种不同的多路复用实现，并且将这些实现进行封装，提供了<strong>统一的</strong>高性能事件库 API 库 AE。</p><figure><img src="http://img.catpaws.top/img/image-20250103093722861-2025-1-309_37_24.png" srcset="/img/loading.gif" lazyload alt="image-20250103093722861"><figcaption aria-hidden="true">image-20250103093722861</figcaption></figure><p>在<code>ae.c</code>中根据当前系统支持的多路复用方式，引入对应响应的 API 库，之后调用 API 时就会调用对应文件中的函数。</p><p>在 Linux 系统下，Redis 底层使用 epoll 实现多路复用，可以参考<a target="_blank" rel="noopener" href="https://www.catpaws.top/284457ed/#基于epoll模式的web服务的基本流程">基于 epoll 模式的 web 服务流程</a>，分析 Redis 单线程网络模型的源码：</p><figure><img src="http://img.catpaws.top/img/Redis单线程网络模型的代码执行流程-2025-1-313_12_44.png" srcset="/img/loading.gif" lazyload alt="Redis单线程网络模型的代码执行流程"><figcaption aria-hidden="true">Redis单线程网络模型的代码执行流程</figcaption></figure><ul><li><code>server.c</code>中的<code>main</code>方法是整个服务的入口</li><li>首先在<code>main</code>方法中，执行<code>initServer()</code>初始化服务，在该方法中调用 aeApiCreate（类似于 epoll_create）创建 epoll 实例，创建 ServerSocket 并得到对应的 fd。同时注册 Socket 连接处理器，在该处理器内部会调用<code>aeApiAddEvent</code>监听 ServerSocket 的读事件，并为为其绑定事件触发时的处理器<code>acceptTcpHandler</code>。</li><li>在<code>acceptTcpHandler</code>中，处理 ServerSocket 上的读事件，接收客户端请求，得到客户端 socket 的 fd。监听 Socket 的读事件，并为其绑定读事件触发时的处理器<code>readQueryFromClient</code>。</li><li><code>readQueryFromClient</code>负责处理客户端发来的命令请求，首先从客户端的读缓冲区中读取命令字符串，再解析这些字符串，转为 Redis 命令参数存入 c-&gt;argv 数组。从 argv 数组中获得要执行的命令和参数，通过对应命令的 command 函数执行命令，并将结果写到客户端写缓冲区 c-&gt;buf，若缓冲区写不下，写到 c-&gt;reply，这是一个链表，容量无上限。最后将客户端添加到 server.clients_pending_write 这个队列，等待被写出。</li><li>之后执行<code>main</code>方法中的<code>aeMain</code>开始循环监听事件，等待 fd 就绪。</li><li>当开始监听后，若指定的 fd 未就绪，则需要休眠等待。因此在开始监听前，会先调用前置处理器<code>beforesleep</code>，对 clients_pending_write 这个队列中等待写出的客户端进行处理，依次将对应客户端缓存区中的数据返回给客户端。</li><li>之后，开始监听 fd，执行<code>aeApiPoll</code>（类似以 epoll_wait）。当就绪队列中有 fd 时，会返回就绪 fd 的数量，调用对应的处理器处理就绪的 fd。</li></ul><figure><img src="http://img.catpaws.top/img/image-20250103114438782-2025-1-311_44_40.png" srcset="/img/loading.gif" lazyload alt="image-20250103114438782"><figcaption aria-hidden="true">image-20250103114438782</figcaption></figure><p>整体来讲，Redis 使用了 IO 多路复用技术，允许单个线程同时监听多个文件描述符（包括服务端的 ServerSocket 和客户端的 socket），并在有数据可读或可写时将任务派发给不同的处理器进行处理。具体来说：</p><ul><li>当服务端的 ServerSocket 发生读事件时，说明有客户端进行连接，将对应的任务分配给连接应答处理器<code>tcpAcceptHandler</code>，获取客户端 socket 对应的 fd，并为其注册监听；</li><li>当客户端 socket 发生读事件时，说明用客户端命令请求到达，将对应的任务分配给命令请求处理器<code>readQueryFromClient</code>，从客户端读缓冲区中读取命令字符串并解析为 Redis 命令进行处理，将处理结果写到客户端写缓冲区，并将该客户端放入 clients_pending_write 队列等待数据写回；</li><li>在每次循环监听 fd 之前，通过<code>beforesleep</code>方法调用命令回复处理器<code>sendReplyToClient</code>处理 clients_pending_write 队列中的客户端，将存储在客户端输出缓冲区（<code>buf</code>字段）或输出链表（<code>reply</code>字段）中的响应数据发送给客户端。</li></ul><p>Redis 6.0 版本中引入了多线程，目的是为了提高 IO 读写效率。</p><p>在处理客户端命令请求时，需要从客户端 Socket 中读出命令，在此过程中涉及到了网络 IO 的读操作，会受到网络带宽等影响。同样的，在将服务端处理结果写回客户端 Socket 中时，涉及到了网络 IO 的写操作，这又是一个性能瓶颈。</p><p>对于 redis 来说在监听 fd，以及命令执行的时候，（主线程）单线程是完成足够的（纯内存操作），真正影响性能的永远是 IO。</p><p>因此在<strong>解析客户端命令</strong>、<strong>写响应结果</strong>时采用了多线程。核心的命令执行、IO 多路复用模块依然是由主线程执行。</p><figure><img src="http://img.catpaws.top/img/image-20250103115210756-2025-1-311_52_11.png" srcset="/img/loading.gif" lazyload alt="image-20250103115210756"><figcaption aria-hidden="true">image-20250103115210756</figcaption></figure><h2 id="三通信协议---resp-协议">三、通信协议 - RESP 协议</h2><p>Redis 是一个 CS 架构的软件，通信一般分两步（不包括 pipeline 和 PubSub）：</p><ol type="1"><li>客户端（client）向服务端（server）发送一条命令</li><li>服务端解析并执行命令，返回响应结果给客户端</li></ol><p>因此客户端发送命令的格式、服务端响应结果的格式必须有一个规范，这个规范就是通信协议。</p><p>而在 Redis 中采用的是 RESP（Redis Serialization Protocol）协议：</p><ul><li>Redis 1.2 版本引入了 RESP 协议</li><li>Redis 2.0 版本中成为与 Redis 服务端通信的标准，称为 RESP2</li><li>Redis 6.0 版本中，从 RESP2 升级到了 RESP3 协议，增加了更多数据类型并且支持 6.0 的新特性--客户端缓存</li></ul><p>但目前，默认使用的依然是 RESP2 协议（以下简称 RESP）。</p><p>在 RESP 中，通过<strong>首字节</strong>的字符来区分不同数据类型，常用的数据类型包括 5 种：</p><ul><li><p>单行字符串：首字节是 <code>+</code>，后面跟上单行字符串，以 CRLF（ <code>\r\n</code>）结尾。例如返回 OK： <code>+OK\r\n</code>。</p><blockquote><p>单行字符串的数据中只能包含普通字符串，不允许包含<code>\r\n</code>，是非二进制安全的。通常用于服务端返回的信息</p></blockquote></li><li><p>错误（Errors）：首字节是 <code>-</code> ，与单行字符串格式一样，只是字符串是异常信息，例如："-Error message"。</p></li><li><p>数值：首字节是 <code>:</code>，后面跟上数字格式的字符串，以 CRLF 结尾。例如：":10"</p></li><li><p>多行字符串：首字节是 <code>$</code> ，表示二进制安全的字符串，最大支持 512MB。记录时保存<strong>字符串长度</strong>和<strong>字符串本身</strong>，例如：</p><figure><img src="http://img.catpaws.top/img/image-20250103141407181-2025-1-314_14_08.png" srcset="/img/loading.gif" lazyload alt="image-20250103141407181"><figcaption aria-hidden="true">image-20250103141407181</figcaption></figure><ul><li><p>如果大小为 0，则代表空字符串："$0"</p></li><li><p>如果大小为-1，则代表不存在："$-1"</p></li></ul></li><li><p>数组：首字节是<code>*</code>，后面跟上数组元素个数，再跟上元素，元素数据类型不限，例如：</p><figure><img src="http://img.catpaws.top/img/image-20250103141609254-2025-1-314_16_10.png" srcset="/img/loading.gif" lazyload alt="image-20250103141609254"><figcaption aria-hidden="true">image-20250103141609254</figcaption></figure></li></ul><h2 id="四内存策略">四、内存策略</h2><p>Redis 之所以性能强，最主要的原因就是基于内存存储。然而单节点的 Redis 其内存大小不宜过大，会影响持久化或主从同步性能。</p><p>我们可以通过修改配置文件来设置 Redis 的最大内存。当内存使用达到上限时，就无法存储更多数据了。</p><p><img src="http://img.catpaws.top/img/image-20250103144051474-2025-1-314_40_52.png" srcset="/img/loading.gif" lazyload alt="image-20250103144051474" style="zoom:80%"></p><h4 id="过期策略">过期策略</h4><p>在 Redis 中，可以通过<code>expire</code>命令给 Redis 的 key 设置 TTL（存活时间）</p><p><img src="http://img.catpaws.top/img/image-20250103214944506-2025-1-321_50_18.png" srcset="/img/loading.gif" lazyload alt="image-20250103214944506" style="zoom:80%"></p><p>可以发现，当 key 的 TTL 到期以后，再次访问 name 返回的是 nil，说明这个 key 已经不存在了，对应的内存也得到释放，从而起到内存回收的目的。</p><p>那么，Redis 如何知道一个 Key 是否过期呢？</p><p>答：利用两个 Dict 分别记录 key-value 对及 key-ttl 对</p><p>Redis 本身是一个典型的 key-value 内存存储数据库，因此所有的 key、value 都保存在 Dict 结构中。不过在其 database 结构体中，对 key 进行了划分，使用多个 Dict 数组保存。其中，<strong><code>dict</code>中存放所有的 key 及 value，而<code>expires</code>只包含设置了 TTL 的 key，在其中存储 key 及其对应的 TTL 存活时间</strong>。</p><figure><img src="http://img.catpaws.top/img/image-20250103215311967-2025-1-321_53_13.png" srcset="/img/loading.gif" lazyload alt="database结构体"><figcaption aria-hidden="true">database结构体</figcaption></figure><p><img src="http://img.catpaws.top/img/redisDb-2025-1-322_35_25.png" srcset="/img/loading.gif" lazyload alt="redisDb" style="zoom:80%"></p><p>是不是 TTL 到期就立即删除了呢？</p><p><strong>惰性删除</strong>：顾明思议并不是在 TTL 到期后就立刻删除，而是在<strong>访问</strong>一个 key 的时候，检查该 key 的存活时间，如果已经过期才执行删除。</p><figure><img src="http://img.catpaws.top/img/image-20250103223836841-2025-1-322_38_38.png" srcset="/img/loading.gif" lazyload alt="惰性删除"><figcaption aria-hidden="true">惰性删除</figcaption></figure><p>若有很多 key 过期后很长时间没有被访问，只采用惰性删除时，这些 key 就无法被释放。</p><p><strong>周期删除</strong>：顾明思议是通过一个定时任务，周期性的<strong>抽样部分过期的 key</strong>，然后执行删除。</p><p>执行周期有两种：</p><ul><li><p>Redis 服务初始化函数 initServer()中设置定时任务，按照 server.hz 的频率来执行过期 key 清理，模式为<strong>SLOW</strong></p></li><li><p>Redis 的每个事件循环前会调用 beforeSleep()函数，执行过期 key 清理，模式为<strong>FAST</strong></p></li></ul><p>SLOW 模式规则：</p><ul><li>执行频率受 server.hz 影响，默认为 10，即每秒执行 10 次，每个执行周期 100ms。</li><li>执行清理耗时不超过一次执行周期的 25%.</li><li>逐个遍历 db，逐个遍历 db 中的 bucket（相当于 dict 中哈希表的一个角标下的链表），抽取 20 个 key 判断是否过期</li><li>如果没达到时间上限（25ms）并且过期 key 比例大于 10%，再进行一次抽样，否则结束</li></ul><p>FAST 模式规则（过期 key 比例小于 10%不执行）：</p><ul><li>执行频率受<code>beforesleep()</code>调用频率影响，但两次 FAST 模式间隔不低于 2ms</li><li>执行清理耗时不超过 1ms</li><li>逐个遍历 db，逐个遍历 db 中的 bucket，抽取 20 个 key 判断是否过期</li><li>如果没达到时间上限（1ms）并且过期 key 比例大于 10%，再进行一次抽样，否则结束</li></ul><p>源码分析：</p><p>Slow 模式会在服务初始化时调用一次<code>serverCron</code>进行清理，并返回下一次调用<code>serverCron</code>的时间间隔，所以可以通过设置<code>server.hz</code>来控制 Slow 模式的清理频率。</p><p><img src="http://img.catpaws.top/img/image-20250103230109701-2025-1-323_01_10.png" srcset="/img/loading.gif" lazyload alt="Slow模式的处理过程" style="zoom:80%"></p><p>Fast 模式会在每次调用<code>beforesleep</code>函数时执行一次。</p><p><img src="http://img.catpaws.top/img/image-20250103230330831-2025-1-323_03_31.png" srcset="/img/loading.gif" lazyload alt="fast模式的处理过程" style="zoom:80%"></p><p>在 Redis 进入事件循环后，每次循环都会执行<code>beforesleep</code>方法，在其中进行 Fast 模式的清理。而当有 fd 就绪，处理完对应的 IO 事件后，会检查当前是否到了执行 Slow 清理模式的时间，若还在时间间隔内，则不做处理；若到了执行时间，则会调用<code>serverCron</code>进行 Slow 模式的清理。</p><p><img src="http://img.catpaws.top/img/image-20250103230423489-2025-1-323_04_24.png" srcset="/img/loading.gif" lazyload alt="两种模式生效时机" style="zoom:67%"></p><h4 id="淘汰策略">淘汰策略</h4><p>当 Redis 中没有 key 过期，但现在 Redis 的内存已经满了，就需要基于淘汰策略删除一部分 key。</p><blockquote><p>被删除的 key 及其对应的数据不再存储在 Redis 中，即数据丢失 ‌。因此应该采取适当的数据持久化策略（如 RDB 或 AOF）来确保数据的可靠性和可恢复性 ‌。</p><p>需要注意的是，持久化策略也不能完全保证数据的绝对安全。例如，在 RDB 持久化中，如果数据在快照保存之前被淘汰，那么这些数据将不会包含在持久化文件中。在 AOF 持久化中，如果数据被淘汰后还没有被写入到 AOF 文件中，那么这些数据也将丢失。</p></blockquote><p><strong>内存淘汰</strong>：就是当 Redis 内存使用达到设置的阈值时，Redis 主动挑选<strong>部分 key</strong>删除以释放更多内存的流程。</p><p>由于任何一条数据的写入操作都会导致内存溢出，因此 Redis 会在每一条命令执行前检查内存是否足够，如果不够会进行内存清理。</p><p>Redis 会在处理客户端命令的方法 processCommand（）中尝试做内存淘汰：</p><p><img src="http://img.catpaws.top/img/image-20250103235731736-2025-1-323_57_42.png" srcset="/img/loading.gif" lazyload alt="image-20250103235731736" style="zoom:80%"></p><p>Redis 支持 8 种不同策略来选择要删除的 key，这八种策略可以归为五类：</p><ol type="1"><li>不淘汰任何 key</li></ol><p><code>noeviction</code>：不淘汰任何 key，但是内存满时不允许写入新数据，默认就是这种策略。</p><ol start="2" type="1"><li>清理设置了 TTL 的 key</li></ol><p><code>volatile-ttl</code>：对设置了 TTL 的 key，比较 key 的剩余 TTL 值，TTL 越小越先被淘汰（送你一程）</p><p>之后的三种策略，根据是要作用在所有 key 上（前缀为<code>allkeys</code>），还是只作用在设置了 TTL 的 key 上(前缀为<code>volatile</code>)，各分为两种。</p><ol start="3" type="1"><li>随机淘汰</li></ol><p><code>allkeys-random</code>：对全体 key，随机进行淘汰。也就是直接从 db-&gt;dkt 中随机挑选</p><p><code>volatile-random</code>：对设置了 TTL 的 key，随机进行淘汰。也就是从 db-&gt;expires 中随机挑选。</p><ol start="4" type="1"><li>LRU</li></ol><p><code>allkeys-lru</code>：对全体 key，基于 LRU 算法进行淘汰</p><p><code>volatile-lru</code>：对设置了 TTL 的 key，基于 LRU 算法进行淘汰</p><ol start="5" type="1"><li>LFU</li></ol><p><code>allkeys-lfu</code>：对全体 key，基于 LFU 算法进行淘汰</p><p><code>volatile-lfu</code>：对设置了 TTL 的 key，基于 LFI 算法进行淘汰</p><blockquote><p><strong>LRU</strong>（Least Recently Used），最近最少使用。用当前时间减去最后一次访问时间，这个值越大则淘汰优先级越高。</p><p><strong>LFU</strong>（Least Frequently Used），最少频率使用。会统计每个 key 的访问频率，值越小淘汰优先级越高。</p></blockquote><p>若采用<code>LRU</code>或者<code>LFU</code>淘汰策略，Redis 如何统计<strong>一个 key 最近一次的访问时间</strong>以及<strong>最近一次访问的频率</strong>？</p><p>Redis 的数据都会被封装为 RedisObject 结构：</p><figure><img src="http://img.catpaws.top/img/image-20250104001134324-2025-1-400_11_35.png" srcset="/img/loading.gif" lazyload alt="image-20250104001134324"><figcaption aria-hidden="true">image-20250104001134324</figcaption></figure><p>其中的<code>unsigned lru:LRU_BITS</code>属性就是用来统计当前 RedisObject 对象的访问信息。<strong>根据配置文件中设置的淘汰策略，这个字段会记录不同的值</strong>。</p><p>若采用<code>LRU</code>淘汰策略，该字段会以秒为单位记录最近一次访问时间，长度 24bit</p><p>若采用<code>LFU</code>淘汰策略，该字段会用高 16 位 以<strong>分钟</strong>为单位记录最近一次访问时间，低 8 位记录<span style="color:red">逻辑访问次数</span></p><p>LFU 的访问次数之所以叫做<strong>逻辑访问次数</strong>，是因为并不是每次 key 被访问都计数，而是通过运算：</p><ol type="1"><li>生成 0~1 之间的随机数 R</li><li>计算 1/（旧次数 * <code>Ifu_log_factor</code> +1），记录为 P，<code>lfu_log_factor</code>默认为 10</li><li>如果 R&lt;P，则计数器 +1，且最大不超过 255</li><li>访问次数会随时间衰减，距离上一次访问时间每隔 <code>lfu_decay_time</code> 分钟（默认 1），计数器-1</li></ol><p>分析：随着访问该 key 的次数增多，得到的 p 越来越小，R&lt;P 的可能就越来越小，该 key 的逻辑访问次数增加的可能也会越来越小。如果长时间不访问，访问次数会随时间衰减。逻辑访问次数虽然不是真正访问次数，但是对所有 key 来说，这个次数还是说明一个 key 的访问频率的高低。</p><p>之前说过，Redis 会在执行每一条客户端命令前执行<code>processCommand()</code>进行内存淘汰。在该函数中会根据当前设定的淘汰策略淘汰一部分 key，具体执行流程如下：</p><p><img src="http://img.catpaws.top/img/image-20250104004036495-2025-1-400_40_37.png" srcset="/img/loading.gif" lazyload alt="processCommand函数执行流程" style="zoom:80%"></p></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" class="category-chain-item">数据库</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/%E5%8A%A8%E6%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2SDS/" class="print-no-link">#动态字符串SDS</a> <a href="/tags/IntSet/" class="print-no-link">#IntSet</a> <a href="/tags/Dict/" class="print-no-link">#Dict</a> <a href="/tags/ZipList/" class="print-no-link">#ZipList</a> <a href="/tags/QuickList/" class="print-no-link">#QuickList</a> <a href="/tags/SkipList/" class="print-no-link">#SkipList</a> <a href="/tags/RedisObject/" class="print-no-link">#RedisObject</a> <a href="/tags/Linux-IO%E6%A8%A1%E5%9E%8B/" class="print-no-link">#Linux IO模型</a> <a href="/tags/Redis%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/" class="print-no-link">#Redis网络模型</a> <a href="/tags/%E5%86%85%E5%AD%98%E7%AD%96%E7%95%A5/" class="print-no-link">#内存策略</a></div></div><div class="license-box my-3"><div class="license-title"><div>Redis - 原理篇</div><div>https://catpaws.top/284457ed/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>猫爪在上</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2024年12月30日</div></div><div class="license-meta-item"><div>许可协议</div><div><a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-cc-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/f0242a65/" title="JVM学习"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">JVM学习</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/29be09bb/" title="Redis - 高级篇"><span class="hidden-mobile">Redis - 高级篇</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><div id="twikoo"></div><script type="text/javascript">Fluid.utils.loadComments("#comments",(function(){Fluid.utils.createScript("https://cdn.smartcis.cn/npm/twikoo@1.6.40/dist/twikoo.all.min.js",(function(){var t=Object.assign({envId:"https://catpaws-comments.netlify.app/.netlify/functions/twikoo",region:"ap-shanghai",path:"window.location.pathname"},{el:"#twikoo",path:"window.location.pathname",onCommentLoaded:function(){Fluid.utils.listenDOMLoaded((function(){var t="#twikoo .tk-content img:not(.tk-owo-emotion)";Fluid.plugins.imageCaption(t),Fluid.plugins.fancyBox(t)}))}});twikoo.init(t)}))}))</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><script>Fluid.utils.createScript("https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js",(function(){mermaid.initialize({theme:"default"}),Fluid.utils.listenDOMLoaded((function(){Fluid.events.registerRefreshCallback((function(){"mermaid"in window&&mermaid.init()}))}))}))</script><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a><br>人山人海，欢迎你的到来 <i class="iconfont icon-love"></i><br><span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script>window.MathJax?(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise()):window.MathJax={tex:{inlineMath:{"[+]":[["$","$"]]}},loader:{load:["ui/lazy"]},options:{renderActions:{insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(t=>{let e=t.parentNode;"li"===e.nodeName.toLowerCase()&&e.parentNode.classList.add("has-jax")})},"",!1]}}},Fluid.events.registerRefreshCallback((function(){"MathJax"in window&&MathJax.startup.document&&"function"==typeof MathJax.startup.document.state&&(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset(),MathJax.typesetPromise())}))</script><script src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js"></script><script defer src="/js/leancloud.js"></script><script src="/js/local-search.js"></script><script src="//img.catpaws.top/blog-source/js/timeDate.js"></script><script src="//sdk.jinrishici.com/v2/browser/jinrishici.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript><script data-pjax src="https://unpkg.com/oh-my-live2d"></script><script>const oml2d=OML2D.loadOml2d({dockedPosition:"left",mobileDisplay:!1,models:[{path:"http://img.catpaws.top/blog-source/live2d/Frieren/Frieren.model3.json",motionPreloadStrategy:"IDLE",position:[-60,-100],scale:.06,stageStyle:{width:250,height:350}}],parentElement:document.body,primaryColor:"var(--btn-bg)",sayHello:!1,tips:{style:{width:200,height:90,left:"calc(50% - 20px)",top:"-100px","font-size":"14px"},idleTips:{interval:15e3,message:function(){return axios.get("https://v1.hitokoto.cn?c=i").then((function(t){return t.data.hitokoto})).catch((function(t){console.error(t)}))}}}})</script></body></html>