<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="http://img.catpaws.top/blog-source/imgs/webicon.png"><link rel="icon" href="http://img.catpaws.top/blog-source/imgs/webicon.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="猫爪在上"><meta name="keywords" content=""><meta name="description" content="redis.conf 配置详解 一、分布式缓存 单节点 Redis 问题  数据丢失问题：Redis 是内存存储，服务重启可能会丢失数据。（通过实现 Redis 数据持久化解决） 并发能力问题：单节点的 Redis 的性能虽然不错，但无法满足如 618 这样的该并发场景（通过搭建主从集群，实现读写分离解决） 故障恢复问题：如果 Redis 宕机，则服务不可用，需要一种自动"><meta property="og:type" content="article"><meta property="og:title" content="Redis - 高级篇"><meta property="og:url" content="https://catpaws.top/29be09bb/index.html"><meta property="og:site_name" content="猫爪在上de书桌"><meta property="og:description" content="redis.conf 配置详解 一、分布式缓存 单节点 Redis 问题  数据丢失问题：Redis 是内存存储，服务重启可能会丢失数据。（通过实现 Redis 数据持久化解决） 并发能力问题：单节点的 Redis 的性能虽然不错，但无法满足如 618 这样的该并发场景（通过搭建主从集群，实现读写分离解决） 故障恢复问题：如果 Redis 宕机，则服务不可用，需要一种自动"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://img.catpaws.top/img/%E6%97%A0%E6%A0%87%E9%A2%98-2024-12-2410_58_16.png"><meta property="og:image" content="http://img.catpaws.top/img/%E6%97%A0%E6%A0%87%E9%A2%98-2024-12-2411_24_48.png"><meta property="og:image" content="http://img.catpaws.top/img/%E6%97%A0%E6%A0%87%E9%A2%98-2024-12-2415_39_06.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20241224162530556-2024-12-2416_25_32.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20241224162742910-2024-12-2416_27_44.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20241224163250288-2024-12-2416_32_51.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20241226104236033-2024-12-2610_42_37.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20241226125548348-2024-12-2612_55_49.png"><meta property="og:image" content="http://img.catpaws.top/img/yeVDlwtfMx-2024-12-2622_06_36.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20241226220907274-2024-12-2622_09_08.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20241226221349893-2024-12-2622_13_57.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20241229104044294-2024-12-2910_40_57.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20241230142225240-2024-12-3014_23_04.png"><meta property="og:image" content="http://img.catpaws.top/img/image-20241230142726964-2024-12-3014_28_04.png"><meta property="article:published_time" content="2024-12-24T01:40:45.000Z"><meta property="article:modified_time" content="2025-01-26T07:06:08.062Z"><meta property="article:author" content="猫爪在上"><meta property="article:tag" content="Redis持久化"><meta property="article:tag" content="Redis主从"><meta property="article:tag" content="Redis分片集群"><meta property="article:tag" content="多级缓存"><meta property="article:tag" content="Redis最佳实践"><meta property="article:tag" content="Redis事务"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="http://img.catpaws.top/img/%E6%97%A0%E6%A0%87%E9%A2%98-2024-12-2410_58_16.png"><title>Redis - 高级篇 - 猫爪在上de书桌</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css"><link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/bynotes/texiao/source/css/shubiao.css"><link rel="stylesheet" href="//img.catpaws.top/blog-source/css/font.css"><link rel="stylesheet" href="//img.catpaws.top/blog-source/css/poem.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"catpaws.top",root:"/",version:"1.9.8",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,follow_dnt:!0,baidu:null,google:{measurement_id:null},tencent:{sid:null,cid:null},leancloud:{app_id:"TNTPv22capMq3aFV9S0sLqSm-gzGzoHsz",app_key:"G2BBAxXmiixopVg5mIJ2sxXR",server_url:"https://tntpv22c.lc-cn-n1-shared.com",path:"window.location.pathname",ignore_local:!1},umami:{src:null,website_id:null,domains:null,start_time:"2024-01-01T00:00:00.000Z",token:null,api_server:null}},search_path:"/local-search.xml",include_content_in_search:!0};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 7.3.0"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>猫爪在上de书桌</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/about/" target="_self"><i class="iconfont icon-addrcard"></i> <span>主页</span></a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><i class="iconfont icon-books"></i> <span>博客</span></a><div class="dropdown-menu" aria-labelledby="navbarDropdown"><a class="dropdown-item" href="/" target="_self"><i class="iconfont icon-pen"></i> <span>文章</span> </a><a class="dropdown-item" href="/archives/" target="_self"><i class="iconfont icon-archive-fill"></i> <span>归档</span> </a><a class="dropdown-item" href="/categories/" target="_self"><i class="iconfont icon-category-fill"></i> <span>分类</span> </a><a class="dropdown-item" href="/tags/" target="_self"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></div></li><li class="nav-item"><a class="nav-link" href="/messages/" target="_self"><i class="iconfont icon-comment"></i> <span>留言板</span></a></li><li class="nav-item"><a class="nav-link" href="/timeline/" target="_self"><i class="iconfont icon-images"></i> <span>时光轴</span></a></li><li class="nav-item"><a class="nav-link" href="/links/" target="_self"><i class="iconfont icon-link-fill"></i> <span>友链</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(http://img.catpaws.top/blog-source/imgs/article-bg.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="Redis - 高级篇"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2024-12-24 09:40" pubdate>2024年12月24日 上午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 21k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 178 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 id="seo-header">Redis - 高级篇</h1><p id="updated-time" class="note note-info">本文最后更新于 2025年1月26日 下午</p><div class="markdown-body"><meta name="referrer" , content="no-referrer"><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/kreo/p/4423362.html">redis.conf 配置详解</a></p><h2 id="一分布式缓存">一、分布式缓存</h2><p>单节点 Redis 问题</p><ul><li>数据丢失问题：Redis 是内存存储，服务重启可能会丢失数据。（通过<strong>实现 Redis 数据持久化</strong>解决）</li><li>并发能力问题：单节点的 Redis 的性能虽然不错，但无法满足如 618 这样的该并发场景（通过<strong>搭建主从集群，实现读写分离</strong>解决）</li><li>故障恢复问题：如果 Redis 宕机，则服务不可用，需要一种自动的故障恢复手段（<strong>利用 Redis 哨兵，实现健康检测和自动恢复</strong>）</li><li>存储能力问题：Redis 是基于内存存储，单节点能存储的数据量难以满足海量数据需求（<strong>搭建分片集群，利用插槽机制实现动态扩容</strong>）。</li></ul><h3 id="redis-持久化">1.1、Redis 持久化</h3><p>Redis 有两种持久化方案：</p><ul><li>RDB 持久化</li><li>AOF 持久化</li></ul><h4 id="rdb-持久化">RDB 持久化</h4><p>RDB 全称<code>Redis Database Backup file</code>（Redis 数据备份文件），也被叫做 Redis 数据快照。简单来说就是<strong>把内存中的所有数据都记录到磁盘中</strong>。Redis 的 RDB 持久化通过定期保存数据快照至一个 rdb 文件中，并在启动时自动加载 rdb 文件，以恢复之前保存的数据。快照文件称为 RDB 文件，默认是保存在当前运行目录。</p><h5 id="执行时机">执行时机</h5><ul><li><p>执行 save 命令</p><div class="code-wrapper"><pre><code class="hljs bash">[root@localhost ~]#redis-cli
127.0.0.1：6379&gt; save   <span class="hljs-comment">#由Redis主进程来执行RDB，会阻塞所有命令ok</span>
127.0.0.1：6379&gt;</code></pre></div><p>save 命令会导致<strong>主进程</strong>执行 RDB，这个过程中其它所有命令都会被<strong>阻塞</strong>。只有在数据迁移时可能用到。</p></li><li><p>执行 bgsave 命令</p><p>下面的命令可以异步执行 RDB：</p><div class="code-wrapper"><pre><code class="hljs bash">127.0.0.1：6379&gt; bgsave#开启子进程执行RDB，避免主进程受到影响
Background saving started</code></pre></div><p>这个命令执行后会<strong>开启独立进程完成 RDB</strong>，主进程可以持续处理用户请求，不受影响。</p></li><li><p>Redis 停机时</p><p>Redis 停机时会执行一次 save 命令，实现 RDB 持久化。</p><figure><img src="http://img.catpaws.top/img/image-20241224104159899-2024-12-2410_42_10.png" srcset="/img/loading.gif" lazyload alt="image-20241224104159899"><figcaption aria-hidden="true">image-20241224104159899</figcaption></figure></li><li><p>触发 RDB 条件时</p><p>Redis 内部有触发 RDB 的机制，可以在 redis.conf 文件中找到，格式如下：</p><div class="code-wrapper"><pre><code class="hljs properties"><span class="hljs-comment"># 900秒内，如果至少有1个key被修改，则执行bgsave ， 如果是 save &quot;&quot; 则表示禁用RDB</span>
<span class="hljs-attr">save</span> <span class="hljs-string">900 1</span>
<span class="hljs-attr">save</span> <span class="hljs-string">300 10</span>
<span class="hljs-attr">save</span> <span class="hljs-string">60 10000</span></code></pre></div></li></ul><p>RDB 的其它配置也可以在 redis.conf 文件中设置：</p><div class="code-wrapper"><pre><code class="hljs properties"><span class="hljs-comment"># 是否压缩 ,建议不开启，压缩也会消耗cpu，磁盘的话不值钱</span>
<span class="hljs-attr">rdbcompression</span> <span class="hljs-string">yes</span>
<span class="hljs-comment"></span>
<span class="hljs-comment"># RDB文件名称</span>
<span class="hljs-attr">dbfilename</span> <span class="hljs-string">dump.rdb</span>
<span class="hljs-comment"></span>
<span class="hljs-comment"># 文件保存的路径目录</span>
<span class="hljs-attr">dir</span> <span class="hljs-string">./</span>


<span class="hljs-attr">docker</span> <span class="hljs-string">run -p 6379:6379 --name redis6.2.6 -v /usr/local/bin/redis/dockerRedis/conf/redis.config:/etc/redis/redis.conf -v /usr/local/bin/redis/dockerRedis/data:/data -v /usr/local/bin/redis/dockerRedis/logs:/logs -d redis:6.2.6 redis-server /etc/redis/redis.conf</span></code></pre></div><h5 id="原理">原理</h5><p>bgsave 开始时会 fork 主进程得到子进程，子进程<strong>共享</strong>主进程的内存数据。完成 fork 后，由子进程读取内存数据并写入 新的 RDB 文件，用新 RDB 文件替换旧的 RDB 文件。</p><blockquote><p>fork 的作用是复制一个与当前进程（父进程）完全相同的子进程。新进程（子进程）的所有数据（变量、环境变量、程序计数器等）的数值都和原进程（父进程）一致，但子进程是一个全新的进程。</p><p>在 fork 过程中父进程是<strong>阻塞</strong>的，完成后才可继续处理请求</p></blockquote><p>fork 采用了写时拷贝（<strong>Copy-On-Write</strong>, COW）技术，在 fork 发生时，并不会立即复制父进程的全部内存数据到子进程，而是将父进程的<strong>页表</strong>拷贝给子进程，此时父子进程会通过相同的页表映射关系共享相同的物理内存页。</p><p>在子进程读取内存数据时，这些内存页设置为<strong>只读模式</strong>，防止父进程在此期间进行写操作而出现脏数据。当父进程修改内存数据时，操作系统会将相应的内存数据复制一份作为副本，主进程对副本数据进行修改，下次读取时也会读取副本数据。</p><figure><img src="http://img.catpaws.top/img/无标题-2024-12-2410_58_16.png" srcset="/img/loading.gif" lazyload alt="fork过程"><figcaption aria-hidden="true">fork过程</figcaption></figure><h5 id="总结">总结</h5><p>RDB 方式 bgsave 的基本流程？</p><ul><li>fork 主进程得到一个子进程，共享内存空间</li><li>子进程读取内存数据并写入新的 RDB 文件</li><li>用新 RDB 文件替换旧的 RDB 文件</li></ul><p>RDB 的缺点？</p><ul><li>RDB 执行间隔时间长，两次 RDB 之间写入数据有丢失的风险</li><li>fork 子进程、压缩、写出 RDB 文件都比较耗时</li></ul><h4 id="aof-持久化">AOF 持久化</h4><p>AOF 全称为<code>Append Only File</code>（追加文件）。Redis 处理的<strong>每一个写命令</strong>都会记录在 AOF 文件，可以看做是命令日志文件。</p><p><img src="http://img.catpaws.top/img/无标题-2024-12-2411_24_48.png" srcset="/img/loading.gif" lazyload alt="AOF" style="zoom:80%"></p><h5 id="相关配置">相关配置</h5><p>AOF<strong>默认是关闭</strong>的，需要修改 redis.conf 配置文件来开启 AOF：</p><div class="code-wrapper"><pre><code class="hljs properties"><span class="hljs-comment"># 是否开启AOF功能，默认是no</span>
<span class="hljs-attr">appendonly</span> <span class="hljs-string">yes</span>
<span class="hljs-comment"># AOF文件的名称</span>
<span class="hljs-attr">appendfilename</span> <span class="hljs-string">&quot;appendonly.aof&quot;</span></code></pre></div><p>AOF 的命令记录的频率也可以通过 redis.conf 文件来配：</p><div class="code-wrapper"><pre><code class="hljs properties"><span class="hljs-comment"># 表示每执行一次写命令，立即记录到AOF文件</span>
<span class="hljs-attr">appendfsync</span> <span class="hljs-string">always</span>
<span class="hljs-comment"># 写命令执行完先放入AOF缓冲区，然后表示每隔1秒将缓冲区数据写到AOF文件，是**默认方案**</span>
<span class="hljs-attr">appendfsync</span> <span class="hljs-string">everysec</span>
<span class="hljs-comment"># 写命令执行完先放入AOF缓冲区，由操作系统决定何时将缓冲区内容写回磁盘</span>
<span class="hljs-attr">appendfsync</span> <span class="hljs-string">no</span></code></pre></div><figure><img src="http://img.catpaws.top/img/image-20241224112620896-2024-12-2411_26_22.png" srcset="/img/loading.gif" lazyload alt="三种策略对比"><figcaption aria-hidden="true">三种策略对比</figcaption></figure><h5 id="aof-文件重写">AOF 文件重写</h5><p>因为是记录命令，AOF 文件会比 RDB 文件大的多。而且 AOF 会记录对同一个 key 的多次写操作，但<strong>只有最后一次写操作才有意义</strong>。通过执行<code>bgrewriteaof</code>命令，可以让 AOF 文件执行重写功能，用最少的命令达到相同效果。</p><figure><img src="http://img.catpaws.top/img/image-20241224112752086-2024-12-2411_27_53.png" srcset="/img/loading.gif" lazyload alt="image-20241224112752086"><figcaption aria-hidden="true">image-20241224112752086</figcaption></figure><blockquote><p>如图，AOF 原本有三个命令，但是<code>set num 123 和 set num 666</code>都是对 num 的操作，第二次会覆盖第一次的值，因此第一个命令记录下来没有意义。所以重写命令后，AOF 文件内容就是：<code>mset name jack num 666</code></p><p><code>bgrewriteaof</code>命令也是<strong>异步</strong>的，会开启新的进程完成。</p></blockquote><p>Redis 也会在触发阈值时自动去重写 AOF 文件。阈值也可以在 redis.conf 中配置：</p><div class="code-wrapper"><pre><code class="hljs properties"><span class="hljs-comment"># AOF文件比上次文件 增长超过多少百分比则触发重写</span>
<span class="hljs-attr">auto-aof-rewrite-percentage</span> <span class="hljs-string">100</span>
<span class="hljs-comment"># AOF文件体积最小多大以上才触发重写</span>
<span class="hljs-attr">auto-aof-rewrite-min-size</span> <span class="hljs-string">64mb</span></code></pre></div><h4 id="rdb-和-aof-对比">RDB 和 AOF 对比</h4><p>RDB 和 AOF 各有自己的优缺点，如果对数据安全性要求较高，在实际开发中往往会<strong>结合</strong>两者来使用。</p><figure><img src="http://img.catpaws.top/img/image-20241224112928342-2024-12-2411_29_29.png" srcset="/img/loading.gif" lazyload alt="RDB和AOF对比"><figcaption aria-hidden="true">RDB和AOF对比</figcaption></figure><h3 id="redis-主从">1.2、Redis 主从</h3><p>单节点 Redis 的并发能力是有上限的，要进一步提高 Redis 的并发能力，就需要搭建主从集群，实现读写分离。</p><figure><img src="http://img.catpaws.top/img/image-20241224151621838-2024-12-2415_16_43.png" srcset="/img/loading.gif" lazyload alt="image-20241224151621838"><figcaption aria-hidden="true">image-20241224151621838</figcaption></figure><h4 id="搭建主从集群">搭建主从集群</h4><p><a href="https://catpaws.top/3e4345d9/#redis主从集群">参考教程</a></p><h4 id="开启主从关系">开启主从关系</h4><p>现在三个实例还没有任何关系，要配置主从可以使用<code>replicaof</code> 或者<code>slaveof</code>（5.0 以前）命令。</p><p>有临时和永久两种模式：</p><ul><li><p>修改配置文件（<strong>永久生效</strong>）</p><p>在 redis.conf 中添加一行配置：<code>slaveof &lt;masterip&gt; &lt;masterport&gt;</code></p></li><li><p>使用 redis-cli 客户端连接到 redis 服务，执行 slaveof 命令（<strong>重启后失效</strong>）：</p><div class="code-wrapper"><pre><code class="hljs sh">slaveof &lt;masterip&gt; &lt;masterport&gt;</code></pre></div></li></ul><p>通过 redis-cli 命令连接 7002，执行下面命令：</p><div class="code-wrapper"><pre><code class="hljs sh"><span class="hljs-comment"># 连接 7002</span>
redis-cli -p 7002
<span class="hljs-comment"># 执行slaveof</span>
slaveof 192.168.150.101 7001</code></pre></div><p>通过 redis-cli 命令连接 7003，执行下面命令：</p><div class="code-wrapper"><pre><code class="hljs sh"><span class="hljs-comment"># 连接 7003</span>
redis-cli -p 7003
<span class="hljs-comment"># 执行slaveof</span>
slaveof 192.168.150.101 7001</code></pre></div><p>然后连接 7001 节点，查看集群状态：</p><div class="code-wrapper"><pre><code class="hljs sh"><span class="hljs-comment"># 连接 7001</span>
redis-cli -p 7001
<span class="hljs-comment"># 查看状态</span>
info replication</code></pre></div><figure><img src="http://img.catpaws.top/img/image-20241224152930388-2024-12-2415_29_31.png" srcset="/img/loading.gif" lazyload alt="image-20241224152930388"><figcaption aria-hidden="true">image-20241224152930388</figcaption></figure><p>测试：只有在 7001 这个 master 节点上可以执行写操作，7002 和 7003 这两个 slave 节点只能执行读操作。</p><figure><img src="http://img.catpaws.top/img/image-20241224153322376-2024-12-2415_33_55.png" srcset="/img/loading.gif" lazyload alt="image-20241224153322376"><figcaption aria-hidden="true">image-20241224153322376</figcaption></figure><h4 id="主从数据同步原理">主从数据同步原理</h4><h5 id="全量同步">全量同步</h5><p>主从第一次建立连接时，会执行<strong>全量同步</strong>，将 master 节点的所有数据都拷贝给 slave 节点。</p><figure><img src="http://img.catpaws.top/img/无标题-2024-12-2415_39_06.png" srcset="/img/loading.gif" lazyload alt="全量同步"><figcaption aria-hidden="true">全量同步</figcaption></figure><p>master 如何得知 salve 是第一次来连接呢？？</p><p>有几个概念，可以作为判断依据：</p><ul><li><strong><code>Replication Id</code></strong>：简称<code>replid</code>，是数据集的标记，id 一致则说明是同一数据集。每一个 master 都有唯一的<code>replid</code>，slave 则会继承 master 节点的<code>replid</code></li><li><strong><code>offset</code></strong>：偏移量，随着记录在<code>repl_baklog</code>中的数据增多而逐渐增大。slave 完成同步时也会记录当前同步的<code>offset</code>。如果 slave 的<code>offset</code>小于 master 的<code>offset</code>，说明 slave 数据落后于 master，需要更新。</li></ul><p>因此 slave 做数据同步，必须向 master 声明自己的<code>replication id</code> 和<code>offset</code>，master 才可以判断到底需要同步哪些数据。</p><blockquote><p>slave 原本也是一个 master，有自己的 replid 和 offset，当第一次变成 slave，与 master 建立连接时，发送的 replid 和 offset 是自己的 replid 和 offset。</p><p>master 判断发现 slave 发送来的 replid 与自己的不一致，说明这是一个全新的 slave，就知道要做全量同步了。</p><p>master 会将自己的 replid 和 offset 都发送给这个 slave，slave 保存这些信息。以后 slave 的 replid 就与 master 一致了。</p></blockquote><p>完整流程：</p><ul><li>slave 节点请求增量同步</li><li>master 节点判断 replid，发现不一致，拒绝增量同步</li><li>master 将完整内存数据生成 RDB，发送 RDB 到 slave</li><li>slave 清空本地数据，加载 master 的 RDB</li><li>master 将 RDB 期间的命令记录在 repl_backlog，并持续将 log 中的命令发送给 slave</li><li>slave 执行接收到的命令，保持与 master 之间的同步</li></ul><h5 id="增量同步">增量同步</h5><p>全量同步需要先做 RDB，然后将 RDB 文件通过网络传输个 slave，耗时太长。因此除了第一次做全量同步，其它大多数时候 slave 与 master 都是做<strong>增量同步</strong>。</p><p>增量同步：只更新 slave 与 master 存在差异的部分数据</p><figure><img src="http://img.catpaws.top/img/image-20241224154926283-2024-12-2415_49_27.png" srcset="/img/loading.gif" lazyload alt="image-20241224154926283"><figcaption aria-hidden="true">image-20241224154926283</figcaption></figure><p>主节点会维护一个 <code>repl_backlog</code> <strong>环形缓冲区</strong>，并不断更新其中的命令日志和偏移量信息。从节点在断连并重新连接主节点时，会发送自己的当前偏移量给主节点。主节点会根据从节点提供的偏移量，在 <code>repl_backlog</code> 中查找对应的日志位置，将之后的新命令发送给从节点，实现数据同步。</p><figure><img src="http://img.catpaws.top/img/image-20241224160654992-2024-12-2416_06_56.png" srcset="/img/loading.gif" lazyload alt="image-20241224160654992"><figcaption aria-hidden="true">image-20241224160654992</figcaption></figure><p>如果 slave 出现网络阻塞，导致 master 的 offset 远远超过了 slave 的 offset，此时 master 继续写入新数据，其 offset 就会覆盖旧的数据，直到将 slave 现在的 offset 也覆盖。棕色框中的红色部分，就是尚未同步，但是却已经被覆盖的数据。此时如果 slave 恢复，需要同步，却发现自己的 offset 都没有了，无法完成增量同步了，只能做<strong>全量同步</strong>。</p><figure><img src="http://img.catpaws.top/img/image-20241224160909032-2024-12-2416_09_10.png" srcset="/img/loading.gif" lazyload alt="image-20241224160909032"><figcaption aria-hidden="true">image-20241224160909032</figcaption></figure><h4 id="主从同步优化">主从同步优化</h4><p>主从同步可以保证主从数据的一致性，非常重要。可以从以下几个方面来优化 Redis 主从就集群：</p><ul><li><p>在 master 中配置 repl-diskless-sync yes 启用无磁盘复制，避免全量同步时的磁盘 IO。</p><blockquote><p>当设置<code>repl-diskless-sync yes</code>时，主节点会直接将内存中的数据通过网络发送给从节点，省去了生成 RDB 文件和写入磁盘的步骤，从而提高了复制的效率 ‌</p></blockquote></li><li><p>Redis 单节点上的内存占用不要太大，减少 RDB 导致的过多磁盘 IO</p></li><li><p>适当提高<code>repl_backlog</code>的大小，发现 slave 宕机时尽快实现故障恢复，尽可能避免全量同步</p></li><li><p>限制一个 master 上的 slave 节点数量，如果实在是太多 slave，则可以采用主-从-从链式结构，减少 master 压力</p><figure><img src="http://img.catpaws.top/img/image-20241224161546157-2024-12-2416_15_47.png" srcset="/img/loading.gif" lazyload alt="主-从-从链式结构"><figcaption aria-hidden="true">主-从-从链式结构</figcaption></figure></li></ul><h4 id="总结-1">总结</h4><p>简述全量同步和增量同步区别？</p><ul><li>全量同步：master 将完整内存数据生成 RDB，发送 RDB 到 slave。后续命令则记录在<code>repl_baklog</code>，逐个发送给 slave。</li><li>增量同步：slave 提交自己的 offset 到 master，master 获取<code>repl_baklog</code>中从 offset 之后的命令给 slave</li></ul><p>什么时候执行全量同步？</p><ul><li>slave 节点第一次连接 master 节点时</li><li>slave 节点断开时间太久，<code>repl_baklog</code>中的 offset 已经被覆盖时</li></ul><p>什么时候执行增量同步？</p><ul><li>slave 节点断开又恢复，并且在 r<code>epl_baklog</code>中能找到 offset 时</li></ul><h3 id="redis-哨兵">1.3、Redis 哨兵</h3><p>Redis 提供了哨兵（Sentinel）机制来实现主从集群的自动故障恢复。哨兵的结构和功能如下:</p><ul><li><strong>监控</strong>：Sentinel 会不断检查您的 master 和 slave 是否按预期工作</li><li><strong>自动故障恢复</strong>：如果 master 故障，Sentinel 会将一个 slave 提升为 master。当故障实例恢复后也以新的 master 为主</li><li><strong>通知</strong>：Sentinel 充当 Redis 客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给 Redis 的客户端</li></ul><p><img src="http://img.catpaws.top/img/image-20241224162530556-2024-12-2416_25_32.png" srcset="/img/loading.gif" lazyload alt="image-20241224162530556" style="zoom:80%"></p><h4 id="集群监控原理">集群监控原理</h4><p>Sentinel 基于<strong>心跳机制</strong>监测服务状态，每隔 1 秒向集群的每个实例发送 ping 命令：</p><p>•主观下线：如果某 sentinel 节点发现某实例未在规定时间响应，则认为该实例<strong>主观下线</strong>。</p><p>•客观下线：若超过指定数量（quorum）的 sentinel 都认为该实例主观下线，则该实例<strong>客观下线</strong>。quorum 值最好超过 Sentinel 实例数量的一半。</p><p><img src="http://img.catpaws.top/img/image-20241224162742910-2024-12-2416_27_44.png" srcset="/img/loading.gif" lazyload alt="image-20241224162742910" style="zoom:80%"></p><h4 id="集群故障恢复原理">集群故障恢复原理</h4><p>一旦发现 master 故障，sentinel 需要在 salve 中选择一个作为新的 master，规则如下：</p><ul><li>首先会判断 slave 节点与 master 节点断开时间长短，如果超过指定值（down-after-milliseconds * 10）则会排除该 slave 节点。（数据太旧了）</li><li>然后判断 slave 节点的<code>slave-priority</code>值，越小优先级越高，如果是 0 则永不参与选举</li><li>如果<code>slave-priority</code>一样，则判断 slave 节点的<code>offset</code>值，越大说明数据越新，优先级越高（主要）</li><li>最后是判断 slave 节点的运行 id 大小，越小优先级越高。</li></ul><p>当选出一个新的 master 后，由哨兵实现结点角色切换，流程如下：</p><ul><li>sentinel 给备选的 slave1 节点，如 7002，发送<code>slaveof no one</code>命令，让该节点成为 master</li><li>sentinel 给所有其它 slave 发送<code>slaveof 192.168.150.101 7002</code> 命令，让这些 slave 成为新 master 的从节点，开始从新的 master 上同步数据。</li><li>最后，sentinel 将故障节点标记为 slave，当故障节点恢复后会自动成为新的 master 的 slave 节点</li></ul><p><img src="http://img.catpaws.top/img/image-20241224163250288-2024-12-2416_32_51.png" srcset="/img/loading.gif" lazyload alt="image-20241224163250288" style="zoom:80%"></p><h4 id="搭建哨兵集群">搭建哨兵集群</h4><p><a href="https://catpaws.top/3e4345d9/#搭建哨兵集群">参考教程</a></p><h4 id="redistemplate-的哨兵模式">RedisTemplate 的哨兵模式</h4><p>在 Sentinel 集群监管下的 Redis 主从集群，其节点会因为自动故障转移而发生变化，Redis 的客户端必须感知这种变化，及时更新连接信息。Spring 的 RedisTemplate 底层利用 lettuce 实现了节点的感知和自动切换。</p><p>1）引入依赖</p><p>在项目的 pom 文件中引入依赖：</p><div class="code-wrapper"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.boot<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-boot-starter-data-redis<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span></code></pre></div><p>2）配置 Redis 地址</p><p>然后在配置文件 application.yml 中指定 redis 的<strong>sentinel</strong>相关信息：</p><blockquote><p>在集群模式下，主从结点的地址会发生变更，不能写死，只需指定哨兵的地址即可</p></blockquote><div class="code-wrapper"><pre><code class="hljs java">spring:
  redis:
    sentinel:
      master: mymaster
      nodes:
        - <span class="hljs-number">192.168</span><span class="hljs-number">.150</span><span class="hljs-number">.101</span>:<span class="hljs-number">27001</span>
        - <span class="hljs-number">192.168</span><span class="hljs-number">.150</span><span class="hljs-number">.101</span>:<span class="hljs-number">27002</span>
        - <span class="hljs-number">192.168</span><span class="hljs-number">.150</span><span class="hljs-number">.101</span>:<span class="hljs-number">27003</span></code></pre></div><p>3）配置读写分离</p><p>在配置类，添加一个新的 bean，指定读写策略</p><div class="code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@Bean</span>
<span class="hljs-keyword">public</span> LettuceClientConfigurationBuilderCustomizer <span class="hljs-title function_">clientConfigurationBuilderCustomizer</span><span class="hljs-params">()</span>&#123;
    <span class="hljs-keyword">return</span> clientConfigurationBuilder -&gt; clientConfigurationBuilder.readFrom(ReadFrom.REPLICA_PREFERRED);
&#125;</code></pre></div><p>这个 bean 中配置的就是读写策略，包括四种：</p><ul><li>MASTER：从主节点读取</li><li>MASTER_PREFERRED：优先从 master 节点读取，master 不可用才读取 replica</li><li>REPLICA：从 slave（replica）节点读取</li><li>REPLICA _PREFERRED：优先从 slave（replica）节点读取，所有的 slave 都不可用才读取 master</li></ul><h3 id="redis-分片集群">1.4、Redis 分片集群</h3><h4 id="搭建分片集群">搭建分片集群</h4><p><a href="https://catpaws.top/3e4345d9/#搭建分片集群">参考教程</a></p><h4 id="散列插槽">散列插槽</h4><p>Redis 会把每一个 master 节点映射到 0~16383 共<strong>16384</strong>个插槽（hash slot）上，查看集群信息时就能看到：</p><figure><img src="http://img.catpaws.top/img/image-20241226104103728-2024-12-2610_41_17.png" srcset="/img/loading.gif" lazyload alt="集群建成时显示的信息"><figcaption aria-hidden="true">集群建成时显示的信息</figcaption></figure><p>连接到某节点使用<code>cluster nodes</code>查看集群节点信息</p><p><img src="http://img.catpaws.top/img/image-20241226104236033-2024-12-2610_42_37.png" srcset="/img/loading.gif" lazyload alt="使用命令查看集群结点信息" style="zoom:80%"></p><p><strong><u>数据 key 不是与节点绑定，而是与插槽绑定。</u></strong></p><blockquote><p>‌<strong>Redis 的数据与插槽绑定而不是与节点绑定，主要是为了实现集群的动态伸缩和高可用性。</strong>‌</p><p>详细来说，与插槽绑定相比，与节点绑定存在明显的局限性。如果数据与特定节点绑定，那么一旦该节点出现故障或需要扩容，数据的迁移和重新分配将变得非常复杂和耗时。而与插槽绑定则不同，插槽可以灵活地映射到不同的节点上。当某个节点出现故障或需要扩容时，<u>只需将相关插槽重新映射到其他健康的节点上即可，无需大规模的数据迁移 ‌</u>。</p><p>此外，与插槽绑定还使得 Redis 集群能够更轻松地实现数据的均衡分布。通过散列插槽的方式，可以将数据均匀地分散到集群中的各个节点上，从而避免某些节点过载或闲置的情况 ‌。这种均衡分布不仅提高了集群的整体性能，还增强了集群的可扩展性和灵活性 ‌</p></blockquote><p>redis 会根据 key 的有效部分计算插槽值，分两种情况：</p><ul><li>key 中包含"{}"，且“{}”中至少包含 1 个字符，“{}”中的部分是有效部分</li><li>key 中不包含“{}”，整个 key 都是有效部分</li></ul><p>在分片集群模式下，要获得/设置一个 key 对应的数据，会首先根据 key 的有效部分计算哈希值，对 16384 取余，余数作为插槽，定位到该插槽所在的节点，重定向到目标节点，在该节点上执行数据存入或读取操作。</p><figure><img src="http://img.catpaws.top/img/image-20241226105823747-2024-12-2610_58_25.png" srcset="/img/loading.gif" lazyload alt="image-20241226105823747"><figcaption aria-hidden="true">image-20241226105823747</figcaption></figure><p>如上，在 7001 节点执行<code>set a 111</code>命令，a 对应的插槽值为 15495，该插槽分配给了 7003 节点，故先重定向到 7003 节点，再执行该命令。此时在 7003 结点上执行<code>set num 123</code>命令，执行过程相同。在 7001 结点读取 a 对应的值，会先切换到 7003 节点再返回 a 的值。</p><blockquote><p>在分片集群模式下连接到某个节点时，在命令中一定要加上<code>-c</code>参数，如</p><div class="code-wrapper"><pre><code class="hljs bash">redis-cli -c -p 7001</code></pre></div></blockquote><p>如何将同一类数据固定的保存在同一个 Redis 实例？</p><ul><li>这一类数据使用相同的有效部分，例如 key 都以{typeId}为前缀</li></ul><h4 id="集群伸缩">集群伸缩</h4><p>redis-cli --cluster 提供了很多操作集群的命令，可以新增节点，删除节点，重新分配插槽等，可以通过<code>redis-cli --cluster help</code>命令查看：</p><figure><img src="http://img.catpaws.top/img/image-20241226110615386-2024-12-2611_06_16.png" srcset="/img/loading.gif" lazyload alt="image-20241226110615386"><figcaption aria-hidden="true">image-20241226110615386</figcaption></figure><p>需求：向集群中添加一个新的 master 节点，并向其中存储 num = 10</p><ul><li>启动一个新的 redis 实例，端口为 7004</li><li>添加 7004 到之前的集群，并作为一个 master 节点</li><li>给 7004 节点<u>分配插槽</u>，使得 num 这个 key 可以存储到 7004 实例</li></ul><p>1、创建新的 redis 实例</p><div class="code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment">#创建一个文件夹</span>
<span class="hljs-built_in">mkdir</span> 7004
<span class="hljs-comment">#拷贝配置文件</span>
<span class="hljs-built_in">cp</span> redis.conf /7004
<span class="hljs-comment">#修改配置文件 将其中初始的所有6379改为7004</span>
sed /s/6379/7004/g 7004/redis.conf
<span class="hljs-comment">#启动</span>
redis-server 7004/redis.conf</code></pre></div><figure><img src="http://img.catpaws.top/img/image-20241226112143003-2024-12-2611_21_44.png" srcset="/img/loading.gif" lazyload alt="image-20241226112143003"><figcaption aria-hidden="true">image-20241226112143003</figcaption></figure><p>2、添加新结点到 Redis 集群</p><p>通过<code>redis-cli --cluset help</code>命令查看集群相关操作，其中有关添加新节点的命令如下</p><div class="code-wrapper"><pre><code class="hljs bash">add-node       new_host:new_port existing_host:existing_port <span class="hljs-comment">#新节点地址和端口，集群中某节点的地址和端口（将新节点的信息通过它通知给其他节点）</span>
                --cluster-slave   <span class="hljs-comment">#设置为slave节点，默认为master节点</span>
                --cluster-master-id &lt;arg&gt; <span class="hljs-comment">#对应master的id</span></code></pre></div><p>将 7004 节点加入集群：</p><div class="code-wrapper"><pre><code class="hljs bash">redis-cli --cluster add-node 192.168.181.100:7004 192.168.181.100:7001</code></pre></div><figure><img src="http://img.catpaws.top/img/image-20241226113344409-2024-12-2611_33_45.png" srcset="/img/loading.gif" lazyload alt="image-20241226113344409"><figcaption aria-hidden="true">image-20241226113344409</figcaption></figure><p>3、转移插槽</p><p>num 的插槽值为 2765，要将 num 这个 key 移到 7004 节点，只需将前 2766 个插槽移到 7004 节点。</p><figure><img src="http://img.catpaws.top/img/image-20241226113557285-2024-12-2611_36_02.png" srcset="/img/loading.gif" lazyload alt="num的插槽值为2765"><figcaption aria-hidden="true">num的插槽值为2765</figcaption></figure><p>集群中插槽转移的命令如下，</p><div class="code-wrapper"><pre><code class="hljs bash">reshard        &lt;host:port&gt; or &lt;host&gt; &lt;port&gt; - separated by either colon or space
                 --cluster-from &lt;arg&gt;
                 --cluster-to &lt;arg&gt;
                 --cluster-slots &lt;arg&gt;
                 --cluster-yes
                 --cluster-timeout &lt;arg&gt;
                 --cluster-pipeline &lt;arg&gt;
                 --cluster-replace</code></pre></div><p>使用<code>redis-cli --cluster reshard 192.168.181.100:7004</code>采用交互式方式输入参数。</p><figure><img src="http://img.catpaws.top/img/image-20241226120318618-2024-12-2612_03_48.png" srcset="/img/loading.gif" lazyload alt="image-20241226120318618"><figcaption aria-hidden="true">image-20241226120318618</figcaption></figure><p>4、在 7004 结点上读取 num 值</p><figure><img src="http://img.catpaws.top/img/image-20241226120412193-2024-12-2612_04_13.png" srcset="/img/loading.gif" lazyload alt="image-20241226120412193"><figcaption aria-hidden="true">image-20241226120412193</figcaption></figure><blockquote><p>此时若要删除 7004 节点，需要先将分配给该结点的插槽转移到其他节点后再删除。</p></blockquote><h4 id="故障转移">故障转移</h4><p>集群的初始状态如下，其中 7001、7002、7003 都是 master，计划让 7002 宕机。</p><figure><img src="http://img.catpaws.top/img/image-20241226124827478-2024-12-2612_48_29.png" srcset="/img/loading.gif" lazyload alt="image-20241226124827478"><figcaption aria-hidden="true">image-20241226124827478</figcaption></figure><h5 id="自动故障转移">自动故障转移</h5><p>执行<code>redis-cli -p 7002 shutdown</code>让 7002 节宕机，通过<code>watch redis-cli -p 7001 cluster nodes</code>监视集群节点的情况。</p><p>1）首先是该实例与其它实例失去连接</p><p>2）然后是疑似宕机：</p><figure><img src="http://img.catpaws.top/img/8b80a1c09i77259f06581dc277354178-2024-12-2612_47_21.jpg" srcset="/img/loading.gif" lazyload alt="8b80a1c09i77259f06581dc277354178"><figcaption aria-hidden="true">8b80a1c09i77259f06581dc277354178</figcaption></figure><p>3）最后是确定下线，自动提升一个 slave 为新的 master：</p><figure><img src="http://img.catpaws.top/img/image-20241226125056817-2024-12-2612_50_58.png" srcset="/img/loading.gif" lazyload alt="image-20241226125056817"><figcaption aria-hidden="true">image-20241226125056817</figcaption></figure><p>4）当 7002 再次启动，就会变为一个 slave 节点了，自动完成主从切换</p><figure><img src="http://img.catpaws.top/img/7f4b21650k45c7f367c97946638748d2-2024-12-2612_52_06.jpg" srcset="/img/loading.gif" lazyload alt="7f4b21650k45c7f367c97946638748d2"><figcaption aria-hidden="true">7f4b21650k45c7f367c97946638748d2</figcaption></figure><h5 id="手动故障转移数据迁移">手动故障转移（数据迁移）</h5><p>利用<code>cluster failover</code>命令可以手动让集群中的某个 master 宕机，切换到执行 cluster failover 命令的这个<strong>slave 节点</strong>，实现无感知的数据迁移。其流程如下：</p><p><img src="http://img.catpaws.top/img/image-20241226125548348-2024-12-2612_55_49.png" srcset="/img/loading.gif" lazyload alt="image-20241226125548348" style="zoom:80%"></p><p>手动的 Failover 支持三种不同模式：</p><ul><li>缺省：默认的流程，如图 1~6 步</li><li>force：省略了对 offset 的一致性校验</li><li>takeover：直接执行第 5 步，忽略数据一致性、忽略 master 状态和其它 master 的意见</li></ul><p>需求：在 7002 这个 slave 节点执行手动故障转移，重新夺回 master 地位</p><p>步骤如下：</p><p>1）利用 redis-cli 连接 7002 这个节点</p><p>2）执行 cluster failover 命令</p><figure><img src="http://img.catpaws.top/img/image-20241226130403702-2024-12-2613_04_05.png" srcset="/img/loading.gif" lazyload alt="image-20241226130403702"><figcaption aria-hidden="true">image-20241226130403702</figcaption></figure><h4 id="redistemplate-访问分片集群">RedisTemplate 访问分片集群</h4><p>RedisTemplate 底层同样基于 lettuce 实现了分片集群的支持，而使用的步骤与哨兵模式基本一致：</p><p>1）引入 redis 的 starter 依赖</p><p>2）配置分片集群地址</p><p>3）配置读写分离</p><p>与哨兵模式相比，其中只有分片集群的配置方式略有差异，如下：</p><div class="code-wrapper"><pre><code class="hljs yaml"><span class="hljs-attr">spring:</span>
  <span class="hljs-attr">redis:</span>
    <span class="hljs-attr">cluster:</span>
      <span class="hljs-attr">nodes:</span> <span class="hljs-comment">#指定分片集群的每一个节点信息</span>
        <span class="hljs-bullet">-</span> <span class="hljs-number">192.168</span><span class="hljs-number">.150</span><span class="hljs-number">.101</span><span class="hljs-string">:7001</span>
        <span class="hljs-bullet">-</span> <span class="hljs-number">192.168</span><span class="hljs-number">.150</span><span class="hljs-number">.101</span><span class="hljs-string">:7002</span>
        <span class="hljs-bullet">-</span> <span class="hljs-number">192.168</span><span class="hljs-number">.150</span><span class="hljs-number">.101</span><span class="hljs-string">:7003</span>
        <span class="hljs-bullet">-</span> <span class="hljs-number">192.168</span><span class="hljs-number">.150</span><span class="hljs-number">.101</span><span class="hljs-string">:8001</span>
        <span class="hljs-bullet">-</span> <span class="hljs-number">192.168</span><span class="hljs-number">.150</span><span class="hljs-number">.101</span><span class="hljs-string">:8002</span>
        <span class="hljs-bullet">-</span> <span class="hljs-number">192.168</span><span class="hljs-number">.150</span><span class="hljs-number">.101</span><span class="hljs-string">:8003</span></code></pre></div><h2 id="二多级缓存">二、多级缓存</h2><h3 id="什么是多级缓存">2.1、什么是多级缓存</h3><p>传统的缓存策略一般是请求到达 Tomcat 后，先查询 Redis，如果未命中则查询数据库，如图：</p><figure><img src="http://img.catpaws.top/img/image-20210821075259137-2024-12-2614_46_17.png" srcset="/img/loading.gif" lazyload alt="image-20210821075259137"><figcaption aria-hidden="true">image-20210821075259137</figcaption></figure><p>存在下面的问题：</p><p>•请求要经过 Tomcat 处理，Tomcat 的性能成为整个系统的瓶颈</p><p>•Redis 缓存失效时，会对数据库产生冲击</p><p>多级缓存就是充分利用请求处理的每个环节，分别添加缓存，减轻 Tomcat 压力，提升服务性能：</p><ul><li>浏览器访问静态资源时，优先读取浏览器本地缓存</li><li>访问非静态资源（ajax 查询数据）时，访问服务端</li><li>请求到达 Nginx 后，优先读取 Nginx 本地缓存</li><li>如果 Nginx 本地缓存未命中，则去直接查询 Redis（不经过 Tomcat）</li><li>如果 Redis 查询未命中，则查询 Tomcat</li><li>请求进入 Tomcat 后，优先查询 JVM 进程缓存</li><li>如果 JVM 进程缓存未命中，则查询数据库</li></ul><figure><img src="http://img.catpaws.top/img/image-20210821075558137-2024-12-2614_47_22.png" srcset="/img/loading.gif" lazyload alt="image-20210821075558137"><figcaption aria-hidden="true">image-20210821075558137</figcaption></figure><p>在多级缓存架构中，Nginx 内部需要编写本地缓存查询、Redis 查询、Tomcat 查询的业务逻辑，因此这样的 nginx 服务不再是一个<strong>反向代理服务器</strong>，而是一个编写<strong>业务的 Web 服务器了</strong>。</p><p>因此这样的业务 Nginx 服务也需要搭建集群来提高并发，再有专门的 nginx 服务来做反向代理。同时，Tomcat 服务将来也会部署为集群模式</p><figure><img src="http://img.catpaws.top/img/image-20210821080954947-2024-12-2614_50_15.png" srcset="/img/loading.gif" lazyload alt="image-20210821080954947"><figcaption aria-hidden="true">image-20210821080954947</figcaption></figure><p>可见，多级缓存的关键有两个：</p><ul><li><p>一个是在 nginx 中编写业务，实现 nginx 本地缓存、对 Redis 和 Tomcat 的查询</p></li><li><p>另一个就是在 Tomcat 中实现 JVM 进程缓存</p></li></ul><p>其中 Nginx 编程则会用到<code>OpenResty</code>框架结合 Lua 这样的语言。</p><h3 id="导入案例">2.2、导入案例</h3><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1cr4y1671t?vd_source=51d78ede0a0127d1839d6abf9204d1ee&amp;spm_id_from=333.788.videopod.episodes&amp;p=115">参考视频</a></p><p><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1189u6u4icQYHg_9_7ovWmA?pwd=eh11&amp;_at_=1735005945139#list/path=%2Fsharelink3232509500-235828228909890%2F7%E3%80%81Redis%E5%85%A5%E9%97%A8%E5%88%B0%E5%AE%9E%E6%88%98%E6%95%99%E7%A8%8B%2FRedis-%E7%AC%94%E8%AE%B0%E8%B5%84%E6%96%99%2F03-%E9%AB%98%E7%BA%A7%E7%AF%87%2F%E8%B5%84%E6%96%99%2Fitem-service&amp;parentPath=%2Fsharelink3232509500-235828228909890">后端文件</a></p><p><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1189u6u4icQYHg_9_7ovWmA?pwd=eh11&amp;_at_=1735005945139#list/path=%2Fsharelink3232509500-235828228909890%2F7%E3%80%81Redis%E5%85%A5%E9%97%A8%E5%88%B0%E5%AE%9E%E6%88%98%E6%95%99%E7%A8%8B%2FRedis-%E7%AC%94%E8%AE%B0%E8%B5%84%E6%96%99%2F03-%E9%AB%98%E7%BA%A7%E7%AF%87%2F%E8%B5%84%E6%96%99%2Fnginx-1.18.0&amp;parentPath=%2Fsharelink3232509500-235828228909890">前端文件</a></p><h3 id="jvm-进程缓存">2.3、JVM 进程缓存</h3><h4 id="初识-caffeine">初识 Caffeine</h4><p>缓存在日常开发中启动至关重要的作用，由于是存储在内存中，数据的读取速度是非常快的，能大量减少对数据库的访问，减 x 少数据库的压力。我们把缓存分为两类：</p><ul><li>分布式缓存，例如 Redis：<ul><li>优点：存储容量更大、可靠性更好、可以在集群间共享</li><li>缺点：访问缓存有网络开销</li><li>场景：缓存数据量较大、可靠性要求较高、需要在集群间共享</li></ul></li><li>进程本地缓存，例如 HashMap、GuavaCache：<ul><li>优点：读取本地内存，没有网络开销，速度更快</li><li>缺点：存储容量有限、可靠性较低、无法共享</li><li>场景：性能要求较高，缓存数据量较小</li></ul></li></ul><p><strong>Caffeine</strong>是一个基于 Java8 开发的，提供了近乎最佳命中率的高性能的本地缓存库。目前 Spring 内部的缓存使用的就是 Caffeine。GitHub 地址：https://github.com/ben-manes/caffeine</p><p>Caffeine 的性能非常好，下图是官方给出的性能对比：</p><figure><img src="http://img.catpaws.top/img/image-20210821081826399-2024-12-2618_34_57.png" srcset="/img/loading.gif" lazyload alt="image-20210821081826399"><figcaption aria-hidden="true">image-20210821081826399</figcaption></figure><p>缓存 API 基本使用</p><div class="code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@Test</span>
<span class="hljs-keyword">void</span> <span class="hljs-title function_">testBasicOps</span><span class="hljs-params">()</span> &#123;
    <span class="hljs-comment">// 构建cache对象</span>
    Cache&lt;String, String&gt; cache = Caffeine.newBuilder().build();

    <span class="hljs-comment">// 存数据</span>
    cache.put(<span class="hljs-string">&quot;gf&quot;</span>, <span class="hljs-string">&quot;迪丽热巴&quot;</span>);

    <span class="hljs-comment">// 取数据</span>
    <span class="hljs-type">String</span> <span class="hljs-variable">gf</span> <span class="hljs-operator">=</span> cache.getIfPresent(<span class="hljs-string">&quot;gf&quot;</span>);
    System.out.println(<span class="hljs-string">&quot;gf = &quot;</span> + gf);

    <span class="hljs-comment">// 取数据，包含两个参数：</span>
    <span class="hljs-comment">// 参数一：缓存的key</span>
    <span class="hljs-comment">// 参数二：Lambda表达式，表达式参数就是缓存的key，方法体是查询数据库的逻辑</span>
    <span class="hljs-comment">// 优先根据key查询JVM缓存，如果未命中，则执行参数二的Lambda表达式</span>
    <span class="hljs-type">String</span> <span class="hljs-variable">defaultGF</span> <span class="hljs-operator">=</span> cache.get(<span class="hljs-string">&quot;defaultGF&quot;</span>, key -&gt; &#123;
        <span class="hljs-comment">// 根据key去数据库查询数据</span>
        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;柳岩&quot;</span>;
    &#125;);
    System.out.println(<span class="hljs-string">&quot;defaultGF = &quot;</span> + defaultGF);
&#125;</code></pre></div><p>Caffeine 既然是缓存的一种，肯定需要有缓存的清除策略，不然的话内存总会有耗尽的时候。</p><p>Caffeine 提供了三种缓存驱逐策略：</p><ul><li><p><strong>基于容量</strong>：设置缓存的数量上限</p><div class="code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">// 创建缓存对象</span>
Cache&lt;String, String&gt; cache = Caffeine.newBuilder()
    .maximumSize(<span class="hljs-number">1</span>) <span class="hljs-comment">// 设置缓存大小上限为 1</span>
    .build();</code></pre></div></li><li><p><strong>基于时间</strong>：设置缓存的有效时间</p><div class="code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">// 创建缓存对象</span>
Cache&lt;String, String&gt; cache = Caffeine.newBuilder()
    <span class="hljs-comment">// 设置缓存有效期为 10 秒，从最后一次写入开始计时</span>
    .expireAfterWrite(Duration.ofSeconds(<span class="hljs-number">10</span>))
    .build();
</code></pre></div></li><li><p><strong>基于引用</strong>：设置缓存为软引用或弱引用，利用 GC 来回收缓存数据。性能较差，不建议使用。</p></li></ul><blockquote><p><strong>注意</strong>：在默认情况下，当一个缓存元素过期的时候，Caffeine 不会自动立即将其清理和驱逐。而是在一次读或写操作后，或者在空闲时间完成对失效数据的驱逐。</p></blockquote><h4 id="实现-jvm-进程缓存">实现 JVM 进程缓存</h4><p>利用 Caffeine 实现下列需求：</p><ul><li>给根据 id 查询商品的业务添加缓存，缓存未命中时查询数据库</li><li>给根据 id 查询商品库存的业务添加缓存，缓存未命中时查询数据库</li><li>缓存初始大小为 100</li><li>缓存上限为 10000</li></ul><p>首先，我们需要定义两个 Caffeine 的缓存对象，分别保存商品、库存的缓存数据。</p><p>在 item-service 的<code>com.heima.item.config</code>包下定义<code>CaffeineConfig</code>类：</p><div class="code-wrapper"><pre><code class="hljs java"><span class="hljs-keyword">package</span> com.heima.item.config;

<span class="hljs-keyword">import</span> com.github.benmanes.caffeine.cache.Cache;
<span class="hljs-keyword">import</span> com.github.benmanes.caffeine.cache.Caffeine;
<span class="hljs-keyword">import</span> com.heima.item.pojo.Item;
<span class="hljs-keyword">import</span> com.heima.item.pojo.ItemStock;
<span class="hljs-keyword">import</span> org.springframework.context.annotation.Bean;
<span class="hljs-keyword">import</span> org.springframework.context.annotation.Configuration;

<span class="hljs-meta">@Configuration</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">CaffeineConfig</span> &#123;

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-keyword">public</span> Cache&lt;Long, Item&gt; <span class="hljs-title function_">itemCache</span><span class="hljs-params">()</span>&#123;
        <span class="hljs-keyword">return</span> Caffeine.newBuilder()
                .initialCapacity(<span class="hljs-number">100</span>)
                .maximumSize(<span class="hljs-number">10_000</span>)
                .build();
    &#125;

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-keyword">public</span> Cache&lt;Long, ItemStock&gt; <span class="hljs-title function_">stockCache</span><span class="hljs-params">()</span>&#123;
        <span class="hljs-keyword">return</span> Caffeine.newBuilder()
                .initialCapacity(<span class="hljs-number">100</span>)
                .maximumSize(<span class="hljs-number">10_000</span>)
                .build();
    &#125;
&#125;</code></pre></div><p>修改 item-service 中的<code>com.heima.item.web</code>包下的 ItemController 类，添加缓存逻辑</p><div class="code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@RestController</span>
<span class="hljs-meta">@RequestMapping(&quot;item&quot;)</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ItemController</span> &#123;

    <span class="hljs-meta">@Autowired</span>
    <span class="hljs-keyword">private</span> IItemService itemService;
    <span class="hljs-meta">@Autowired</span>
    <span class="hljs-keyword">private</span> IItemStockService stockService;

    <span class="hljs-meta">@Autowired</span>
    <span class="hljs-keyword">private</span> Cache&lt;Long, Item&gt; itemCache;
    <span class="hljs-meta">@Autowired</span>
    <span class="hljs-keyword">private</span> Cache&lt;Long, ItemStock&gt; stockCache;

    <span class="hljs-comment">// ...其它略</span>

    <span class="hljs-meta">@GetMapping(&quot;/&#123;id&#125;&quot;)</span>
    <span class="hljs-keyword">public</span> Item <span class="hljs-title function_">findById</span><span class="hljs-params">(<span class="hljs-meta">@PathVariable(&quot;id&quot;)</span> Long id)</span> &#123;
        <span class="hljs-keyword">return</span> itemCache.get(id, key -&gt; itemService.query()
                .ne(<span class="hljs-string">&quot;status&quot;</span>, <span class="hljs-number">3</span>).eq(<span class="hljs-string">&quot;id&quot;</span>, key)
                .one()
        );
    &#125;

    <span class="hljs-meta">@GetMapping(&quot;/stock/&#123;id&#125;&quot;)</span>
    <span class="hljs-keyword">public</span> ItemStock <span class="hljs-title function_">findStockById</span><span class="hljs-params">(<span class="hljs-meta">@PathVariable(&quot;id&quot;)</span> Long id)</span> &#123;
        <span class="hljs-keyword">return</span> stockCache.get(id, key -&gt; stockService.getById(key));
    &#125;
&#125;</code></pre></div><h3 id="lua-入门">2.4、Lua 入门</h3><p>Nginx 编程需要用到 Lua 语言，因此我们必须先入门 Lua 的基本语法。</p><h4 id="初识-lua">初识 Lua</h4><p>Lua 是一种轻量小巧的脚本语言，用标准 C 语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。<a target="_blank" rel="noopener" href="https://www.lua.org/">官网</a></p><figure><img src="http://img.catpaws.top/img/image-20210821091437975-2024-12-2619_13_40.png" srcset="/img/loading.gif" lazyload alt="image-20210821091437975"><figcaption aria-hidden="true">image-20210821091437975</figcaption></figure><p>Lua 经常嵌入到 C 语言开发的程序中，例如游戏开发、游戏插件等。</p><p>Nginx 本身也是 C 语言开发，因此也允许基于 Lua 做拓展。</p><p><a target="_blank" rel="noopener" href="https://www.runoob.com/lua/lua-tutorial.html">语法参考</a></p><h4 id="hello-world">Hello World</h4><p>CentOS7 默认已经安装了 Lua 语言环境，所以可以直接运行 Lua 代码。</p><p>在 Linux 虚拟机的任意目录下，新建一个 hello.lua 文件</p><div class="code-wrapper"><pre><code class="hljs bash"><span class="hljs-built_in">touch</span> hello.lua</code></pre></div><p><code>vi hello.lua</code>向文件中添加</p><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Hello World!&quot;</span>)</code></pre></div><p>运行该文件</p><div class="code-wrapper"><pre><code class="hljs bash">[root@ai100 tmp]# lua hello.lua
Hello World!</code></pre></div><h4 id="变量">变量</h4><p>学习任何语言必然离不开变量，而变量的声明必须先知道数据的类型。</p><p>Lua 中支持的常见数据类型包括：</p><figure><img src="http://img.catpaws.top/img/image-20210821091835406-2024-12-2619_20_37.png" srcset="/img/loading.gif" lazyload alt="image-20210821091835406"><figcaption aria-hidden="true">image-20210821091835406</figcaption></figure><p>另外，Lua 提供了 type()函数来判断一个变量的数据类型：</p><div class="code-wrapper"><pre><code class="hljs bash">[root@ai100 tmp]# lua
Lua 5.1.4  Copyright (C) 1994-2008 Lua.org, PUC-Rio
&gt; <span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(<span class="hljs-string">&quot;Hello World!&quot;</span>))
string
&gt; <span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(10*.314))
number</code></pre></div><blockquote><p>控制台输入 <code>lua</code>，进入 lua 的命令行模式</p></blockquote><p>Lua 声明变量的时候无需指定数据类型，而是用 local 来声明变量为<strong>局部变量</strong>：</p><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-comment">-- 声明字符串，可以用单引号或双引号，</span>
<span class="hljs-keyword">local</span> str = <span class="hljs-string">&#x27;hello&#x27;</span>
<span class="hljs-comment">-- 字符串拼接可以使用 ..</span>
<span class="hljs-keyword">local</span> str2 = <span class="hljs-string">&#x27;hello&#x27;</span> .. <span class="hljs-string">&#x27;world&#x27;</span>
<span class="hljs-comment">-- 声明数字</span>
<span class="hljs-keyword">local</span> num = <span class="hljs-number">21</span>
<span class="hljs-comment">-- 声明布尔类型</span>
<span class="hljs-keyword">local</span> flag = <span class="hljs-literal">true</span></code></pre></div><p>Lua 中的 table 类型既可以作为数组，又可以作为 Java 中的 map 来使用。数组就是特殊的 table，key 是数组角标而已：</p><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-comment">-- 声明数组 ，key为角标的 table</span>
<span class="hljs-keyword">local</span> arr = &#123;<span class="hljs-string">&#x27;java&#x27;</span>, <span class="hljs-string">&#x27;python&#x27;</span>, <span class="hljs-string">&#x27;lua&#x27;</span>&#125;
<span class="hljs-comment">-- 声明table，类似java的map</span>
<span class="hljs-keyword">local</span> map =  &#123;name=<span class="hljs-string">&#x27;Jack&#x27;</span>, age=<span class="hljs-number">21</span>&#125;</code></pre></div><p>Lua 中的数组角标是从 1 开始，访问的时候与 Java 中类似：</p><blockquote><p>lua 数组的角标从 1 开始</p></blockquote><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-comment">-- 访问数组，lua数组的角标从1开始</span>
<span class="hljs-built_in">print</span>(arr[<span class="hljs-number">1</span>])</code></pre></div><p>Lua 中的 table 可以用 key 来访问：</p><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-comment">-- 访问table</span>
<span class="hljs-built_in">print</span>(map[<span class="hljs-string">&#x27;name&#x27;</span>])
<span class="hljs-built_in">print</span>(map.name)</code></pre></div><h4 id="循环">循环</h4><p><strong>while 循环</strong></p><p>语法如下</p><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-keyword">while</span>(condition)
<span class="hljs-keyword">do</span>
   statements
<span class="hljs-keyword">end</span></code></pre></div><p><strong>statements(循环体语句)</strong> 可以是一条或多条语句，<strong>condition(条件)</strong> 可以是任意表达式，在 <strong>condition(条件)</strong> 为 true 时执行循环体语句。</p><p>Lua 编程语言中 for 语句有两大类：：</p><ul><li><p>数值 for 循环</p></li><li><p>泛型 for 循环</p></li></ul><p><strong>数值 for 循环</strong></p><p>语法如下：</p><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-keyword">for</span> var=exp1,exp2,exp3 <span class="hljs-keyword">do</span>
    &lt;执行体&gt;
<span class="hljs-keyword">end</span></code></pre></div><p>var 从 exp1 变化到 exp2，每次变化以 exp3 为步长递增 var，并执行一次 <strong>"执行体"</strong>。exp3 是可选的，如果不指定，<strong>默认为 1</strong>。</p><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-keyword">for</span> i=<span class="hljs-number">10</span>,<span class="hljs-number">1</span>,<span class="hljs-number">-1</span> <span class="hljs-keyword">do</span>
    <span class="hljs-built_in">print</span>(i)
<span class="hljs-keyword">end</span>
<span class="hljs-comment">-- 输出 10 9 8  7  6 5 4 3 2 1</span></code></pre></div><p>for 的三个表达式在循环开始前一次性求值，以后不再进行求值。比如下面 f(x)只会在循环开始前执行一次，其结果用在后面的循环中。</p><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">f</span><span class="hljs-params">(x)</span></span>
    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;function&quot;</span>)
    <span class="hljs-keyword">return</span> x*<span class="hljs-number">2</span>
<span class="hljs-keyword">end</span>
<span class="hljs-keyword">for</span> i=<span class="hljs-number">1</span>,f(<span class="hljs-number">5</span>) <span class="hljs-keyword">do</span>
    <span class="hljs-built_in">print</span>(i)
<span class="hljs-keyword">end</span>
<span class="hljs-comment">-- 输出 function 1 2 3 4 5 6 7 8 9 10</span></code></pre></div><p><strong>泛型 for 循环</strong></p><p>泛型 for 循环通过一个迭代器函数来遍历所有值，类似 java 中的 foreach 语句。</p><p>遍历数组型 table</p><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-comment">-- 声明数组 key为索引的 table</span>
<span class="hljs-keyword">local</span> arr = &#123;<span class="hljs-string">&#x27;java&#x27;</span>, <span class="hljs-string">&#x27;python&#x27;</span>, <span class="hljs-string">&#x27;lua&#x27;</span>&#125;
<span class="hljs-comment">-- 遍历数组</span>
<span class="hljs-keyword">for</span> index,value <span class="hljs-keyword">in</span> <span class="hljs-built_in">ipairs</span>(arr) <span class="hljs-keyword">do</span>
    <span class="hljs-built_in">print</span>(index, value)
<span class="hljs-keyword">end</span></code></pre></div><p>遍历普通 table</p><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-comment">-- 声明map，也就是table</span>
<span class="hljs-keyword">local</span> map = &#123;name=<span class="hljs-string">&#x27;Jack&#x27;</span>, age=<span class="hljs-number">21</span>&#125;
<span class="hljs-comment">-- 遍历table</span>
<span class="hljs-keyword">for</span> key,value <span class="hljs-keyword">in</span> <span class="hljs-built_in">pairs</span>(map) <span class="hljs-keyword">do</span>
   <span class="hljs-built_in">print</span>(key, value)
<span class="hljs-keyword">end</span></code></pre></div><blockquote><p>注：在 lua 中 pairs 与 ipairs 两个迭代器的用法相近，但仍有区别：</p><p>pairs 可以遍历表中所有的 key，并且除了迭代器本身以及遍历表本身还可以返回 nil;</p><p>但是 ipairs 则不能返回 nil,只能返回数字 0，如果遇到 nil 则退出。ipairs 在迭代过程中是会直接跳过所有手动设定 key 值的变量。</p></blockquote><h4 id="条件控制">条件控制</h4><p>类似 Java 的条件控制，例如 if、else 语法：</p><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-keyword">if</span>(布尔表达式)
<span class="hljs-keyword">then</span>
   <span class="hljs-comment">--[ 布尔表达式为 true 时执行该语句块 --]</span>
<span class="hljs-keyword">else</span>
   <span class="hljs-comment">--[ 布尔表达式为 false 时执行该语句块 --]</span>
<span class="hljs-keyword">end</span>
</code></pre></div><p>与 java 不同，布尔表达式中的逻辑运算是基于英文单词：</p><figure><img src="http://img.catpaws.top/img/image-20210821092657918-2024-12-2619_47_35.png" srcset="/img/loading.gif" lazyload alt="image-20210821092657918"><figcaption aria-hidden="true">image-20210821092657918</figcaption></figure><h4 id="函数">函数</h4><p>定义函数的语法：</p><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-function"><span class="hljs-keyword">function</span> 函数名<span class="hljs-params">( argument1, argument2..., argumentn)</span></span>
    <span class="hljs-comment">-- 函数体</span>
    <span class="hljs-keyword">return</span> 返回值
<span class="hljs-keyword">end</span></code></pre></div><p>例如，定义一个函数，用来打印数组：</p><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">printArr</span><span class="hljs-params">(arr)</span></span>
    <span class="hljs-keyword">for</span> index, value <span class="hljs-keyword">in</span> <span class="hljs-built_in">ipairs</span>(arr) <span class="hljs-keyword">do</span>
        <span class="hljs-built_in">print</span>(value)
    <span class="hljs-keyword">end</span>
<span class="hljs-keyword">end</span></code></pre></div><h3 id="实现多级缓存">2.5、实现多级缓存</h3><p>多级缓存的实现离不开 Nginx 编程，而 Nginx 编程又离不开<strong>OpenResty</strong>。</p><h4 id="安装-openresty">安装 OpenResty</h4><p>OpenResty® 是一个基于 Nginx 的高性能 Web 平台，用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。具备下列特点：</p><ul><li>具备 Nginx 的完整功能</li><li>基于 Lua 语言进行扩展，集成了大量精良的 Lua 库、第三方模块</li><li>允许使用 Lua<strong>自定义业务逻辑</strong>、<strong>自定义库</strong></li></ul><p><a target="_blank" rel="noopener" href="https://openresty.org/cn/">官方网站</a></p><figure><img src="http://img.catpaws.top/img/image-20210821092902946-2024-12-2621_38_27.png" srcset="/img/loading.gif" lazyload alt="image-20210821092902946"><figcaption aria-hidden="true">image-20210821092902946</figcaption></figure><p><a href="https://catpaws.top/50a9e6bc/">安装教程</a></p><p>安装后的所在目录：<code>/usr/local/openresty</code></p><h4 id="openresty-快速入门">OpenResty 快速入门</h4><p>多级缓存架构如图：</p><figure><img src="http://img.catpaws.top/img/yeVDlwtfMx-2024-12-2622_06_36.png" srcset="/img/loading.gif" lazyload alt="yeVDlwtfMx"><figcaption aria-hidden="true">yeVDlwtfMx</figcaption></figure><p>其中：</p><ul><li>windows 上的 nginx 用来做反向代理服务，将前端的查询商品的 ajax 请求代理到 OpenResty 集群</li><li>OpenResty 集群用来编写多级缓存业务</li></ul><h5 id="反向代理流程">反向代理流程</h5><p>现在，商品详情页使用的是假的商品数据。不过在浏览器中，可以看到页面有发起 ajax 请求查询真实商品数据。</p><p><img src="http://img.catpaws.top/img/image-20241226220907274-2024-12-2622_09_08.png" srcset="/img/loading.gif" lazyload alt="image-20241226220907274" style="zoom:67%"></p><p>在 Windows 的 nginx 中配置反向代理逻辑，将以<code>/api</code>为前缀的请求反向代理给 OpenRestry 集群处理</p><p><img src="http://img.catpaws.top/img/image-20241226221349893-2024-12-2622_13_57.png" srcset="/img/loading.gif" lazyload alt="image-20241226221349893" style="zoom:67%"></p><h5 id="openresty-监听请求">OpenResty 监听请求</h5><p>OpenResty 的很多功能都依赖于其目录下的 Lua 库，需要在 nginx.conf 中指定依赖库的目录，并导入依赖：</p><p>1）添加对 OpenResty 的 Lua 模块的加载</p><p>修改<code>/usr/local/openresty/nginx/conf/nginx.conf</code>文件，在其中的 http 下面，添加下面代码：</p><div class="code-wrapper"><pre><code class="hljs nginx"><span class="hljs-comment">#lua 模块</span>
<span class="hljs-attribute">lua_package_path</span> <span class="hljs-string">&quot;/usr/local/openresty/lualib/?.lua;;&quot;</span>;
<span class="hljs-comment">#c模块</span>
<span class="hljs-attribute">lua_package_cpath</span> <span class="hljs-string">&quot;/usr/local/openresty/lualib/?.so;;&quot;</span>;</code></pre></div><p>2）监听/api/item 路径</p><p>修改<code>/usr/local/openresty/nginx/conf/nginx.conf</code>文件，在 nginx.conf 的 server 下面，添加对/api/item 这个路径的监听：</p><div class="code-wrapper"><pre><code class="hljs nginx"><span class="hljs-section">location</span>  /api/item &#123;
    <span class="hljs-comment"># 默认的响应类型</span>
    <span class="hljs-attribute">default_type</span> application/json;
    <span class="hljs-comment"># 响应结果由lua/item.lua文件来决定</span>
    <span class="hljs-attribute">content_by_lua_file</span> lua/item.lua;
&#125;</code></pre></div><blockquote><p>这个监听，就类似于 SpringMVC 中的<code>@GetMapping("/api/item")</code>做路径映射。</p><p>而<code>content_by_lua_file lua/item.lua</code>则相当于调用 item.lua 这个文件，执行其中的业务，把结果返回给用户。相当于 java 中调用 service。</p></blockquote><h5 id="编写-item.lua">编写 item.lua</h5><p>在<code>/usr/loca/openresty/nginx</code>目录创建文件夹 <code>lua</code>，并在 lua 文件夹下新建文件 <code>item.lua</code></p><div class="code-wrapper"><pre><code class="hljs bash">[root@ai100 nginx]# <span class="hljs-built_in">mkdir</span> lua
[root@ai100 nginx]# <span class="hljs-built_in">touch</span> lua/item.lua</code></pre></div><p>item.lua 中，利用<code>ngx.say()</code>函数返回数据到 Response 中，<strong>此处暂时写入假数据，之后在 lua 文件中向 reids 和 Tomcat 发起请求获取真实数据</strong>。修改其中商品价格为 19900</p><div class="code-wrapper"><pre><code class="hljs lua">ngx.say(<span class="hljs-string">&#x27;&#123;&quot;id&quot;:10001,&quot;name&quot;:&quot;SALSA AIR&quot;,&quot;title&quot;:&quot;RIMOWA 21寸托运箱拉杆箱 SALSA AIR系列果绿色 820.70.36.4&quot;,&quot;price&quot;:19900,&quot;image&quot;:&quot;https://m.360buyimg.com/mobilecms/s720x720_jfs/t6934/364/1195375010/84676/e9f2c55f/597ece38N0ddcbc77.jpg!q70.jpg.webp&quot;,&quot;category&quot;:&quot;拉杆箱&quot;,&quot;brand&quot;:&quot;RIMOWA&quot;,&quot;spec&quot;:&quot;&quot;,&quot;status&quot;:1,&quot;createTime&quot;:&quot;2019-04-30T16:00:00.000+00:00&quot;,&quot;updateTime&quot;:&quot;2019-04-30T16:00:00.000+00:00&quot;,&quot;stock&quot;:2999,&quot;sold&quot;:31290&#125;&#x27;</span>)</code></pre></div><p>重新加载配置</p><div class="code-wrapper"><pre><code class="hljs bash">nginx -s reload</code></pre></div><p>刷新商品页面即可查看效果</p><figure><img src="http://img.catpaws.top/img/image-20241226222109001-2024-12-2622_21_57.png" srcset="/img/loading.gif" lazyload alt="image-20241226222109001"><figcaption aria-hidden="true">image-20241226222109001</figcaption></figure><h4 id="请求参数处理">请求参数处理</h4><p>OpenResty 中提供了一些 API 用来获取不同类型的前端请求参数：</p><figure><img src="http://img.catpaws.top/img/image-20210821101433528-2024-12-2622_25_47.png" srcset="/img/loading.gif" lazyload alt="image-20210821101433528"><figcaption aria-hidden="true">image-20210821101433528</figcaption></figure><p>前端请求路径为：<code>http://localhost:8088/api/item/10001</code>，其中商品 id 是以路径参数传递的，因此可以利用正则表达式匹配的方式来获取 ID。</p><p>修改<code>/usr/loca/openresty/nginx/nginx.conf</code>文件中监听/api/item 的代码，利用正则表达式获取 ID</p><div class="code-wrapper"><pre><code class="hljs properties"><span class="hljs-attr">location</span> <span class="hljs-string">~ /api/item/(\d+) &#123;</span>
<span class="hljs-comment">    # 默认的响应类型</span>
    <span class="hljs-attr">default_type</span> <span class="hljs-string">application/json;</span>
<span class="hljs-comment">    # 响应结果由lua/item.lua文件来决定</span>
    <span class="hljs-attr">content_by_lua_file</span> <span class="hljs-string">lua/item.lua;</span>
<span class="hljs-attr">&#125;</span></code></pre></div><p>在<code>item.lua</code>中获取商品 id</p><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-comment">-- 获取商品id</span>
<span class="hljs-keyword">local</span> id = ngx.var[<span class="hljs-number">1</span>]</code></pre></div><h4 id="查询-tomcat">查询 TomCat</h4><p>拿到商品 ID 后，本应去缓存中查询商品信息，不过目前我们还未建立 nginx、redis 缓存。因此，这里我们先根据商品 id 去 tomcat 查询商品信息。</p><figure><img src="http://img.catpaws.top/img/image-20210821111023255-2024-12-2721_29_43.png" srcset="/img/loading.gif" lazyload alt="image-20210821111023255"><figcaption aria-hidden="true">image-20210821111023255</figcaption></figure><h5 id="发送-http-请求的-api">发送 http 请求的 API</h5><p>nginx 提供了内部 API 用以发送 http 请求：</p><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-keyword">local</span> resp = ngx.location.capture(<span class="hljs-string">&quot;/path&quot;</span>,&#123;
    method = ngx.HTTP_GET,   <span class="hljs-comment">-- 请求方式</span>
    args = &#123;a=<span class="hljs-number">1</span>,b=<span class="hljs-number">2</span>&#125;,  <span class="hljs-comment">-- get方式传参数</span>
&#125;)</code></pre></div><p>返回的响应内容包括：</p><ul><li>resp.status：响应状态码</li><li>resp.header：响应头，是一个 table</li><li>resp.body：响应体，就是响应数据</li></ul><p><strong>注意：这里的 path 是路径，并不包含 IP 和端口。这个请求会被 nginx 内部的 server 监听并处理。</strong></p><p><strong>为了让请求发送到 Tomcat 服务器，所以还需要编写一个 server 来对这个路径做反向代理</strong>：</p><div class="code-wrapper"><pre><code class="hljs nginx"><span class="hljs-section">location</span> /path &#123;
    <span class="hljs-comment"># 这里是windows电脑的ip和Java服务端口，需要确保windows防火墙处于关闭状态</span>
    <span class="hljs-attribute">proxy_pass</span> http://192.168.181.1:8081;
&#125;</code></pre></div><p>原理如图：</p><figure><img src="http://img.catpaws.top/img/image-20210821104149061-2024-12-2622_33_57.png" srcset="/img/loading.gif" lazyload alt="image-20210821104149061"><figcaption aria-hidden="true">image-20210821104149061</figcaption></figure><h5 id="封装-http-工具">封装 http 工具</h5><p>封装一个发送 Http 请求的工具，基于<code>ngx.location.capture</code>来实现查询 tomcat</p><p>1）添加反向代理，到 windows 的 Java 服务</p><p>因为 item-service 中的接口都是/item 开头，所以需要监听/item 路径，代理到 windows 上的 tomcat 服务。</p><p>修改 <code>/usr/local/openresty/nginx/conf/nginx.conf</code>文件，添加一个 location：</p><div class="code-wrapper"><pre><code class="hljs nginx"><span class="hljs-section">location</span> /item &#123;
    <span class="hljs-attribute">proxy_pass</span> http://192.168.181.1:8081;
&#125;</code></pre></div><p>之后只要使用<code>ngx.location.capture("/item")</code>，就一定能发送请求到 windows 的 tomcat 服务。</p><p>2）封装工具类</p><p>在<code>/usr/local/openresty/lualib</code>目录下，新建一个 common.lua 文件，编写请求代码</p><div class="code-wrapper"><pre><code class="hljs bash">vi /usr/local/openresty/lualib/common.lua</code></pre></div><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-comment">-- 封装函数，发送http请求，并解析响应</span>
<span class="hljs-keyword">local</span> <span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">read_http</span><span class="hljs-params">(path, params)</span></span>
    <span class="hljs-keyword">local</span> resp = ngx.location.capture(<span class="hljs-built_in">path</span>,&#123;
        method = ngx.HTTP_GET,  <span class="hljs-comment">-- 处理GET请求</span>
        args = params,
    &#125;)
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> resp <span class="hljs-keyword">then</span>
        <span class="hljs-comment">-- 记录错误信息，返回404</span>
        ngx.<span class="hljs-built_in">log</span>(ngx.ERR, <span class="hljs-string">&quot;http请求查询失败, path: &quot;</span>, <span class="hljs-built_in">path</span> , <span class="hljs-string">&quot;, args: &quot;</span>, args)
        ngx.<span class="hljs-built_in">exit</span>(<span class="hljs-number">404</span>)
    <span class="hljs-keyword">end</span>
    <span class="hljs-keyword">return</span> resp.body
<span class="hljs-keyword">end</span>
<span class="hljs-comment">-- 将方法导出</span>
<span class="hljs-keyword">local</span> _M = &#123;
    read_http = read_http
&#125;
<span class="hljs-keyword">return</span> _M</code></pre></div><blockquote><p>这个工具将 read_http 函数封装到_M 这个<strong>table 类型</strong>的变量中，并且返回，这类似于导出。使用的时候，可以利用<code>require('common')</code>来导入该函数库，这里的 common 是函数库的文件名。</p><p>lua 的工具类都存放在<code>/usr/local/openresty/lualib</code>路径下</p></blockquote><h5 id="实现商品查询">实现商品查询</h5><p>修改<code>/usr/local/openresty/lua/item.lua</code>文件，利用刚刚封装的函数库实现对 tomcat 的查询</p><div class="code-wrapper"><pre><code class="hljs applescript"><span class="hljs-comment">-- 引入自定义common工具模块，返回值是common中返回的 _M</span>
<span class="hljs-keyword">local</span> common = require(<span class="hljs-string">&quot;common&quot;</span>)
<span class="hljs-comment">-- 导入cjson工具包</span>
<span class="hljs-keyword">local</span> cjson = require(<span class="hljs-string">&quot;cjson&quot;</span>)


<span class="hljs-comment">-- 从common中获取read_quest函数</span>
<span class="hljs-keyword">local</span> read_quest = common.read_quest

<span class="hljs-comment">-- 获取路径参数</span>
<span class="hljs-keyword">local</span> <span class="hljs-built_in">id</span> = ngx.var[<span class="hljs-number">1</span>]

<span class="hljs-comment">-- 根据id查询商品</span>
<span class="hljs-keyword">local</span> itemJson = read_quest(<span class="hljs-string">&quot;/item/&quot;</span> .. <span class="hljs-built_in">id</span>, nil)
<span class="hljs-comment">-- 根据id查询商品库存</span>
<span class="hljs-keyword">local</span> itemStockJSON = read_http(<span class="hljs-string">&quot;/item/stock/&quot;</span>.. <span class="hljs-built_in">id</span>, nil)

<span class="hljs-comment">-- 查询到的是商品、库存的json格式数据，我们需要将两部分数据组装，需要用到JSON处理函数库。</span>
<span class="hljs-comment">-- 将JSON转化为lua的table进行数据拼接</span>
<span class="hljs-keyword">local</span> <span class="hljs-built_in">item</span> = cjson.decode(itemJson)
<span class="hljs-keyword">local</span> itemStock = cjson.decode(itemStockJSON)

<span class="hljs-comment">--数据拼接</span>
<span class="hljs-built_in">item</span>.stock = itemStock.stock
<span class="hljs-built_in">item</span>.sold = itemStock.sold

<span class="hljs-comment">-- 把item序列化为json 返回结果</span>
ngx.<span class="hljs-built_in">say</span>(cjson.endcode(<span class="hljs-built_in">item</span>))</code></pre></div><blockquote><p>OpenResty 提供了一个<strong>cjson</strong>的模块用来处理 JSON 的序列化和反序列化，使用方法如下：</p><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-comment">-- 引入cjson模块</span>
<span class="hljs-keyword">local</span> cjson = <span class="hljs-built_in">require</span> <span class="hljs-string">&quot;cjson&quot;</span>

<span class="hljs-comment">-- 序列化，使用encode方法</span>
<span class="hljs-keyword">local</span> obj = &#123;
    name = <span class="hljs-string">&#x27;jack&#x27;</span>,
    age = <span class="hljs-number">21</span>
&#125;
<span class="hljs-keyword">local</span> json = cjson.encode(obj) <span class="hljs-comment">-- 把 table 序列化为 json</span>

<span class="hljs-comment">-- 反序列化，使用decode方法</span>
<span class="hljs-keyword">local</span> json = <span class="hljs-string">&#x27;&#123;&quot;name&quot;: &quot;jack&quot;, &quot;age&quot;: 21&#125;&#x27;</span>
<span class="hljs-keyword">local</span> obj = cjson.decode(json) <span class="hljs-comment">-- 反序列化 json为 table</span>
<span class="hljs-built_in">print</span>(obj.name)
</code></pre></div></blockquote><h4 id="tomcat-集群的负载均衡基于-id-的负载均衡">Tomcat 集群的负载均衡（基于 ID 的负载均衡）</h4><p>OpenResty 对 tomcat 集群负载均衡的默认策略是<strong>轮询模式</strong>。当查询/item/10001 时假设访问的是 8081 端口的 tomcat 服务，查询完成会在该服务器内部建立 JVM 缓存，而当第二次查询时，由于是轮询所以会去访问其他端口的服务，而其他服务器内部没有该商品的 JVM 缓存，需要查询数据库，导致之前的 JVM 缓存失效，并且在多个服务器建立冗余的缓存。</p><p>如果能让同一个商品，每次查询时都访问同一个 tomcat 服务，那么 JVM 缓存就一定能生效了。</p><p>也就是说，我们需要根据<strong>商品 id</strong>做负载均衡，而不是轮询。</p><h5 id="原理-1">原理</h5><p>nginx 提供了<strong>基于请求路径做负载均衡</strong>的算法：</p><p>nginx 根据请求路径做 hash 运算，把得到的数值对 tomcat 服务的数量取余，余数是几，就访问第几个服务，实现负载均衡。只要 id 不变，每次 hash 运算结果也不会变，那就可以保证同一个商品，一直访问同一个 tomcat 服务，确保 JVM 缓存生效。</p><h5 id="实现">实现</h5><p>修改<code>/usr/local/openresty/nginx/conf/nginx.conf</code>文件，实现基于 ID 做负载均衡。</p><p>首先，定义 tomcat 集群，并设置基于路径做负载均衡：</p><div class="code-wrapper"><pre><code class="hljs nginx"><span class="hljs-section">upstream</span> tomcat-cluster &#123;
    <span class="hljs-attribute">hash</span> <span class="hljs-variable">$request_uri</span>;  <span class="hljs-comment">#设置负载均衡策略</span>
    <span class="hljs-attribute">server</span> <span class="hljs-number">192.168.150.1:8081</span>;
    <span class="hljs-attribute">server</span> <span class="hljs-number">192.168.150.1:8082</span>;
&#125;</code></pre></div><p>然后，修改对 tomcat 服务的反向代理，目标指向 tomcat 集群：</p><div class="code-wrapper"><pre><code class="hljs nginx"><span class="hljs-section">location</span> /item &#123;
    <span class="hljs-attribute">proxy_pass</span> http://tomcat-cluster;
&#125;</code></pre></div><p>重新加载 OpenResty</p><div class="code-wrapper"><pre><code class="hljs sh">nginx -s reload</code></pre></div><h4 id="添加-redis-缓存">添加 Redis 缓存</h4><figure><img src="http://img.catpaws.top/img/image-20210821113340111-2024-12-2721_29_07.png" srcset="/img/loading.gif" lazyload alt="image-20210821113340111"><figcaption aria-hidden="true">image-20210821113340111</figcaption></figure><h5 id="缓存预热">缓存预热</h5><p><strong>冷启动</strong>：服务刚刚启动时，Redis 中并没有缓存，如果所有商品数据都在第一次查询时添加缓存，可能会给数据库带来较大压力。</p><p><strong>缓存预热</strong>：在实际开发中，可以利用大数据统计用户访问的热点数据，在项目启动时将这些热点数据提前查询并保存到 Redis 中。</p><p>1、利用 Docker 安装 Redis</p><p>2、在 item-service 服务中引入 Redis 依赖</p><div class="code-wrapper"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.boot<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-boot-starter-data-redis<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span></code></pre></div><p>3、配置 redis 地址</p><div class="code-wrapper"><pre><code class="hljs properties"><span class="hljs-attr">spring</span>:<span class="hljs-string"></span>
	<span class="hljs-attr">redis</span>:<span class="hljs-string"></span>
   		<span class="hljs-attr">host</span>: <span class="hljs-string">192.168.181.100</span>
    	<span class="hljs-attr">port</span>: <span class="hljs-string">6379</span>
    	<span class="hljs-attr">password</span>: <span class="hljs-string">liuhao123</span></code></pre></div><p>4、编写初始化类</p><p>缓存预热需要在项目启动时完成，并且必须是拿到 RedisTemplate 之后。</p><blockquote><p>这里利用<code>InitializingBean</code>接口来实现，该接口定义了一个方法<code>afterPropertiesSet()</code>，<u><strong>该方法在 Bean 的所有属性被 Spring 容器设置之后自动被调用</strong></u>。这允许开发者在 Bean 的初始化阶段执行一些必要的操作，如检查配置的正确性、初始化资源、建立数据库连接等。</p></blockquote><blockquote><p><code>ObjectMapper</code>是 Jackson 库中的一个核心类，它提供了 Java 对象和 JSON 数据之间转换的功能。</p><p>序列化：<code>writeValueAsString(xxx)</code></p><p>反序列化：<code>readValue(xxx)</code></p></blockquote><div class="code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@Component</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">RedisHandler</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">InitializingBean</span> &#123;
    <span class="hljs-meta">@Autowired</span>
    <span class="hljs-keyword">private</span> StringRedisTemplate stringRedisTemplate;
    <span class="hljs-meta">@Autowired</span>
    <span class="hljs-keyword">private</span> IItemService iItemService;
    <span class="hljs-meta">@Autowired</span>
    <span class="hljs-keyword">private</span> IItemStockService iItemStockService;
    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">ObjectMapper</span> <span class="hljs-variable">objectMapper</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ObjectMapper</span>();

    <span class="hljs-meta">@Override</span>
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">afterPropertiesSet</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> Exception &#123;
        <span class="hljs-comment">//初始化缓存</span>
        <span class="hljs-comment">//1、查询数据库</span>
        List&lt;Item&gt; itemList = iItemService.list();
        List&lt;ItemStock&gt; stockList = iItemStockService.list();

        <span class="hljs-comment">//2、存入redis</span>
        <span class="hljs-keyword">for</span> (Item item : itemList) &#123;
            <span class="hljs-comment">//将item对象序列化为JSON字符串</span>
            <span class="hljs-type">String</span> <span class="hljs-variable">itemJson</span> <span class="hljs-operator">=</span> objectMapper.writeValueAsString(item);
            stringRedisTemplate.opsForValue().set(<span class="hljs-string">&quot;item:id&quot;</span>+item.getId(),itemJson);
        &#125;
        <span class="hljs-keyword">for</span> (ItemStock itemStock : stockList) &#123;
            <span class="hljs-comment">//将itemStock对象序列化为JSON字符串</span>
            <span class="hljs-type">String</span> <span class="hljs-variable">stockJson</span> <span class="hljs-operator">=</span> objectMapper.writeValueAsString(itemStock);
            stringRedisTemplate.opsForValue()
                .set(<span class="hljs-string">&quot;item:stock:id&quot;</span>+itemStock.getId(),stockJson);
        &#125;
    &#125;
&#125;</code></pre></div><h5 id="查询-redis-缓存">查询 redis 缓存</h5><p>OpenResty 提供了操作 Redis 的模块，我们只要引入该模块就能直接使用：</p><ol type="1"><li><p>引入 Redis 模块，并初始化 Redis 对象</p><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-comment">-- 导入redis</span>
<span class="hljs-keyword">local</span> redis = <span class="hljs-built_in">require</span>(<span class="hljs-string">&quot;resty.redis&quot;</span>)
<span class="hljs-comment">-- 初始化redis对象</span>
<span class="hljs-keyword">local</span> red = redis:new()  <span class="hljs-comment">-- 通过 ：调用方法</span>
<span class="hljs-comment">--设置redis超时时间</span>
red:set_timeouts(<span class="hljs-number">1000</span>,<span class="hljs-number">1000</span>,<span class="hljs-number">1000</span>)</code></pre></div></li><li><p>从连接池获取 redis 连接</p><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-keyword">local</span> ip = <span class="hljs-string">&quot;127.0.0.1&quot;</span>
<span class="hljs-keyword">local</span> port = <span class="hljs-number">6379</span>
<span class="hljs-keyword">local</span> ok, err = red:connect(ip,port)
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> ok <span class="hljs-keyword">then</span>
    ngx.<span class="hljs-built_in">log</span>(ngx.ERR, <span class="hljs-string">&quot;连接redis失败&quot;</span>,err)
    <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>
<span class="hljs-keyword">end</span>

<span class="hljs-comment">--连接后验证密码</span>
<span class="hljs-comment">-- 使用 red:get_reused_times 方法可以得知当前连接被使用的次数</span>
<span class="hljs-keyword">local</span> count, err = red:get_reused_times()
<span class="hljs-keyword">if</span> <span class="hljs-number">0</span> == count <span class="hljs-keyword">then</span> <span class="hljs-comment">----新建连接，需要认证密码</span>
    ok, err = red:auth(<span class="hljs-string">&quot;liu123&quot;</span>)
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> ok <span class="hljs-keyword">then</span>
        ngx.say(<span class="hljs-string">&quot;failed to auth: &quot;</span>, err)
        <span class="hljs-keyword">return</span>
    <span class="hljs-keyword">end</span>
<span class="hljs-keyword">elseif</span> err <span class="hljs-keyword">then</span>  <span class="hljs-comment">----从连接池中获取连接，无需再次认证密码</span>
    ngx.say(<span class="hljs-string">&quot;failed to get reused times: &quot;</span>, err)
    <span class="hljs-keyword">return</span>
<span class="hljs-keyword">end</span></code></pre></div></li><li><p>操作 Redis：<code>red:xxx()</code>。 其中对各种数据类型的操作方法与在 redis 中一致，如对 String 类型操作的 <code>set</code> <code>get</code>方法，对 List 操作的<code>lpush</code> <code>rpop</code>等等，</p><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-comment">-- 设置字符串</span>
<span class="hljs-keyword">local</span> ok, err = red:set(<span class="hljs-string">&quot;string_key&quot;</span>, <span class="hljs-string">&quot;string_value&quot;</span>)
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> ok <span class="hljs-keyword">then</span>
    ngx.say(<span class="hljs-string">&quot;failed to set string: &quot;</span>, err)
    <span class="hljs-keyword">return</span>
<span class="hljs-keyword">end</span>

<span class="hljs-comment">-- 获取字符串</span>
<span class="hljs-keyword">local</span> res, err = red:get(<span class="hljs-string">&quot;string_key&quot;</span>)
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> res <span class="hljs-keyword">then</span>
    ngx.say(<span class="hljs-string">&quot;failed to get string: &quot;</span>, err)
    <span class="hljs-keyword">return</span>
<span class="hljs-keyword">end</span>

ngx.say(<span class="hljs-string">&quot;got string: &quot;</span>, res)

<span class="hljs-comment">-- 设置哈希</span>
<span class="hljs-keyword">local</span> ok, err = red:hset(<span class="hljs-string">&quot;hash_key&quot;</span>, <span class="hljs-string">&quot;field1&quot;</span>, <span class="hljs-string">&quot;value1&quot;</span>)
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> ok <span class="hljs-keyword">then</span>
    ngx.say(<span class="hljs-string">&quot;failed to set hash: &quot;</span>, err)
    <span class="hljs-keyword">return</span>
<span class="hljs-keyword">end</span>

<span class="hljs-comment">-- 获取哈希字段</span>
<span class="hljs-keyword">local</span> res, err = red:hget(<span class="hljs-string">&quot;hash_key&quot;</span>, <span class="hljs-string">&quot;field1&quot;</span>)
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> res <span class="hljs-keyword">then</span>
    ngx.say(<span class="hljs-string">&quot;failed to get hash field: &quot;</span>, err)
    <span class="hljs-keyword">return</span>
<span class="hljs-keyword">end</span>

ngx.say(<span class="hljs-string">&quot;got hash field: &quot;</span>, res)

<span class="hljs-comment">-- 设置列表</span>
<span class="hljs-keyword">local</span> ok, err = red:rpush(<span class="hljs-string">&quot;list_key&quot;</span>, <span class="hljs-string">&quot;value1&quot;</span>)
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> ok <span class="hljs-keyword">then</span>
    ngx.say(<span class="hljs-string">&quot;failed to set list: &quot;</span>, err)
    <span class="hljs-keyword">return</span>
<span class="hljs-keyword">end</span>

<span class="hljs-comment">-- 获取列表</span>
<span class="hljs-keyword">local</span> res, err = red:lrange(<span class="hljs-string">&quot;list_key&quot;</span>, <span class="hljs-number">0</span>, <span class="hljs-number">-1</span>)
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> res <span class="hljs-keyword">then</span>
    ngx.say(<span class="hljs-string">&quot;failed to get list: &quot;</span>, err)
    <span class="hljs-keyword">return</span>
<span class="hljs-keyword">end</span>

ngx.say(<span class="hljs-string">&quot;got list: &quot;</span>, <span class="hljs-built_in">table</span>.<span class="hljs-built_in">concat</span>(res, <span class="hljs-string">&quot;, &quot;</span>))

<span class="hljs-comment">-- 设置集合</span>
<span class="hljs-keyword">local</span> ok, err = red:sadd(<span class="hljs-string">&quot;set_key&quot;</span>, <span class="hljs-string">&quot;value1&quot;</span>)
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> ok <span class="hljs-keyword">then</span>
    ngx.say(<span class="hljs-string">&quot;failed to set set: &quot;</span>, err)
    <span class="hljs-keyword">return</span>
<span class="hljs-keyword">end</span>

<span class="hljs-comment">-- 获取集合</span>
<span class="hljs-keyword">local</span> res, err = red:smembers(<span class="hljs-string">&quot;set_key&quot;</span>)
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> res <span class="hljs-keyword">then</span>
    ngx.say(<span class="hljs-string">&quot;failed to get set: &quot;</span>, err)
    <span class="hljs-keyword">return</span>
<span class="hljs-keyword">end</span>

ngx.say(<span class="hljs-string">&quot;got set: &quot;</span>, <span class="hljs-built_in">table</span>.<span class="hljs-built_in">concat</span>(res, <span class="hljs-string">&quot;, &quot;</span>))

<span class="hljs-comment">-- 设置有序集合</span>
<span class="hljs-keyword">local</span> ok, err = red:zadd(<span class="hljs-string">&quot;zset_key&quot;</span>, <span class="hljs-number">10</span>, <span class="hljs-string">&quot;value1&quot;</span>)
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> ok <span class="hljs-keyword">then</span>
    ngx.say(<span class="hljs-string">&quot;failed to set zset: &quot;</span>, err)
    <span class="hljs-keyword">return</span>
<span class="hljs-keyword">end</span>

<span class="hljs-comment">-- 获取有序集合</span>
<span class="hljs-keyword">local</span> res, err = red:zrange(<span class="hljs-string">&quot;zset_key&quot;</span>, <span class="hljs-number">0</span>, <span class="hljs-number">-1</span>)
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> res <span class="hljs-keyword">then</span>
    ngx.say(<span class="hljs-string">&quot;failed to get zset: &quot;</span>, err)
    <span class="hljs-keyword">return</span>
<span class="hljs-keyword">end</span>

ngx.say(<span class="hljs-string">&quot;got zset: &quot;</span>, <span class="hljs-built_in">table</span>.<span class="hljs-built_in">concat</span>(res, <span class="hljs-string">&quot;, &quot;</span>))
</code></pre></div></li><li><p>关闭连接池。redis 的连接是 TCP 连接，建立 TCP 连接需要三次握手，而释放 TCP 连接需要四次握手，耗时较长，应该将该 TCP 连接放入连接池进行复用。</p><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-keyword">local</span> <span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">close_redis</span><span class="hljs-params">(red)</span></span>  <span class="hljs-comment">-- 封装成函数方便调用</span>
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> red <span class="hljs-keyword">then</span>
        <span class="hljs-keyword">return</span>
    <span class="hljs-keyword">end</span>
    <span class="hljs-comment">--释放连接(连接池实现)</span>
    <span class="hljs-keyword">local</span> pool_max_idle_time = <span class="hljs-number">10000</span> <span class="hljs-comment">--连接的最大空闲时间（毫秒），超出该时间还未被使用则断开该连接</span>
    <span class="hljs-keyword">local</span> pool_size = <span class="hljs-number">100</span> <span class="hljs-comment">--连接池大小</span>
    <span class="hljs-keyword">local</span> ok, err = red:set_keepalive(pool_max_idle_time, pool_size)  <span class="hljs-comment">--将连接放回连接池中</span>
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> ok <span class="hljs-keyword">then</span>
        ngx.say(<span class="hljs-string">&quot;set keepalive error : &quot;</span>, err)
    <span class="hljs-keyword">end</span>
<span class="hljs-keyword">end</span></code></pre></div></li></ol><p>将建立和释放 redis 连接，查询 redis 数据等操作封装到<code>common.lua</code>中方便调用</p><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-comment">-- 导入redis</span>
<span class="hljs-keyword">local</span> redis = <span class="hljs-built_in">require</span>(<span class="hljs-string">&#x27;resty.redis&#x27;</span>)
<span class="hljs-comment">-- 初始化redis</span>
<span class="hljs-keyword">local</span> red = redis:new()
red:set_timeouts(<span class="hljs-number">1000</span>, <span class="hljs-number">1000</span>, <span class="hljs-number">1000</span>)

<span class="hljs-comment">-- 关闭redis连接的工具方法，其实是放入连接池</span>
<span class="hljs-keyword">local</span> <span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">close_redis</span><span class="hljs-params">(red)</span></span>
    <span class="hljs-keyword">local</span> pool_max_idle_time = <span class="hljs-number">10000</span> <span class="hljs-comment">-- 连接的空闲时间，单位是毫秒</span>
    <span class="hljs-keyword">local</span> pool_size = <span class="hljs-number">100</span> <span class="hljs-comment">--连接池大小</span>
    <span class="hljs-keyword">local</span> ok, err = red:set_keepalive(pool_max_idle_time, pool_size)
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> ok <span class="hljs-keyword">then</span>
        ngx.<span class="hljs-built_in">log</span>(ngx.ERR, <span class="hljs-string">&quot;放入redis连接池失败: &quot;</span>, err)
    <span class="hljs-keyword">end</span>
<span class="hljs-keyword">end</span>

<span class="hljs-comment">-- 查询redis的方法 ip和port是redis地址，key是查询的key</span>
<span class="hljs-keyword">local</span> <span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">read_redis</span><span class="hljs-params">(ip, port, key)</span></span>
    <span class="hljs-comment">-- 获取一个连接</span>
    <span class="hljs-keyword">local</span> ok, err = red:connect(ip, port)
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> ok <span class="hljs-keyword">then</span>
        ngx.<span class="hljs-built_in">log</span>(ngx.ERR, <span class="hljs-string">&quot;连接redis失败 : &quot;</span>, err)
        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>
    <span class="hljs-keyword">end</span>
    red.auth(<span class="hljs-string">&quot;liuhao123&quot;</span>) <span class="hljs-comment">--验证密码</span>
    <span class="hljs-comment">-- 查询redis</span>
    <span class="hljs-keyword">local</span> resp, err = red:get(key)
    <span class="hljs-comment">-- 查询失败处理</span>
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> resp <span class="hljs-keyword">then</span>
        ngx.<span class="hljs-built_in">log</span>(ngx.ERR, <span class="hljs-string">&quot;查询Redis失败: &quot;</span>, err, <span class="hljs-string">&quot;, key = &quot;</span> , key)
    <span class="hljs-keyword">end</span>
    <span class="hljs-comment">--得到的数据为空处理</span>
    <span class="hljs-keyword">if</span> resp == ngx.null <span class="hljs-keyword">then</span>
        resp = <span class="hljs-literal">nil</span>
        ngx.<span class="hljs-built_in">log</span>(ngx.ERR, <span class="hljs-string">&quot;查询Redis数据为空, key = &quot;</span>, key)
    <span class="hljs-keyword">end</span>
    <span class="hljs-comment">-- 归还redis连接</span>
    close_redis(red)
    <span class="hljs-keyword">return</span> resp
<span class="hljs-keyword">end</span>


<span class="hljs-comment">-- 封装函数，发送http请求，并解析响应</span>
<span class="hljs-keyword">local</span> <span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">read_http</span><span class="hljs-params">(path, params)</span></span>
    <span class="hljs-keyword">local</span> resp = ngx.location.capture(<span class="hljs-built_in">path</span>,&#123;
        method = ngx.HTTP_GET,
        args = params,
    &#125;)
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> resp <span class="hljs-keyword">then</span>
        <span class="hljs-comment">-- 记录错误信息，返回404</span>
        ngx.<span class="hljs-built_in">log</span>(ngx.ERR, <span class="hljs-string">&quot;http查询失败, path: &quot;</span>, <span class="hljs-built_in">path</span> , <span class="hljs-string">&quot;, args: &quot;</span>, args)
        ngx.<span class="hljs-built_in">exit</span>(<span class="hljs-number">404</span>)
    <span class="hljs-keyword">end</span>
    <span class="hljs-keyword">return</span> resp.body
<span class="hljs-keyword">end</span>

<span class="hljs-comment">-- 将方法导出</span>
<span class="hljs-keyword">local</span> _M = &#123;
    read_http = read_http,
    read_redis = read_redis
&#125;
<span class="hljs-keyword">return</span> _M</code></pre></div><p>修改<code>item.lua</code>实现对 Reids 查询。封装一个<code>read_data</code>函数，其中数据请求到达后先查询 Reids，查询失败后再查 Tomcat，将查询结果返回。</p><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-comment">-- 引入common库中封装的函数</span>
<span class="hljs-keyword">local</span> common = <span class="hljs-built_in">require</span>(<span class="hljs-string">&quot;common&quot;</span>)
<span class="hljs-keyword">local</span> read_redis = common.read_redis
<span class="hljs-keyword">local</span> read_http = common.read_http
<span class="hljs-comment">-- 导入cjson库</span>
<span class="hljs-keyword">local</span> cjson = <span class="hljs-built_in">require</span>(<span class="hljs-string">&#x27;cjson&#x27;</span>)


<span class="hljs-comment">-- 封装查询函数</span>
<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">read_data</span><span class="hljs-params">(key, path, params)</span></span>
    <span class="hljs-comment">-- 查询本地缓存</span>
    <span class="hljs-keyword">local</span> val = read_redis(<span class="hljs-string">&quot;127.0.0.1&quot;</span>, <span class="hljs-number">6379</span>, key)
    <span class="hljs-comment">-- 判断查询结果</span>
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> val <span class="hljs-keyword">then</span>
        ngx.<span class="hljs-built_in">log</span>(ngx.ERR, <span class="hljs-string">&quot;redis查询失败，尝试查询http， key: &quot;</span>, key)
        <span class="hljs-comment">-- redis查询失败，去查询http</span>
        val = read_http(<span class="hljs-built_in">path</span>, params)
    <span class="hljs-keyword">end</span>
    <span class="hljs-comment">-- 返回数据</span>
    <span class="hljs-keyword">return</span> val
<span class="hljs-keyword">end</span>

<span class="hljs-comment">-- 获取路径参数</span>
<span class="hljs-keyword">local</span> id = ngx.var[<span class="hljs-number">1</span>]

<span class="hljs-comment">-- 查询商品信息</span>
<span class="hljs-keyword">local</span> itemJSON = read_data(<span class="hljs-string">&quot;item:id:&quot;</span> .. id,  <span class="hljs-string">&quot;/item/&quot;</span> .. id, <span class="hljs-literal">nil</span>)
<span class="hljs-comment">-- 查询库存信息</span>
<span class="hljs-keyword">local</span> stockJSON = read_data(<span class="hljs-string">&quot;item:stock:id:&quot;</span> .. id, <span class="hljs-string">&quot;/item/stock/&quot;</span> .. id, <span class="hljs-literal">nil</span>)

<span class="hljs-comment">-- JSON转化为lua的table</span>
<span class="hljs-keyword">local</span> item = cjson.decode(itemJSON)
<span class="hljs-keyword">local</span> stock = cjson.decode(stockJSON)
<span class="hljs-comment">-- 组合数据</span>
item.stock = stock.stock
item.sold = stock.sold

<span class="hljs-comment">-- 把item序列化为json 返回结果</span>
ngx.say(cjson.encode(item))</code></pre></div><h4 id="nginx-本地缓存">Nginx 本地缓存</h4><p>多级缓存的最后一环</p><figure><img src="http://img.catpaws.top/img/image-20210821114742950-2024-12-2721_28_27.png" srcset="/img/loading.gif" lazyload alt="image-20210821114742950"><figcaption aria-hidden="true">image-20210821114742950</figcaption></figure><h5 id="本地缓存-api">本地缓存 API</h5><p>OpenResty 为 Nginx 提供了<code>shard dict</code>的功能，可以<strong>在一个 nginx 服务的多个 worker 之间共享数据</strong>，实现缓存功能。</p><ol type="1"><li><p>开启共享字典，在 nginx.conf 的 http 下添加配置：</p><div class="code-wrapper"><pre><code class="hljs nginx"><span class="hljs-comment"># 共享字典，也就是本地缓存，名称叫做：item_cache，大小150m</span>
 <span class="hljs-attribute">lua_shared_dict</span> item_cache <span class="hljs-number">150m</span>;</code></pre></div></li><li><p>操作共享字典：</p><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-comment">-- 获取本地缓存对象</span>
<span class="hljs-keyword">local</span> item_cache = ngx.shared.item_cache
<span class="hljs-comment">-- 存储, 指定key、value、过期时间，单位s，默认为0代表永不过期</span>
item_cache:set(<span class="hljs-string">&quot;key&quot;</span>,<span class="hljs-string">&quot;value&quot;</span>,<span class="hljs-number">100</span>)
<span class="hljs-comment">-- 读取</span>
<span class="hljs-keyword">local</span> val = item_cache:get(<span class="hljs-string">&#x27;key&#x27;</span>)</code></pre></div></li></ol><h5 id="实现本地缓存查询">实现本地缓存查询</h5><p>修改<code>/usr/local/openresty/lua/item.lua</code>文件，修改 read_data 查询函数，添加本地缓存逻辑：</p><ul><li>优先查询本地缓存，未命中时再查询 Redis、Tomcat</li><li>查询 Redis 或 Tomcat 成功后，将数据写入本地缓存，并设置有效期。商品基本信息，有效期 30 分钟；库存信息，有效期 1 分钟</li></ul><div class="code-wrapper"><pre><code class="hljs lua"><span class="hljs-comment">--导入共享词典，本地缓存</span>
<span class="hljs-keyword">local</span> item_cache =  ngx.shared.item_cache

<span class="hljs-comment">-- 封装查询函数</span>
<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">read_data</span><span class="hljs-params">(key,expire, path, params)</span></span>
    <span class="hljs-comment">-- 查询本地缓存</span>
    <span class="hljs-keyword">local</span> val = item_cache.get(key)
    <span class="hljs-comment">--判断本地缓存查询结果</span>
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> val <span class="hljs-keyword">then</span>
        ngx.<span class="hljs-built_in">log</span>(ngx.ERR,<span class="hljs-string">&quot;本地缓存查询失败，尝试查询redis缓存，key:&quot;</span>,key)
        <span class="hljs-comment">--查询redis缓存</span>
        val = read_redis(<span class="hljs-string">&quot;127.0.0.1&quot;</span>, <span class="hljs-number">6379</span>, key)
        <span class="hljs-comment">-- 判断redis查询结果</span>
        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> val <span class="hljs-keyword">then</span>
            ngx.<span class="hljs-built_in">log</span>(ngx.ERR, <span class="hljs-string">&quot;redis查询失败，尝试查询http， key: &quot;</span>, key)
            <span class="hljs-comment">-- redis查询失败，去查询http</span>
            val = read_http(<span class="hljs-built_in">path</span>, params)
        <span class="hljs-keyword">end</span>
    <span class="hljs-keyword">end</span>
    <span class="hljs-comment">--查询成功，将数据写入本地缓存</span>
    item_cache.set(key,val,expire)
    <span class="hljs-comment">-- 返回数据</span>
    <span class="hljs-keyword">return</span> val
<span class="hljs-keyword">end</span>

<span class="hljs-comment">--调用read_data时，需再传入一个参数：key的过期时间</span></code></pre></div><h3 id="缓存同步">2.6、缓存同步</h3><p>大多数情况下，浏览器查询到的都是缓存数据，如果缓存数据与数据库数据存在较大差异，可能会产生比较严重的后果。</p><p>所以必须保证数据库数据、缓存数据的一致性，这就是缓存与数据库的同步。</p><h4 id="数据同步策略">数据同步策略</h4><p>缓存数据同步的常见方式有三种：</p><p><strong>设置有效期</strong>：给缓存设置有效期，到期后自动删除。再次查询时更新</p><ul><li>优势：简单、方便</li><li>缺点：时效性差，缓存过期之前可能不一致</li><li>场景：更新频率较低，时效性要求低的业务</li></ul><p><strong>同步双写</strong>：在修改数据库的同时，直接修改缓存</p><ul><li>优势：时效性强，缓存与数据库强一致</li><li>缺点：有代码侵入，耦合度高；</li><li>场景：对一致性、时效性要求较高的缓存数据</li></ul><p><strong>异步通知：</strong>修改数据库时发送事件通知，相关服务监听到通知后修改缓存数据</p><ul><li>优势：低耦合，可以同时通知多个缓存服务</li><li>缺点：时效性一般，可能存在中间不一致状态</li><li>场景：时效性要求一般，有多个服务需要同步</li></ul><p>而异步实现又可以基于 MQ 或者 Canal 来实现：</p><p>1）基于 MQ 的异步通知：</p><figure><img src="http://img.catpaws.top/img/image-20210821115552327-2024-12-2721_56_52.png" srcset="/img/loading.gif" lazyload alt="image-20210821115552327"><figcaption aria-hidden="true">image-20210821115552327</figcaption></figure><ul><li>商品服务完成对数据的修改后，只需要发送一条消息到 MQ 中。</li><li>缓存服务监听 MQ 消息，然后完成对缓存的更新</li></ul><p>依然有少量的代码侵入。</p><p>2）基于 Canal 的通知</p><figure><img src="http://img.catpaws.top/img/image-20210821115719363-2024-12-2721_56_50.png" srcset="/img/loading.gif" lazyload alt="image-20210821115719363"><figcaption aria-hidden="true">image-20210821115719363</figcaption></figure><ul><li>商品服务完成商品修改后，业务直接结束，没有任何代码侵入</li><li>Canal 监听 MySQL 变化，当发现变化后，立即通知缓存服务</li><li>缓存服务接收到 canal 通知，更新缓存</li></ul><p>代码零侵入</p><h4 id="初识-canal">初识 Canal</h4><p><strong>Canal </strong>译意为水道/管道，canal 是阿里巴巴旗下的一款开源项目，基于 Java 开发。<strong>基于数据库增量日志解析，提供增量数据订阅&amp;消费</strong>。<a target="_blank" rel="noopener" href="https://github.com/alibaba/canal">GitHub 的地址</a></p><p>Canal 是基于<strong>MySQL 的主从同步</strong>来实现的，MySQL 主从同步的原理如下：</p><figure><img src="http://img.catpaws.top/img/image-20210821115914748-2024-12-2723_01_28.png" srcset="/img/loading.gif" lazyload alt="image-20210821115914748"><figcaption aria-hidden="true">image-20210821115914748</figcaption></figure><ol type="1"><li>MySQL master 将数据变更写入二进制日志( binary log），其中记录的数据叫做 binary log events</li><li>MySQL slave 将 master 的 binary log events 拷贝到它的中继日志(relay log)</li><li>MySQL slave 重放 relay log 中事件，将数据变更反映它自己的数据</li></ol><p><strong>而 Canal 就是把自己伪装成 MySQL 的一个 slave 节点，从而监听 master 的 binary log 变化。再把得到的变化信息通知给 Canal 的客户端，进而完成对其它数据库的同步。</strong></p><figure><img src="http://img.catpaws.top/img/image-20210821115948395-2024-12-2723_03_46.png" srcset="/img/loading.gif" lazyload alt="image-20210821115948395"><figcaption aria-hidden="true">image-20210821115948395</figcaption></figure><h4 id="安装-canal">安装 Canal</h4><p><a href="https://catpaws.top/ceeb6373/">安装教程</a></p><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1cr4y1671t?vd_source=51d78ede0a0127d1839d6abf9204d1ee&amp;spm_id_from=333.788.videopod.episodes&amp;p=131">参考视频</a></p><h4 id="监听-canal">监听 Canal</h4><p>Canal 提供了各种语言的客户端，当 Canal 监听到 binlog 变化时，会通知 Canal 的客户端。此处利用 Canal 提供的 Java 客户端，监听 Canal 通知消息。当收到变化的消息时，完成对缓存的更新。</p><figure><img src="http://img.catpaws.top/img/image-20210821120049024-2024-12-2723_19_34.png" srcset="/img/loading.gif" lazyload alt="image-20210821120049024"><figcaption aria-hidden="true">image-20210821120049024</figcaption></figure><p>对于 springboot 项目，GitHub 上的第三方开源的<a target="_blank" rel="noopener" href="https://github.com/NormanGyllenhaal/canal-client">canal-starter</a>与 SpringBoot 完美整合，自动装配，比官方客户端要简单好用很多。</p><p>1、引入依赖</p><div class="code-wrapper"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>top.javatool<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>canal-spring-boot-starter<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.2.1-RELEASE<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span></code></pre></div><p>2、添加配置</p><div class="code-wrapper"><pre><code class="hljs properties"><span class="hljs-attr">canal</span>:<span class="hljs-string"></span>
  <span class="hljs-attr">destination</span>: <span class="hljs-string">item-service  	# canal的集群名字，要与安装canal时设置的名称一致</span>
  <span class="hljs-attr">server</span>: <span class="hljs-string">192.168.150.101:11111  # canal服务地址</span></code></pre></div><p>3、Canal 推送给 canal-client 的是被修改的这一行数据（row），而我们引入的 canal-client 则会帮我们把行数据封装到指定的实体类中。这个过程中需要知道数据库与实体的映射关系，要用到 JPA 的几个注解：<code>@Id</code>、<code>@Column</code>、<code>@Transient</code>等，说明实体类和表中字段的映射关系。</p><figure><img src="http://img.catpaws.top/img/image-20241227233005012-2024-12-2723_30_06.png" srcset="/img/loading.gif" lazyload alt="常用注解的作用"><figcaption aria-hidden="true">常用注解的作用</figcaption></figure><p>4、添加监听器。通过实现<code>EntryHandler&lt;T&gt;</code>接口编写监听器，监听 Canal 消息。注意两点：</p><ul><li>实现类通过<code>@CanalTable("tb_item")</code>指定监听的表信息</li><li>EntryHandler 的泛型是与表对应的实体类</li></ul><figure><img src="http://img.catpaws.top/img/image-20241227233153170-2024-12-2723_31_54.png" srcset="/img/loading.gif" lazyload alt="监听器基本结构"><figcaption aria-hidden="true">监听器基本结构</figcaption></figure><div class="code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@Component</span>
<span class="hljs-meta">@CanalTable(&quot;tb_item&quot;)</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ItemHandler</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">EntryHandler</span>&lt;Item&gt; &#123;
    <span class="hljs-meta">@Autowired</span>
    <span class="hljs-keyword">private</span> StringRedisTemplate stringRedisTemplate;
    <span class="hljs-meta">@Autowired</span>
    <span class="hljs-keyword">private</span> Cache&lt;Long,Item&gt; itemCache;
    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">ObjectMapper</span> <span class="hljs-variable">objectMapper</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ObjectMapper</span>();

    <span class="hljs-meta">@Override</span>
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">insert</span><span class="hljs-params">(Item item)</span> &#123;
        <span class="hljs-comment">//添加数据到JVM缓存</span>
        itemCache.put(item.getId(),item);
        <span class="hljs-comment">//添加数据到Redis缓存</span>
        saveItem(item);
    &#125;

    <span class="hljs-meta">@Override</span>
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">update</span><span class="hljs-params">(Item before, Item after)</span> &#123;
        <span class="hljs-comment">//添加数据到JVM缓存</span>
        itemCache.put(after.getId(),after);
        <span class="hljs-comment">//添加数据到Redis缓存</span>
        saveItem(after);
    &#125;

    <span class="hljs-meta">@Override</span>
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">delete</span><span class="hljs-params">(Item item)</span> &#123;
        <span class="hljs-comment">//删除JVM缓存中对应的数据</span>
        itemCache.invalidate(item.getId());
        <span class="hljs-comment">//删除Redis缓存中对应的数据</span>
        deleteItem(item);
    &#125;


    <span class="hljs-comment">/**</span>
<span class="hljs-comment">     * 向Redis中添加商品数据</span>
<span class="hljs-comment">     * <span class="hljs-doctag">@param</span> item</span>
<span class="hljs-comment">     */</span>
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">saveItem</span><span class="hljs-params">(Item item)</span> &#123;
        <span class="hljs-keyword">try</span> &#123;
            <span class="hljs-type">String</span> <span class="hljs-variable">itemJson</span> <span class="hljs-operator">=</span> objectMapper.writeValueAsString(item);
            stringRedisTemplate.opsForValue().set(<span class="hljs-string">&quot;item:id&quot;</span>+item.getId(),itemJson);
        &#125; <span class="hljs-keyword">catch</span> (JsonProcessingException e) &#123;
            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">RuntimeException</span>(e);
        &#125;
    &#125;

    <span class="hljs-comment">/**</span>
<span class="hljs-comment">     * 删除Redis中对应的商品数据</span>
<span class="hljs-comment">     * <span class="hljs-doctag">@param</span> item</span>
<span class="hljs-comment">     */</span>
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">deleteItem</span><span class="hljs-params">(Item item)</span> &#123;
        stringRedisTemplate.delete(<span class="hljs-string">&quot;item:id&quot;</span>+item.getId());
    &#125;
&#125;
</code></pre></div><h2 id="三redis-最佳实践">三、Redis 最佳实践</h2><h3 id="redis-键值设计">3.1、Redis 键值设计</h3><h4 id="优雅的-key-结构">优雅的 Key 结构</h4><p>Redis 的 Key 虽然可以自定义，但最好遵循下面的几个最佳实践约定：</p><ul><li>遵循基本格式：<strong>[业务名称]：[数据名]：[id]</strong></li><li><strong>长度不超过 44 字节</strong></li><li>不包含特殊字符</li></ul><p>例如：我们的登录业务，保存用户信息，其 key 是这样的：</p><p><img src="http://img.catpaws.top/img/image-20241229104044294-2024-12-2910_40_57.png" srcset="/img/loading.gif" lazyload alt="image-20241229104044294" style="zoom:80%"></p><p>优点：</p><ol type="1"><li>可读性强</li><li>避免 key 冲突</li><li>方便管理</li><li>更节省内存</li></ol><p>为什么 key 的长度不要超过 44 字节？查看<a href="https://catpaws.top/284457ed/#string">Redis 的 String 类型编码详解</a></p><blockquote><p>通过<code>OBJECT ENCODING &lt;key&gt;</code>命令可以查看一个数据库键的值对象的编码。</p></blockquote><figure><img src="http://img.catpaws.top/img/image-20241229210405733-2024-12-2921_04_20.png" srcset="/img/loading.gif" lazyload alt="image-20241229210405733"><figcaption aria-hidden="true">image-20241229210405733</figcaption></figure><h4 id="拒绝-bigkey">拒绝 BigKey</h4><h5 id="什么是-bigkey"><strong>什么是 BigKey？</strong></h5><p>BigKey 通常以<strong>Key 的大小</strong>和<strong>Key 中成员的数量</strong>来综合判定，例如：</p><ul><li>Key 本身的数据量过大：一个 String 类型的 Key，它的值为 5 MB。</li><li>Key 中的成员数过多：一个 ZSET 类型的 Key，它的成员数量为 10，000 个。</li><li>Key 中成员的数据量过大：一个 Hash 类型的 Key，它的成员数量虽然只有 1，000 个但这些成员的 Value（值）总大小为 100 MB。</li></ul><p>推荐值：</p><ul><li>单个 key 的 value 小于 10KB</li><li>对于集合类型的 key，建议元素数量小于 1000</li></ul><h5 id="bigkey-的危害"><strong>BigKey 的危害</strong></h5><ul><li><p>网络阻塞</p><p>对 BigKey 执行读请求时，少量的 QPS 就可能导致带宽使用率被占满，导致 Redis 实例，乃至所在物理机变慢</p></li><li><p>数据倾斜 集群中各节点内存空间使用可能非常不均衡，BigKey 所在的 Redis 实例内存使用率远超其他实例，无法使数据分片的内存资源达到均衡。也会导致在集群模式下，数据迁移和复制变得困难</p></li><li><p>Redis 阻塞 对元素较多的 hash、list、zset 等做运算会耗时较旧，使主线程被阻塞</p></li><li><p>CPU 压力 对 BigKey 的数据序列化和反序列化会导致 CPU 的使用率飙升，影响 Redis 实例和本机其它应用</p></li></ul><h5 id="如何发现-bigkey"><strong>如何发现 BigKey</strong></h5><ul><li><p><code>redis-cli--bigkeys</code></p><p>利用 redis-cli 提供的--bigkeys 参数，可以遍历分析所有 key，并返回 Key 的整体统计信息与<strong>每个数据类型的 Top1</strong>的 big key 。当然，每个类型的 Top1 未必就是 BigKey，也有可能 Top2 也是 BigKey，但该命令无法列出，该命令的结果只做参考，</p><figure><img src="http://img.catpaws.top/img/image-20241229213242858-2024-12-2921_33_24.png" srcset="/img/loading.gif" lazyload alt="image-20241229213242858"><figcaption aria-hidden="true">image-20241229213242858</figcaption></figure></li><li><p>scan 扫描 自己编程，利用<code>scan</code>命令扫描 Redis 中的所有 key，利用 strlen，hlen 等命令判断 key 的长度（此处不建议使用 MEMORY USAGE）。</p><p><code>SCAN</code>命令是扫描 redis 中所有的 key，而 Redis 还提供了针对集合 key 的扫描命令<a target="_blank" rel="noopener" href="https://redis.io/docs/latest/commands/hscan/">HSCAN</a>、<a target="_blank" rel="noopener" href="https://redis.io/docs/latest/commands/sscan/">SSCAN</a>、<a target="_blank" rel="noopener" href="https://redis.io/docs/latest/commands/zscan/">ZSCAN</a>。</p><blockquote><p>Redis 的 SCAN 命令是一个<strong>基于游标的迭代器</strong>，用于逐步遍历数据库中的 key。与 KEYS 命令不同，SCAN 命令不会一次性返回所有匹配的 key，而是<strong>分批返回</strong>，从而减轻了对 Redis 服务器的负担。</p><p>基本语法：</p><div class="code-wrapper"><pre><code class="hljs bash">SCAN cursor [MATCH pattern] [COUNT count]</code></pre></div><ul><li>‌<strong>cursor</strong>‌：表示当前遍历的位置，初始值为 0。每次调用 SCAN 命令后，Redis 会返回一个新的游标值，用于下一次迭代。</li><li>‌<strong>MATCH pattern</strong>‌：可选参数，用于指定匹配的模式，只返回符合模式的 key。</li><li>‌<strong>COUNT count</strong>‌：可选参数，用于指定每次迭代返回的 key 数量。这是一种提示（hint），并不保证精确返回指定数量的 key。</li></ul></blockquote><p>使用 jedis 连接 Reids，使用<code>Scan</code>命令分批读取所有 key，对读取的 key 按数据类型进行分类判断是不是 BigKey，若超过指定标准，则输出该 key 的相关信息。</p><div class="code-wrapper"><pre><code class="hljs java"><span class="hljs-keyword">import</span> com.heima.jedis.util.JedisConnectionFactory;
<span class="hljs-keyword">import</span> org.junit.jupiter.api.AfterEach;
<span class="hljs-keyword">import</span> org.junit.jupiter.api.BeforeEach;
<span class="hljs-keyword">import</span> org.junit.jupiter.api.Test;
<span class="hljs-keyword">import</span> redis.clients.jedis.Jedis;
<span class="hljs-keyword">import</span> redis.clients.jedis.ScanResult;

<span class="hljs-keyword">import</span> java.util.HashMap;
<span class="hljs-keyword">import</span> java.util.List;
<span class="hljs-keyword">import</span> java.util.Map;

<span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">JedisTest</span> &#123;
    <span class="hljs-keyword">private</span> Jedis jedis;

    <span class="hljs-meta">@BeforeEach</span>
    <span class="hljs-keyword">void</span> <span class="hljs-title function_">setUp</span><span class="hljs-params">()</span> &#123;
        <span class="hljs-comment">// 1.建立连接</span>
        <span class="hljs-comment">// jedis = new Jedis(&quot;192.168.150.101&quot;, 6379);</span>
        jedis = JedisConnectionFactory.getJedis();
        <span class="hljs-comment">// 2.设置密码</span>
        jedis.auth(<span class="hljs-string">&quot;123321&quot;</span>);
        <span class="hljs-comment">// 3.选择库</span>
        jedis.select(<span class="hljs-number">0</span>);
    &#125;

    <span class="hljs-comment">// BigKey判断标准，单个key大小不要超过10kB，集合key不要超过500个成员</span>
    <span class="hljs-keyword">final</span> <span class="hljs-keyword">static</span> <span class="hljs-type">int</span> <span class="hljs-variable">STR_MAX_LEN</span> <span class="hljs-operator">=</span> <span class="hljs-number">10</span> * <span class="hljs-number">1024</span>;
    <span class="hljs-keyword">final</span> <span class="hljs-keyword">static</span> <span class="hljs-type">int</span> <span class="hljs-variable">HASH_MAX_LEN</span> <span class="hljs-operator">=</span> <span class="hljs-number">500</span>;

    <span class="hljs-meta">@Test</span>
    <span class="hljs-keyword">void</span> <span class="hljs-title function_">testScan</span><span class="hljs-params">()</span> &#123;
        <span class="hljs-type">int</span> <span class="hljs-variable">maxLen</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;
        <span class="hljs-type">long</span> <span class="hljs-variable">len</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;

        <span class="hljs-type">String</span> <span class="hljs-variable">cursor</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;0&quot;</span>;
        <span class="hljs-keyword">do</span> &#123;
            <span class="hljs-comment">// 扫描并获取一部分key</span>
            ScanResult&lt;String&gt; result = jedis.scan(cursor);
            <span class="hljs-comment">// 记录cursor</span>
            cursor = result.getCursor();
            List&lt;String&gt; list = result.getResult();
            <span class="hljs-keyword">if</span> (list == <span class="hljs-literal">null</span> || list.isEmpty()) &#123;
                <span class="hljs-keyword">break</span>;
            &#125;
            <span class="hljs-comment">// 遍历</span>
            <span class="hljs-keyword">for</span> (String key : list) &#123;
                <span class="hljs-comment">// 判断key的类型</span>
                <span class="hljs-type">String</span> <span class="hljs-variable">type</span> <span class="hljs-operator">=</span> jedis.type(key);
                <span class="hljs-keyword">switch</span> (type) &#123;
                    <span class="hljs-keyword">case</span> <span class="hljs-string">&quot;string&quot;</span>:
                        len = jedis.strlen(key);
                        maxLen = STR_MAX_LEN;
                        <span class="hljs-keyword">break</span>;
                    <span class="hljs-keyword">case</span> <span class="hljs-string">&quot;hash&quot;</span>:
                        len = jedis.hlen(key);
                        maxLen = HASH_MAX_LEN;
                        <span class="hljs-keyword">break</span>;
                    <span class="hljs-keyword">case</span> <span class="hljs-string">&quot;list&quot;</span>:
                        len = jedis.llen(key);
                        maxLen = HASH_MAX_LEN;
                        <span class="hljs-keyword">break</span>;
                    <span class="hljs-keyword">case</span> <span class="hljs-string">&quot;set&quot;</span>:
                        len = jedis.scard(key);
                        maxLen = HASH_MAX_LEN;
                        <span class="hljs-keyword">break</span>;
                    <span class="hljs-keyword">case</span> <span class="hljs-string">&quot;zset&quot;</span>:
                        len = jedis.zcard(key);
                        maxLen = HASH_MAX_LEN;
                        <span class="hljs-keyword">break</span>;
                    <span class="hljs-keyword">default</span>:
                        <span class="hljs-keyword">break</span>;
                &#125;
                <span class="hljs-keyword">if</span> (len &gt;= maxLen) &#123;
                    System.out.printf(<span class="hljs-string">&quot;Found big key : %s, type: %s, length or size: %d %n&quot;</span>, key, type, len);
                &#125;
            &#125;
        &#125; <span class="hljs-keyword">while</span> (!cursor.equals(<span class="hljs-string">&quot;0&quot;</span>));
    &#125;

    <span class="hljs-meta">@AfterEach</span>
    <span class="hljs-keyword">void</span> <span class="hljs-title function_">tearDown</span><span class="hljs-params">()</span> &#123;
        <span class="hljs-keyword">if</span> (jedis != <span class="hljs-literal">null</span>) &#123;
            jedis.close();
        &#125;
    &#125;
&#125;</code></pre></div><figure><img src="http://img.catpaws.top/img/image-20241229214647372-2024-12-2921_47_24.png" srcset="/img/loading.gif" lazyload alt="image-20241229214647372"><figcaption aria-hidden="true">image-20241229214647372</figcaption></figure></li><li><p>第三方工具 利用第三方工具，如<a target="_blank" rel="noopener" href="https://github.com/sripathikrishnan/redis-rdb-tools">Redis-Rdb-Tools</a> 离线分析 RDB 快照文件，全面分析内存使用情况，对 Redis 性能没有任何影响，但可能存在数据时效性的差异。</p></li><li><p>网络监控 自定义工具，监控进出 Redis 的网络数据，超出预警值时主动告警。</p></li></ul><h5 id="删除-bigkey"><strong>删除 BigKey</strong></h5><p>在找到 BigKey 后，应该将 BigKey 的数据进行拆分，重新存储，之后再删除该 key。</p><p>Bigkey 内存占用较多，即便时删除这样的 key 也需要耗费很长时间，导致 Redis 主线程阻塞，引发一系列问题。</p><ul><li>redis 3.0 及以下版本 如果是集合类型，则遍历 BigKey 的元素，<strong>先逐个删除子元素，最后删除 BigKey</strong></li><li>Redis 4.0 以后 <code>UNLINK</code> 是 Redis 4.0 及更高版本中引入的一个新命令，用于异步地删除一个或多个键。与 <code>DEL</code> 命令不同，<code>UNLINK</code> 命令不会立即释放与键相关联的内存，而是将键的删除操作放入后台线程中异步执行，从而避免在删除大量键时对 Redis 的主线程造成阻塞。</li></ul><blockquote><p>补充：<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/631094333/answer/3299005487">Redis 的 HotKey</a></p></blockquote><h4 id="恰当的数据类型">恰当的数据类型</h4><h5 id="例一">例一</h5><p>比如存储一个 User 对象，我们有三种存储方式：</p><p><strong>① 方式一：json 字符串</strong></p><div class="line-block">user:1 | {"name": "Jack", "age": 21} |</div><p>优点：实现简单粗暴</p><p>缺点：数据耦合，不够灵活</p><p><strong>② 方式二：字段打散</strong></p><table><thead><tr class="header"><th style="text-align:center">user:1:name</th><th style="text-align:center">Jack</th></tr></thead><tbody><tr class="odd"><td style="text-align:center">user:1:age</td><td style="text-align:center">21</td></tr></tbody></table><p>优点：可以灵活访问对象任意字段</p><p>缺点：占用空间大、没办法做统一控制</p><p><strong>③ 方式三：hash（推荐）</strong></p><table><tr><td rowspan="2">user:1</td><td>name</td><td>jack</td></tr><tr><td>age</td><td>21</td></tr></table><p>优点：底层使用 ziplist，空间占用小，可以灵活访问对象的任意字段</p><p>缺点：代码相对复杂</p><h5 id="例二">例二</h5><p>假如有 hash 类型的 key，其中有 100 万对 field 和 value，field 是自增 id，这个 key 存在什么问题？如何优化？</p><table><tr style="color:red"><td>key</td><td>field</td><td>value</td></tr><tr><td rowspan="3">someKey</td><td>id:0</td><td>value0</td></tr><tr><td>.....</td><td>.....</td></tr><tr><td>id:999999</td><td>value999999</td></tr></table><p>存在的问题：</p><ul><li><p>hash 的 entry 数量超过 500 时，会使用哈希表而不是 ZipList，内存占用较多</p><figure><img src="http://img.catpaws.top/img/image-20220521142943350-2024-12-2922_20_10.png" srcset="/img/loading.gif" lazyload alt="image-20220521142943350"><figcaption aria-hidden="true">image-20220521142943350</figcaption></figure></li><li><p>可以通过 hash-max-ziplist-entries 配置 entry 上限。但是如果 entry 过多就会导致 BigKey 问题</p></li></ul><p><strong>方案一</strong></p><p>拆分为 string 类型</p><table><tr style="color:red"><td>key</td><td>value</td></tr><tr><td>id:0</td><td>value0</td></tr><tr><td>.....</td><td>.....</td></tr><tr><td>id:999999</td><td>value999999</td></tr></table><p>存在的问题：</p><ul><li>string 结构底层没有太多内存优化，内存占用较多</li></ul><figure><img src="http://img.catpaws.top/img/image-20220521143458010-2024-12-2922_20_18.png" srcset="/img/loading.gif" lazyload alt="image-20220521143458010"><figcaption aria-hidden="true">image-20220521143458010</figcaption></figure><ul><li>想要批量获取这些数据比较麻烦</li></ul><p><strong>方案二</strong></p><p>拆分为小的 hash，<strong>将 id / 100 作为 key， 将 id % 100 作为 field</strong>，这样每 100 个元素为一个 Hash</p><table><tr style="color:red"><td>key</td><td>field</td><td>value</td></tr><tr><td rowspan="3">key:0</td><td>id:00</td><td>value0</td></tr><tr><td>.....</td><td>.....</td></tr><tr><td>id:99</td><td>value99</td></tr><tr><td rowspan="3">key:1</td><td>id:00</td><td>value100</td></tr><tr><td>.....</td><td>.....</td></tr><tr><td>id:99</td><td>value199</td></tr><tr><td colspan="3">....</td></tr><tr><td rowspan="3">key:9999</td><td>id:00</td><td>value999900</td></tr><tr><td>.....</td><td>.....</td></tr><tr><td>id:99</td><td>value999999</td></tr></table><figure><img src="http://img.catpaws.top/img/image-20220521144339377-2024-12-2922_20_21.png" srcset="/img/loading.gif" lazyload alt="image-20220521144339377"><figcaption aria-hidden="true">image-20220521144339377</figcaption></figure><h3 id="批处理优化">3.2、批处理优化</h3><p>对于海量数据进行处理时，可以选择 N 条命令逐个执行，也可以选择每次执行 m 条，分 n 次执行完。</p><p>一次 Redis 命令的执行耗时，主要客户端和 Redis 服务器之间一次往返的网络传输耗时 + 一次 Redis 命令处理耗时，其中网络传输耗时占命令耗时的主要部分。</p><p>若 N 条命令依次执行，则<strong>N 条命令的响应时间 = N 次往返的网络传输耗时 + N 次 Redis 执行命令耗时</strong></p><figure><img src="http://img.catpaws.top/img/image-20241229224534815-2024-12-2922_46_24.png" srcset="/img/loading.gif" lazyload alt="N条命令依次执行"><figcaption aria-hidden="true">N条命令依次执行</figcaption></figure><p>若 N 条命令批量执行，<strong>N 次命令的响应时间 =m 次往返的网络传输耗时 + N 次 Redis 执行命令耗时</strong></p><figure><img src="http://img.catpaws.top/img/image-20241229224753860-2024-12-2922_47_54.png" srcset="/img/loading.gif" lazyload alt="N条命令批量执行"><figcaption aria-hidden="true">N条命令批量执行</figcaption></figure><blockquote><p>注：不要在一次批处理中传输太多命令，否则单次命令占用带宽过多，会导致网络阻塞</p></blockquote><h4 id="单机模式下的批处理pipeline">单机模式下的批处理：Pipeline</h4><p>Redis 提供了很多<code>Mxxx</code>这样的命令，可以实现批量插入数据，例如：<code>MSET</code>,<code>MHSET</code>等，但这些命令虽然可以批处理，但是却只能操作部分数据类型，因此如果有对复杂数据类型的批处理需要，建议使用 Pipeline 功能。使用 Pipeline 可以添加对任意数据类型操作的命令，十分灵活。</p><p>Pipeline 允许客户端将多个命令一次性发送到 Redis 服务器，而不是逐个发送命令并等待响应。这种方式显著减少了网络延迟和通信开销，从而提高了命令执行的效率。</p><p><strong>大致工作流程如下：</strong></p><ol type="1"><li>客户端创建一个 Pipeline 对象，并向其中添加需要执行的命令。</li><li>客户端将所有命令一次性发送到 Redis 服务器。</li><li>由于<strong>Redis 是单线程执行命令</strong>，Redis 服务器接收到命令后，会对命令进行<strong>排队</strong>，依次执行这些命令，并将每个命令的结果存储起来。</li><li>客户端等待所有命令执行完成后，从服务器获取结果并按照命令发送的顺序进行处理。</li></ol><p>例如，使用 Jedis 的 pipeline 功能，批量处理 100000 条数据</p><div class="code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@Test</span>
<span class="hljs-keyword">void</span> <span class="hljs-title function_">testPipeline</span><span class="hljs-params">()</span> &#123;
    <span class="hljs-comment">// 创建管道</span>
    <span class="hljs-type">Pipeline</span> <span class="hljs-variable">pipeline</span> <span class="hljs-operator">=</span> jedis.pipelined();
    <span class="hljs-type">long</span> <span class="hljs-variable">b</span> <span class="hljs-operator">=</span> System.currentTimeMillis();
    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt;= <span class="hljs-number">100000</span>; i++) &#123;
        <span class="hljs-comment">// 放入命令到管道</span>
        pipeline.set(<span class="hljs-string">&quot;test:key_&quot;</span> + i, <span class="hljs-string">&quot;value_&quot;</span> + i);
        <span class="hljs-keyword">if</span> (i % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>) &#123;
            <span class="hljs-comment">// 每放入1000条命令，批量执行</span>
            pipeline.sync();
        &#125;
    &#125;
    <span class="hljs-type">long</span> <span class="hljs-variable">e</span> <span class="hljs-operator">=</span> System.currentTimeMillis();
    System.out.println(<span class="hljs-string">&quot;time: &quot;</span> + (e - b));
&#125;</code></pre></div><blockquote><p>注意事项：</p><ol type="i"><li><p>Pipeline 中的命令<strong>不具备原子性</strong>，即如果其中一个命令失败，不会影响到其他命令的执行。</p></li><li><p>使用 Pipeline 时，应该避免一次性发送过多命令，以免造成服务器处理阻塞，影响其他客户端的请求。</p></li></ol></blockquote><p>Spring Data Redis 也封装了对 Pipeline 的使用方法。<code>executePipelined</code> 是 Spring Data Redis 提供的一个方法，用于执行 Redis 的 Pipeline 操作。</p><p>在 Spring Data Redis 中，<code>executePipelined</code> 方法被定义在 <code>RedisTemplate</code> 类中。该方法接受一个 <code>RedisCallback&lt;List&lt;Object&gt;&gt;</code> 类型的参数，这个参数是一个回调接口，用于定义要在 Redis 上执行的命令。在回调接口的 <code>doInRedis</code> 方法中，可以使用 <code>RedisConnection</code> 来执行任意数量的 Redis 命令。这些命令会被打包成一个 Pipeline 请求发送到 Redis 服务器。</p><p><code>executePipelined</code> 方法的返回值是一个 <code>List&lt;Object&gt;</code>，包含了所有命令的执行结果。这些结果的顺序与你在 <code>doInRedis</code> 方法中执行命令的顺序是一致的。</p><div class="code-wrapper"><pre><code class="hljs java"><span class="hljs-keyword">import</span> org.springframework.beans.factory.annotation.Autowired;
<span class="hljs-keyword">import</span> org.springframework.data.redis.core.RedisCallback;
<span class="hljs-keyword">import</span> org.springframework.data.redis.core.RedisTemplate;
<span class="hljs-keyword">import</span> org.springframework.stereotype.Service;

<span class="hljs-keyword">import</span> java.util.List;

<span class="hljs-meta">@Service</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">RedisService</span> &#123;

    <span class="hljs-meta">@Autowired</span>
    <span class="hljs-keyword">private</span> RedisTemplate&lt;String, Object&gt; redisTemplate;

    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">executeRedisPipeline</span><span class="hljs-params">()</span> &#123;
        <span class="hljs-comment">// 使用 Pipeline 执行多个命令</span>
        List&lt;Object&gt; results = redisTemplate.executePipelined(<span class="hljs-keyword">new</span> <span class="hljs-title class_">RedisCallback</span>&lt;List&lt;Object&gt;&gt;() &#123;
            <span class="hljs-meta">@Override</span>
            <span class="hljs-keyword">public</span> List&lt;Object&gt; <span class="hljs-title function_">doInRedis</span><span class="hljs-params">(org.springframework.data.redis.connection.RedisConnection connection)</span> <span class="hljs-keyword">throws</span> Exception &#123;
                <span class="hljs-comment">// 开启 Pipeline（实际上，Spring Data Redis 在调用这个方法时已经为你管理了 Pipeline）</span>

                <span class="hljs-comment">// 执行命令，这些命令会被打包成一个 Pipeline 请求</span>
                connection.set(<span class="hljs-string">&quot;key1&quot;</span>.getBytes(), <span class="hljs-string">&quot;value1&quot;</span>.getBytes());
                connection.set(<span class="hljs-string">&quot;key2&quot;</span>.getBytes(), <span class="hljs-string">&quot;value2&quot;</span>.getBytes());
                connection.get(<span class="hljs-string">&quot;key1&quot;</span>.getBytes());

                <span class="hljs-comment">// 注意：这里不需要关闭连接，因为 Spring Data Redis 会为你处理</span>

                <span class="hljs-comment">// 返回 null 或者一个空列表，因为结果会通过 Pipeline 异步获取</span>
                <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;
            &#125;
        &#125;);

        <span class="hljs-comment">// 处理结果</span>
        <span class="hljs-keyword">for</span> (Object result : results) &#123;
            <span class="hljs-comment">// 根据命令的类型和顺序解析结果</span>
            System.out.println(result);
        &#125;
    &#125;
&#125;
</code></pre></div><blockquote><p>参考文章：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_39363204/article/details/125665896?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7EPaidSort-1-125665896-blog-119837981.235%5Ev43%5Epc_blog_bottom_relevance_base8&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7EPaidSort-1-125665896-blog-119837981.235%5Ev43%5Epc_blog_bottom_relevance_base8&amp;utm_relevant_index=2">RedisTemplate Pipeline 管道使用</a></p></blockquote><p>有的系统对延迟要求很高，那么 redis 管道第一次请求很慢，就需要在系统启动时进行管道的预热，保证系统启动后每次请求的低延迟。</p><div class="code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@PostConstruct</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">init</span><span class="hljs-params">()</span> &#123;
    <span class="hljs-type">long</span> <span class="hljs-variable">startTime</span> <span class="hljs-operator">=</span> System.currentTimeMillis();
    redisTemplate.executePipelined(<span class="hljs-keyword">new</span> <span class="hljs-title class_">SessionCallback</span>&lt;Object&gt;() &#123;
        <span class="hljs-meta">@Override</span>
        <span class="hljs-keyword">public</span> &lt;K, V&gt; Object <span class="hljs-title function_">execute</span><span class="hljs-params">(RedisOperations&lt;K, V&gt; operations)</span> <span class="hljs-keyword">throws</span> DataAccessException &#123;
            operations.hasKey((K) <span class="hljs-string">&quot;&quot;</span>);
            <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;
        &#125;
    &#125;);
    log.info(<span class="hljs-string">&quot;redis初始化管道请求end，耗时：&#123;&#125;ms&quot;</span>, System.currentTimeMillis() - startTime);
&#125;</code></pre></div><h4 id="集群下的批处理">集群下的批处理</h4><p>如果 Redis 是一个集群，那<strong>批处理命令的多个 key 必须落在一个插槽中</strong>，否则就会导致执行失败。</p><p>Pipeline 并不支持跨节点的命令执行。如果 pipeline 中的命令涉及多个不同的槽（即多个不同的节点），那么这些命令将无法在一个 pipeline 中成功执行。因为 Redis 集群是由多个节点组成的，每个节点只负责维护一部分数据。当尝试在属于不同节点的数据上使用 Pipeline 时，Redis 会返回错误，因为它不知道如何在不同节点之间协调和执行这些命令。同时，Pipeline 的主要目的是减少网络延迟和开销。如果 pipeline 中的命令需要跨多个节点执行，那么每个节点都需要处理并响应这些命令，这会增加网络延迟和处理的复杂度。</p><p><strong>四种解决方案</strong></p><figure><img src="http://img.catpaws.top/img/1653126446641-2024-12-3010_03_44.png" srcset="/img/loading.gif" lazyload alt="1653126446641"><figcaption aria-hidden="true">1653126446641</figcaption></figure><p>综合考虑下，使用并行 slot 处理较为合理，虽然实现较为复杂，需要创建多个线程并行执行各组 pipeline 命令，但其性能优于串行 Slot，也不会出现像 hash_tag 方案的数据倾斜问题。</p><p>在 Spring 集群环境下的<code>mset</code>、<code>hmset</code>等命令已经实现了并行 slot，解决了集群模式下的批处理问题。</p><p>测试代码</p><div class="code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@Test</span>
 <span class="hljs-keyword">void</span> <span class="hljs-title function_">testMSetInCluster</span><span class="hljs-params">()</span> &#123;
     Map&lt;String, String&gt; map = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;&gt;(<span class="hljs-number">3</span>);
     map.put(<span class="hljs-string">&quot;name&quot;</span>, <span class="hljs-string">&quot;Rose&quot;</span>);
     map.put(<span class="hljs-string">&quot;age&quot;</span>, <span class="hljs-string">&quot;21&quot;</span>);
     map.put(<span class="hljs-string">&quot;sex&quot;</span>, <span class="hljs-string">&quot;Female&quot;</span>);
     stringRedisTemplate.opsForValue().multiSet(map);


     List&lt;String&gt; strings = stringRedisTemplate.opsForValue().multiGet(Arrays.asList(<span class="hljs-string">&quot;name&quot;</span>, <span class="hljs-string">&quot;age&quot;</span>, <span class="hljs-string">&quot;sex&quot;</span>));
     strings.forEach(System.out::println);

 &#125;</code></pre></div><p>原理分析：</p><p>在 RedisAdvancedClusterAsyncCommandsImpl 类中</p><p>首先根据 slotHash 算出来一个 partitioned 的 map，map 中的 key 就是 slot，而他的 value 就是对应的对应相同 slot 的 key 对应的数据</p><p>通过 RedisFuture<string>mset = super.mset(op);进行异步的消息发送</string></p><div class="code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@Override</span>
<span class="hljs-keyword">public</span> RedisFuture&lt;String&gt; <span class="hljs-title function_">mset</span><span class="hljs-params">(Map&lt;K, V&gt; map)</span> &#123;

    Map&lt;Integer, List&lt;K&gt;&gt; partitioned = SlotHash.partition(codec, map.keySet());

    <span class="hljs-keyword">if</span> (partitioned.size() &lt; <span class="hljs-number">2</span>) &#123;
        <span class="hljs-keyword">return</span> <span class="hljs-built_in">super</span>.mset(map);
    &#125;

    Map&lt;Integer, RedisFuture&lt;String&gt;&gt; executions = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;&gt;();

    <span class="hljs-keyword">for</span> (Map.Entry&lt;Integer, List&lt;K&gt;&gt; entry : partitioned.entrySet()) &#123;

        Map&lt;K, V&gt; op = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;&gt;();
        entry.getValue().forEach(k -&gt; op.put(k, map.get(k)));

        RedisFuture&lt;String&gt; mset = <span class="hljs-built_in">super</span>.mset(op);
        executions.put(entry.getKey(), mset);
    &#125;

    <span class="hljs-keyword">return</span> MultiNodeExecution.firstOfAsync(executions);
&#125;</code></pre></div><h3 id="服务端优化">3.3、服务端优化</h3><h4 id="持久化配置"><strong>持久化配置</strong></h4><p>Redis 的持久化虽然可以保证数据安全，但也会带来很多额外的开销，因此持久化请遵循下列建议：</p><ul><li><p>用来做缓存的 Redis 实例尽量不要开启持久化功能</p></li><li><p>建议关闭 RDB 持久化功能，使用 AOF 持久化（AOF 数据时效性和安全性更好）</p><blockquote><p>redis.conf</p><div class="code-wrapper"><pre><code class="hljs properties"><span class="hljs-comment"># 关闭RDB持久化</span>
<span class="hljs-comment"># save 900 1</span>
<span class="hljs-comment"># save 300 10</span>
<span class="hljs-comment"># save 60 10000</span>
<span class="hljs-comment"></span>
<span class="hljs-comment"># 开启AOF持久化</span>
<span class="hljs-attr">appendonly</span> <span class="hljs-string">yes</span>
<span class="hljs-comment"></span>
<span class="hljs-comment"># 设置AOF同步频率</span>
<span class="hljs-attr">appendfsync</span> <span class="hljs-string">everysec</span></code></pre></div></blockquote></li><li><p>利用脚本定期在 slave 节点做 RDB，实现数据<strong>备份</strong>。频繁的 RDB fork 操作耗时较久，涉及大量磁盘 IO，对性能影响较大。</p></li><li><p>设置合理的 rewrite 阈值，避免频繁对 AOF 文件做 bgrewrite。(bgrewrite 对 CPU 和磁盘占用较高)</p><blockquote><p>redis.conf</p><div class="code-wrapper"><pre><code class="hljs properties"><span class="hljs-comment"># redis会记录上一次bgrewrite时的文件大小，当AOF文件大小超过上次文件大小指定的百分比后，会触发bgrewrite机制</span>
<span class="hljs-attr">auto-aof-rewrite-percentage</span> <span class="hljs-string">100</span>
<span class="hljs-comment"># 执行bgrewrite时AOF文件的最小容量</span>
<span class="hljs-attr">auto-aof-rewrite-min-size</span> <span class="hljs-string">64mb</span></code></pre></div></blockquote></li><li><p>配置<code>no-appendfsync-on-rewrite = yes</code>，禁止在 rewrite 期间做 aof，避免因 AOF 引起的阻塞。</p><p>在执行 bgrewrite 时对 CPU 和磁盘的占用较高，且这个过程持续时间较长，而 AOF 默认的同步刷盘频率是每秒执行一次。在开启 AOF 机制后，主线程执行完一条命令后，要判断当前的刷盘时间是否小于 2 秒，若超过两秒会阻塞等待刷盘操作完成。在执行 bgrewrite 期间肯定会影响到 AOF 的刷盘效率，可能进一步导致主线程阻塞。在设置了<code>no-appendfsync-on-rewrite = yes</code>后，Redis 若发现当前在做 bgrewrite，就不会做 AOF 同步，主线程执行完命令直接返回。但由于在此期间没有做 AOF 持久化，可能出现数据丢失的问题。</p><p>是否开启 在 bgrewrite 期间禁止做 AOF 同步，要视业务需求而定，若追求数据的安全，则设置为 no，若追求的是性能，则开启。</p><figure><img src="http://img.catpaws.top/img/image-20241230103348982-2024-12-3010_34_05.png" srcset="/img/loading.gif" lazyload alt="image-20241230103348982"><figcaption aria-hidden="true">image-20241230103348982</figcaption></figure></li><li><p>部署有关建议：</p><ul><li>Redis 实例的物理机要预留足够内存，应对 fork 和 rewrite</li><li>单个 Redis 实例内存上限不要太大，例如 4G 或 8G。可以加快 fork 的速度、减少主从同步、数据迁移压力</li><li>不要与 CPU 密集型应用部署在一起</li><li>不要与高硬盘负载应用一起部署。例如：数据库、消息队列</li></ul></li></ul><h4 id="慢查询">慢查询</h4><p>在 Redis 执行时耗时超过某个阈值的<strong>命令</strong>，称为慢查询。</p><p>慢查询的危害：由于 Redis 是单线程的，所以当客户端发出指令后，他们都会进入到 redis 底层的 queue 来执行，如果此时有一些慢查询的数据，就会导致大量请求阻塞，从而引起报错。</p><figure><img src="http://img.catpaws.top/img/1653129590210-2024-12-3010_52_29.png" srcset="/img/loading.gif" lazyload alt="1653129590210"><figcaption aria-hidden="true">1653129590210</figcaption></figure><p>慢查询的阈值在 redis.conf 中设置：</p><p><code>slowlog-log-slower-than</code>：慢查询阈值，单位是微秒。默认是 10000，建议 1000</p><p>慢查询会被放入慢查询日志中，日志的长度有上限，可以通过配置指定：</p><p><code>slowlog-max-len</code>：慢查询日志（本质是一个队列）的长度。默认是 128，建议 1000</p><figure><img src="http://img.catpaws.top/img/image-20241230105504516-2024-12-3010_55_05.png" srcset="/img/loading.gif" lazyload alt="image-20241230105504516"><figcaption aria-hidden="true">image-20241230105504516</figcaption></figure><p><strong>查看慢查询日志列表</strong></p><ul><li><code>slowlog len</code>：查询慢查询日志长度</li><li><code>slowlog get [n]</code>：读取 n 条慢查询日志</li><li><code>slowlog reset</code>：清空慢查询列表</li></ul><figure><img src="http://img.catpaws.top/img/1653130858066-2024-12-3010_56_01.png" srcset="/img/loading.gif" lazyload alt="1653130858066"><figcaption aria-hidden="true">1653130858066</figcaption></figure><p>也可以在图形化客户端中查看</p><figure><img src="http://img.catpaws.top/img/image-20241230105734147-2024-12-3010_57_36.png" srcset="/img/loading.gif" lazyload alt="image-20241230105734147"><figcaption aria-hidden="true">image-20241230105734147</figcaption></figure><h4 id="安全配置">安全配置</h4><p>安全可以说是服务器端一个非常重要的话题，如果安全出现了问题，那么一旦这个漏洞被一些坏人知道了之后，并且进行攻击，那么这就会给咱们的系统带来很多的损失，所以我们这节课就来解决这个问题。</p><p>Redis 会绑定在 0.0.0.0:6379，这样将会将 Redis 服务暴露到公网上，而 Redis 如果没有做身份认证，会出现严重的安全漏洞.<a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1039000">漏洞重现方式</a></p><p>为什么会出现不需要密码也能够登录呢，主要是 Redis 考虑到每次登录都比较麻烦，所以 Redis 就有一种 ssh 免秘钥登录的方式，生成一对公钥和私钥，私钥放在本地，公钥放在 redis 端，当我们登录时服务器，再登录时候，他会去解析公钥和私钥，如果没有问题，则不需要利用 redis 的登录也能访问，这种做法本身也很常见，但是这里有一个前提，前提就是公钥必须保存在服务器上，才行，但是 Redis 的漏洞在于在不登录的情况下，也能把秘钥送到 Linux 服务器，从而产生漏洞。其核心操作就是连接到 Redis 服务器，使用<code>config set</code>命令修改 Redis 持久化文件的名称和保存目录，再执行持久化操作，将秘钥内容写入服务器，完成免密登录。</p><p>漏洞出现的核心的原因有以下几点：</p><ul><li>Redis 未设置密码</li><li>利用了 Redis 的 config set 命令动态修改 Redis 配置</li><li>使用了 Root 账号权限启动 Redis</li></ul><p>所以：如何解决呢？我们可以采用如下几种方案</p><p>为了避免这样的漏洞，这里给出一些建议：</p><ul><li><p>Redis 一定要设置密码</p></li><li><p>禁止线上使用下面命令：keys、flushall、flushdb、config set 等命令。可以在配置文件中利用<code>rename-command</code>给这些命令重命名或禁用。</p><figure><img src="http://img.catpaws.top/img/image-20241230111054332-2024-12-3011_11_05.png" srcset="/img/loading.gif" lazyload alt="image-20241230111054332"><figcaption aria-hidden="true">image-20241230111054332</figcaption></figure></li><li><p>bind：限制网卡，禁止外网网卡访问</p></li><li><p>开启防火墙</p></li><li><p>不要使用 Root 账户启动 Redis</p></li><li><p>尽量不是有默认的端口</p></li></ul><h4 id="内存配置">内存配置</h4><p>当 Redis 内存不足时，可能导致 Key 频繁被删除、响应时间变长、QPS 不稳定等问题。当内存使用率达到 90%以上时就需要我们警惕，并快速定位到内存占用的原因。</p><p>查看到 Redis 目前的内存分配状态：</p><ul><li><p><code>info memory</code>：查看内存分配的情况</p></li><li><p><code>memory xxx</code>：查看 key 的主要占用情况</p><p><code>memory state</code>命令返回结果分析</p><div class="code-wrapper"><pre><code class="hljs bash">1）<span class="hljs-string">&quot;peak.allocated&quot;</span>//Redis进程自启动以来消耗内存的峰值。
2）（<span class="hljs-built_in">integer</span>）794923123）<span class="hljs-string">&quot;total.allocated&quot;</span>//Redis使用其分配器分配的总字节数，即当前的总内存使用量。
4）（<span class="hljs-built_in">integer</span>）79307776
5）<span class="hljs-string">&quot;startup.allocated&quot;</span>_//Redis启动时消耗的初始内存量。
6）（<span class="hljs-built_in">integer</span>）45582592
7）<span class="hljs-string">&quot;replication.backlog&quot;</span>//复制积压缓冲区的大小。
8）（<span class="hljs-built_in">integer</span>）33554432
9）<span class="hljs-string">&quot;clients.slaves&quot;</span>//主从复制中所有从节点的读写缓冲区大小。
10）（<span class="hljs-built_in">integer</span>）17266
11）<span class="hljs-string">&quot;clients.normal&quot;</span>//除从节点外，所有其他客户端的读写缓冲区大小。
12）（<span class="hljs-built_in">integer</span>）119102
13）<span class="hljs-string">&quot;aof.buffer&quot;</span>//AOF持久化使用的缓存和AOF重写时产生的缓存。
14）（<span class="hljs-built_in">integer</span>）0
15）<span class="hljs-string">&quot;db.0&quot;</span>//业务数据库的数量。
16）1）<span class="hljs-string">&quot;overhead.hashtable.main&quot;</span>//当前数据库的<span class="hljs-built_in">hash</span>链表开销内存总和，即元数据内存。
        2）（<span class="hljs-built_in">integer</span>）144
        3）<span class="hljs-string">&quot;overhead.hashtable.expires&quot;</span>//用于存储key的过期时间所消耗的内存。
        4）（<span class="hljs-built_in">integer</span>）e
17）<span class="hljs-string">&quot;overhead.total&quot;</span>//数值=startup.allocated+replication.backlog+clients.slaves+clients.normal+aof.buffer+db.X.
18）（<span class="hljs-built_in">integer</span>）79273616
19）<span class="hljs-string">&quot;keys.count&quot;</span>//当前Redis实例的key总数
20）（<span class="hljs-built_in">integer</span>）221）<span class="hljs-string">&quot;keys.bytes-per-key&quot;</span>//当前Redis实例每个key的平均大小，计算公式
21）<span class="hljs-string">&quot;keys.bytes-per-key&quot;</span>//当前Redis实例每个key的平均大小，计算公式：（total.allocated-startup.allocated）/keys.count.
22）（<span class="hljs-built_in">integer</span>）16862592
23）<span class="hljs-string">&quot;dataset.bytes&quot;</span>//纯业务数据占用的内存大小。
24）（<span class="hljs-built_in">integer</span>）34160
25）<span class="hljs-string">&quot;dataset.percentage&quot;</span>//纯业务数据占用的内存比例，计算公式：dataset.bytes*100/（total.allocated-startup.allocated）.
26）<span class="hljs-string">&quot;0.1012892946600914&quot;</span>
27）<span class="hljs-string">&quot;peak.percentage&quot;</span>//当前总内存与历史峰值的比例，计算公式：total.allocated*100/peak.allocated.
28）<span class="hljs-string">&quot;99.767860412597656&quot;</span>
29）<span class="hljs-string">&quot;fragmentation&quot;</span>//内存的碎片率。
30）<span class="hljs-string">&quot;0.45836541056632996&quot;</span>
</code></pre></div></li></ul><p>Redis 的内存占用主要划分为以下几个部分：</p><figure><img src="http://img.catpaws.top/img/image-20241230132253444-2024-12-3013_23_01.png" srcset="/img/loading.gif" lazyload alt="Redis内存划分"><figcaption aria-hidden="true">Redis内存划分</figcaption></figure><p><strong>1、数据内存问题分析</strong>：</p><p>主要是 BigKey 和内存碎片问题。</p><p>其中 BigKey 之前已经讲过，应该选择合适的数据结构避免出现 BigKey，对已经出现的 BigKey 的数据进行拆分后删除即可。</p><p>内存碎片的形成主要有以下几个原因：</p><ol type="i"><li><p><strong>内存分配机制</strong>：Redis 使用的内存分配器（默认是<code>jemalloc</code>）<strong>会按照固定大小来分配内存，而不是完全按照程序申请的内存大小来进行分配。</strong>这可能导致分配的内存空间大于实际需要的空间，从而产生碎片 ‌。例如，当前 key 只需要 10 个字节，此时分配 8 肯定不够，那么他就会分配 16 个字节，多出来的 6 个字节就不能被使用。内存碎片对 Redis 的影响主要体现在内存利用率上。虽然内存碎片不会影响 Redis 的性能，但会降低内存的实际可用空间，从而可能导致 Redis 需要和外存进行数据交换（Swap），或者根据淘汰策略清理老数据，进而影响整体系统的性能。</p></li><li><p><strong>数据删除与修改</strong>‌：当 Redis 删除或修改数据时，释放的内存空间并不一定能被立即重新利用。尤其是当这些空闲内存空间大小不一致时，就更可能导致内存碎片的出现 ‌</p></li></ol><p>为了清理内存碎片，Redis 4.0 版本后提供了自动内存碎片清理机制 ‌。此外，也可以通过重启 Redis 服务来清理内存碎片，但这种方法需要谨慎使用，因为重启期间 Redis 不可用，且如果未开启持久化机制，数据可能会丢失。</p><p><strong>2、进程内存问题分析：</strong></p><p>Redis 进程自身运行所需的内存消耗，这部分内存消耗通常非常小，通常可以忽略不计</p><p><strong>3、缓冲区内存问题分析：</strong></p><p>缓冲区内存占用波动较大，特别是在高并发或大流量场景下，需要重点分析和管理。</p><p>Redis 的缓冲区内存主要包括以下几个部分：</p><p>‌<strong>复制缓存（Replication Backlog Buffer）</strong>‌：</p><ul><li>这是一个可重用的固定大小缓冲区（<code>repl_backlog_buf</code>），用于支持主从复制功能。如果太小可能导致频繁的全量复制，影响性能。它存储复制过程中的数据缓冲区，避免全量复制。配置参数为<code>repl-backlog-size</code>，默认值为 1M。单个主节点配置一个复制积压缓冲区。</li></ul><p>‌<strong>AOF 缓冲区</strong>‌：</p><ul><li>如果启用了 AOF（Append-Only File）持久化，则会有一个缓冲区用于存储写操作，以便在后台将其写入磁盘。AOF 重写期间增量的写入命令也会保存在这个缓冲区中。此部分缓存占用大小取决于 AOF 重写时间及增量。</li></ul><p>‌<strong>客户端缓存</strong>‌：</p><p>Redis 客户端主要分为<strong>从客户端</strong>、<strong>订阅客户端</strong>和<strong>普通客户端</strong>。从客户端连接主要用于主从复制，订阅客户端用于发布订阅功能，普通客户端则是通常的应用连接。每种类型的客户端都有不同的缓冲配置限制，以避免因缓冲区积压而导致的内存问题。</p><ul><li><p>‌<strong>输入缓冲</strong>‌：TCP 连接的输入缓冲占用是不受控制的，最大允许空间为 1G。</p></li><li><p>‌<strong>输出缓冲</strong>‌：TCP 连接的输出缓冲占用可以通过<code>client-output-buffer-limit</code>参数配置。</p><figure><img src="http://img.catpaws.top/img/image-20241230140922747-2024-12-3014_09_30.png" srcset="/img/loading.gif" lazyload alt="image-20241230140922747"><figcaption aria-hidden="true">image-20241230140922747</figcaption></figure><div class="code-wrapper"><pre><code class="hljs properties"><span class="hljs-comment">#默认配置如下：</span>
<span class="hljs-comment"># Both the hard or the soft limit can be disabled by setting them to zero.</span>
<span class="hljs-comment">#普通客户端默认不受限制</span>
<span class="hljs-attr">client-output-buffer-limit</span> <span class="hljs-string">normal 0 0 0</span>
<span class="hljs-attr">client-output-buffer-limit</span> <span class="hljs-string">replica 256mb 64mb 60</span>
<span class="hljs-attr">client-output-buffer-limit</span> <span class="hljs-string">pubsub 32mb 8mb 60</span></code></pre></div></li></ul><p>解决客户端缓冲区过大导致断开 Redis 连接的方法：</p><p>1、设置一个大小</p><p>2、增加带宽，避免我们出现大量数据从而直接超过了 redis 的承受能力</p><p>Redis 提供的查看客户端详情的命令</p><ul><li><p><code>info clients</code>，返回客户端总览，其中包括最大输入和最大输出缓冲区的大小</p><p><img src="http://img.catpaws.top/img/image-20241230142225240-2024-12-3014_23_04.png" srcset="/img/loading.gif" lazyload alt="image-20241230142225240" style="zoom:80%"></p></li><li><p><code>client list</code>，可以获取当前连接到 Redis 服务器的所有客户端信息，其中包括客户端的缓冲区使用情况。</p><p><img src="http://img.catpaws.top/img/image-20241230142726964-2024-12-3014_28_04.png" srcset="/img/loading.gif" lazyload alt="image-20241230142726964" style="zoom:67%"></p><p>在输出结果中，关注与客户端缓冲区相关的字段，这些字段包括：</p><ul><li><code>qbuf</code>：查询缓冲区的长度（字节为单位），表示客户端发送到 Redis 但尚未被处理的命令所占用的缓冲区大小。如果<code>qbuf</code>很大，而同时<code>qbuf-free</code>（查询缓冲区剩余空间的长度）很小，说明客户端的输入缓冲区已经占用了很多内存，且空闲空间不足。</li><li><code>qbuf-free</code>：查询缓冲区剩余空间的长度（字节为单位），表示客户端输入缓冲区中剩余的可用空间大小。</li><li><code>obl</code>：输出缓冲区的长度（字节为单位），表示 Redis 为客户端分配的输出缓冲区中，已用于存储命令执行结果的部分所占用的空间大小。</li><li><code>oll</code>：输出列表包含的对象数量，当输出缓冲区没有剩余空间时，命令回复会以字符串对象的形式被入队到这个队列里。</li><li><code>omem</code>：输出缓冲区和输出列表占用的内存总量。</li></ul><p>根据上述字段的值，可以分析客户端的缓冲区使用情况。例如，如果<code>qbuf</code>值很大，说明客户端正在向 Redis 发送大量命令，而 Redis 尚未处理完这些命令。如果<code>obl</code>和<code>oll</code>值很大，说明 Redis 正在为客户端准备大量的命令执行结果，但尚未发送给客户端。如果<code>qbuf-free</code>值很小或接近 0，说明客户端的输入缓冲区已经接近满负荷，可能需要考虑优化客户端的命令发送速率或增加 Redis 的处理能力。</p><p>根据分析结果，采取相应的措施来优化客户端的缓冲区使用情况。例如，如果发现某个客户端的<code>qbuf</code>值持续很高，可以考虑优化该客户端的命令发送逻辑，减少不必要的命令发送；如果发现 Redis 的输出缓冲区占用过高，可以考虑增加 Redis 的内存配额、优化数据访问模式或增加 Redis 实例的数量等。</p><blockquote><p>注意：<code>CLIENT LIST</code>命令输出的缓冲区信息只是瞬时值，要全面了解客户端的缓冲区使用情况，可能需要结合监控工具和日志分析等方法进行综合评估。</p></blockquote></li></ul><h3 id="集群最佳实践---集群-or-主从">3.4、集群最佳实践 - 集群 or 主从</h3><p>集群虽然具备高可用特性，能实现自动故障恢复，但是如果使用不当，也会存在一些问题：</p><ul><li><p><strong>集群完整性问题</strong></p><p>在 Redis 的默认配置中，如果发现任意一个插槽不可用，则整个集群都会停止对外服务：</p><figure><img src="http://img.catpaws.top/img/1653132740637-2024-12-3013_12_20.png" srcset="/img/loading.gif" lazyload alt="1653132740637"><figcaption aria-hidden="true">1653132740637</figcaption></figure><p>在开发中，其实最重要的是可用性，所以需要把如下配置修改成 no，即有 slot 不能使用时，redis 集群的其他节点还是可以对外提供服务。</p></li><li><p><strong>集群带宽问题</strong></p><p>集群节点之间会不断的互相 Ping 来确定集群中其它节点的状态。每次 Ping 携带的信息至少包括：</p><ul><li>插槽信息</li><li>集群状态信息</li></ul><p>集群中节点越多，集群状态信息数据量也越大，10 个节点的相关信息可能达到 1kb，此时每次集群互通需要的带宽会非常高，这样会导致集群中大量的带宽都会被 ping 信息所占用，这是一个非常可怕的问题。</p><p><strong>解决途径：</strong></p><ul><li>避免大集群，集群节点数不要太多，最好少于 1000，如果业务庞大，则建立多个集群。</li><li>避免在单个物理机中运行太多 Redis 实例</li><li>配置合适的 cluster-node-timeout 值</li></ul></li><li><p><strong>数据倾斜问题</strong></p><p>在出现 BigKey 或者批处理中使用 hash_tag 策略时，会产生数据倾斜的问题。</p></li><li><p><strong>客户端性能问题</strong></p></li><li><p><strong>命令的集群兼容性问题</strong></p></li><li><p><strong>lua 和事务问题</strong></p><p>lua 和事务都是要保证原子性问题，如果你的 key 不在一个节点，那么是无法保证 lua 的执行和事务的特性的，所以在集群模式是没有办法执行 lua 和事务的。</p></li></ul><p><strong>到底是集群还是主从？</strong></p><p>单体 Redis（主从 Redis）已经能达到万级别的 QPS，并且也具备很强的高可用特性。如果主从能满足业务需求的情况下，所以如果不是在万不得已的情况下，尽量不搭建 Redis 集群</p><h2 id="四补充redis-事务">四、补充：Redis 事务</h2><p>Redis 事务：一组命令的集合。事务中每条命令都会被序列化，执行过程中按顺序执行，不允许其他命令进行干扰。所有事务中的命令在加入时都没有被执行，直到提交时才会开始执行(Exec)一次性完成。</p><h3 id="使用-redis-事务">4.1、使用 Redis 事务</h3><p>Redis 可以通过 <strong>MULTI</strong>，<strong>EXEC</strong>，<strong>DISCARD</strong> 和 <strong>WATCH</strong> 等命令来实现事务(Transaction)功能。</p><p>操作过程：开启事务(<code>multi</code>) &gt;&gt; 命令入队 &gt;&gt; 执行事务(<code>exec</code>)</p><div class="code-wrapper"><pre><code class="hljs bash">127.0.0.1:6379&gt; multi <span class="hljs-comment"># 开启事务</span>
OK
127.0.0.1:6379&gt; <span class="hljs-built_in">set</span> k1 v1 <span class="hljs-comment"># 命令入队</span>
QUEUED
127.0.0.1:6379&gt; <span class="hljs-built_in">set</span> k2 v2 <span class="hljs-comment"># ..</span>
QUEUED
127.0.0.1:6379&gt; get k1
QUEUED
127.0.0.1:6379&gt; <span class="hljs-built_in">set</span> k3 v3
QUEUED
127.0.0.1:6379&gt; keys *
QUEUED
127.0.0.1:6379&gt; <span class="hljs-built_in">exec</span> <span class="hljs-comment"># 事务执行</span>
1) OK
2) OK
3) <span class="hljs-string">&quot;v1&quot;</span>
4) OK
5) 1) <span class="hljs-string">&quot;k3&quot;</span>
   2) <span class="hljs-string">&quot;k2&quot;</span>
   3) <span class="hljs-string">&quot;k1&quot;</span></code></pre></div><p>取消事务(<code>discurd</code>)</p><div class="code-wrapper"><pre><code class="hljs bash">127.0.0.1:6379&gt; multi
OK
127.0.0.1:6379&gt; <span class="hljs-built_in">set</span> k1 v1
QUEUED
127.0.0.1:6379&gt; <span class="hljs-built_in">set</span> k2 v2
QUEUED
127.0.0.1:6379&gt; DISCARD <span class="hljs-comment"># 放弃事务</span>
OK
127.0.0.1:6379&gt; EXEC
(error) ERR EXEC without MULTI <span class="hljs-comment"># 当前未开启事务</span>
127.0.0.1:6379&gt; get k1 <span class="hljs-comment"># 被放弃事务中命令并未执行</span>
(nil)</code></pre></div><p>通过<code>WATCH</code> 命令监听指定的 Key，当调用 <strong>EXEC</strong> 命令执行事务时，如果一个被 <strong>WATCH</strong> 命令监视的 Key 被 其他客户端/Session 修改的话，整个事务都不会被执行。</p><div class="code-wrapper"><pre><code class="hljs bash"><span class="hljs-comment"># 客户端 1</span>
127.0.0.1:6379&gt; SET PROJECT <span class="hljs-string">&quot;Hello，Redis!&quot;</span>
OK
127.0.0.1:6379&gt; WATCH PROJECT
OK
127.0.0.1:6379&gt; MULTI
OK
127.0.0.1:6379&gt; SET PROJECT <span class="hljs-string">&quot;Hello，Redis!&quot;</span>
QUEUED

<span class="hljs-comment"># 客户端 2</span>
<span class="hljs-comment"># 在客户端 1 执行 EXEC 命令提交事务之前修改 PROJECT 的值</span>
127.0.0.1:6379&gt; SET PROJECT <span class="hljs-string">&quot;Hi，Redis!&quot;</span>

<span class="hljs-comment"># 客户端 1</span>
<span class="hljs-comment"># 修改失败，因为 PROJECT 的值被客户端2修改了</span>
127.0.0.1:6379&gt; EXEC
(nil)
127.0.0.1:6379&gt; GET PROJECT
<span class="hljs-string">&quot;Hi，Redis!&quot;</span></code></pre></div><h3 id="redis-事务特性">4.2、Redis 事务特性</h3><p><strong>Redis 的单条命令是保证原子性的，但是 redis 事务不能保证原子性</strong></p><p>对于提交到事务中的命令，若出现代码语法错误（编译时异常）所有的命令都不执行；若是代码逻辑错误 (运行时异常) <strong>其他命令可以正常执行 </strong>（<u>不保证事务原子性</u>）。并且，Redis 事务是不支持回滚（roll back）操作的。</p><p>Redis 从 2.6 版本开始支持执行 Lua 脚本，它的功能和事务非常类似。我们可以利用 Lua 脚本来批量执行多条 Redis 命令，这些 Redis 命令会被提交到 Redis 服务器一次性执行完成，大幅减小了网络开销。一段 Lua 脚本可以视作一条命令执行，一段 Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行，保证了操作不会被其他指令插入或打扰。</p><p>不过，如果 Lua 脚本运行时出错并中途结束，出错之后的命令是不会被执行的。并且，出错之前执行的命令是无法被撤销的，无法实现类似关系型数据库执行失败可以回滚的那种原子性效果。因此， 严格来说的话，通过 Lua 脚本来批量执行 Redis 命令实际也是不完全满足原子性的。</p><p>如果想要让 Lua 脚本中的命令全部执行，必须保证语句语法和命令都是对的。</p><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Bisikl/article/details/143578263">参考文章</a></p></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/" class="category-chain-item">数据库</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/Redis%E6%8C%81%E4%B9%85%E5%8C%96/" class="print-no-link">#Redis持久化</a> <a href="/tags/Redis%E4%B8%BB%E4%BB%8E/" class="print-no-link">#Redis主从</a> <a href="/tags/Redis%E5%88%86%E7%89%87%E9%9B%86%E7%BE%A4/" class="print-no-link">#Redis分片集群</a> <a href="/tags/%E5%A4%9A%E7%BA%A7%E7%BC%93%E5%AD%98/" class="print-no-link">#多级缓存</a> <a href="/tags/Redis%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/" class="print-no-link">#Redis最佳实践</a> <a href="/tags/Redis%E4%BA%8B%E5%8A%A1/" class="print-no-link">#Redis事务</a></div></div><div class="license-box my-3"><div class="license-title"><div>Redis - 高级篇</div><div>https://catpaws.top/29be09bb/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>猫爪在上</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2024年12月24日</div></div><div class="license-meta-item"><div>许可协议</div><div><a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-cc-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/284457ed/" title="Redis - 原理篇"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">Redis - 原理篇</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/e0606bbf/" title="Redis - 实战篇"><span class="hidden-mobile">Redis - 实战篇</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><div id="twikoo"></div><script type="text/javascript">Fluid.utils.loadComments("#comments",(function(){Fluid.utils.createScript("https://cdn.smartcis.cn/npm/twikoo@1.6.40/dist/twikoo.all.min.js",(function(){var t=Object.assign({envId:"https://catpaws-comments.netlify.app/.netlify/functions/twikoo",region:"ap-shanghai",path:"window.location.pathname"},{el:"#twikoo",path:"window.location.pathname",onCommentLoaded:function(){Fluid.utils.listenDOMLoaded((function(){var t="#twikoo .tk-content img:not(.tk-owo-emotion)";Fluid.plugins.imageCaption(t),Fluid.plugins.fancyBox(t)}))}});twikoo.init(t)}))}))</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><script>Fluid.utils.createScript("https://lib.baomitu.com/mermaid/8.14.0/mermaid.min.js",(function(){mermaid.initialize({theme:"default"}),Fluid.utils.listenDOMLoaded((function(){Fluid.events.registerRefreshCallback((function(){"mermaid"in window&&mermaid.init()}))}))}))</script><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a><br>人山人海，欢迎你的到来 <i class="iconfont icon-love"></i><br><span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script defer src="/js/leancloud.js"></script><script src="/js/local-search.js"></script><script src="//img.catpaws.top/blog-source/js/timeDate.js"></script><script src="//sdk.jinrishici.com/v2/browser/jinrishici.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript><script data-pjax src="https://unpkg.com/oh-my-live2d"></script><script>const oml2d=OML2D.loadOml2d({dockedPosition:"left",mobileDisplay:!1,models:[{path:"http://img.catpaws.top/blog-source/live2d/Frieren/Frieren.model3.json",motionPreloadStrategy:"IDLE",position:[-60,-100],scale:.06,stageStyle:{width:250,height:350}}],parentElement:document.body,primaryColor:"var(--btn-bg)",sayHello:!1,tips:{style:{width:200,height:90,left:"calc(50% - 20px)",top:"-100px","font-size":"14px"},idleTips:{interval:15e3,message:function(){return axios.get("https://v1.hitokoto.cn?c=i").then((function(t){return t.data.hitokoto})).catch((function(t){console.error(t)}))}}}})</script></body></html>